{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 3\n",
    "\n",
    "## Reporting: Different Kinds of Frequencies\n",
    "\n",
    "When reporting your findings from last week, you've mainly been using \"absolute frequency\" (AF). There are, however, many ways report word frequencies in a corpus. As we go over these frequencies, consider the trade-offs and advantages of each.\n",
    "\n",
    "### Absolute (\"raw\") frequency\n",
    "\n",
    "Brezina defines AF as \"a count of all tokens in the text or corpus that belong to a particular word type\" [@Brezina2018 42]. He uses the example of the 6,041,234 occurrences of the token \"the\" in the British National Corpus (BNC). Since Greek inflects the definite article, we can't simply count the occurrences of a single token.\n",
    "\n",
    "> Discuss: When should you use absolute frequency in reporting?\n",
    "\n",
    "As usual, let's load up our text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyCapytain.resources.texts.local.capitains.cts import CapitainsCtsText\n",
    "\n",
    "with open(\"../tei/tlg0525.tlg001.perseus-eng2.xml\") as f:\n",
    "    text = CapitainsCtsText(urn=\"urn:cts:greekLit:tlg0525.tlg001.perseus-eng2\", resource=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And let's count the occurrences of the definite article across the whole work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lxml import etree\n",
    "from MyCapytain.common.constants import Mimetypes\n",
    "\n",
    "urns = []\n",
    "raw_xmls = []\n",
    "unannotated_strings = []\n",
    "\n",
    "for ref in text.getReffs(level=len(text.citation)):\n",
    "    urn = f\"{text.urn}:{ref}\"\n",
    "    node = text.getTextualNode(ref)\n",
    "    raw_xml = node.export(Mimetypes.XML.TEI)\n",
    "    tree = node.export(Mimetypes.PYTHON.ETREE)\n",
    "    s = etree.tostring(tree, encoding=\"unicode\", method=\"text\")\n",
    "\n",
    "    urns.append(urn)\n",
    "    raw_xmls.append(raw_xml)\n",
    "    unannotated_strings.append(s)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "d = {\n",
    "    \"urn\": pd.Series(urns, dtype=\"string\"),\n",
    "    \"raw_xml\": raw_xmls,\n",
    "    \"unannotated_strings\": pd.Series(unannotated_strings, dtype=\"string\")\n",
    "}\n",
    "pausanias_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will take a while\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])\n",
    "\n",
    "raw_texts = [t for t in pausanias_df['unannotated_strings']]\n",
    "annotated_texts = nlp.pipe(raw_texts, batch_size=100)\n",
    "\n",
    "pausanias_df['nlp_docs'] = list(annotated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26932"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definite_article = [t for t in pausanias_df['nlp_docs'].explode() if t.lemma_ == \"the\"]\n",
    "\n",
    "len(definite_article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus we have 26,932 occurrences of the definite article in Pausanias.\n",
    "\n",
    "When might we want to use absolute frequency? As we've already started to see when working with Pausanias, absolute frequency can be useful for sorting tokens and lemmata in a single corpus. When comparing multiple corpora, however, absolute frequency does not provide a good comparison: consider the problem when comparing a relatively small corpus, like Aeschylus' seven extant plays, to all of Pausanias: absolute frequencies as a point of comparison would be essentially meaningless. Or to take a more ready-to-hand example, what would it mean to compare the frequencies in a single book of Pausanias to the entire work? For this kind of analysis, we need to use **relative frequency**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relative (\"normalized\") frequency\n",
    "\n",
    "Relative frequency [@Brezina2018 43] is easy to calculate: take the absolute frequency of the target word and divide it by the total words in the corpus. By convention, we then multiple it by a constant, the \"basis for normalization\" -- this converts the measurement from a percentage of tokens in the corpus to an expression of tokens per thousand -- or million, whatever you decide to make your constant.\n",
    "\n",
    "To practice, let's calculate the number of definite articles per million words in Pausanias.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86444.08352966099\n"
     ]
    }
   ],
   "source": [
    "n_definite_article = len(definite_article)\n",
    "n_tokens = len([t for t in pausanias_df['nlp_docs'].explode()])\n",
    "basis = 1_000_000\n",
    "\n",
    "rf_definite_article_in_pausanias = (n_definite_article / n_tokens) * basis\n",
    "\n",
    "print(rf_definite_article_in_pausanias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you've probably surmised from looking at this calculation, the relative frequency \"can ... be considered as ... the mean of the frequencies of the word in hypothetical samples of _x_ tokens from the corpus, where _x_ is the basis for normalization\" [@Brezina2018 43].\n",
    "\n",
    "In other words, if we were to divide Pausanias into equal 1-million-word chunks, counting the occurrences of the definite article in each chunk and then averaging them, we would arrive at the same number.\n",
    "\n",
    "Keep this intuition in mind for later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hapax legomena (\"once-saids\")\n",
    "\n",
    "_Hapax legomena_ (singular _hapax legomenon_ or simply _hapax_) are words that occur only once in the corpus. We can get a sense of hapaxes in Pausanias by counting the occurrences of lemmata like we did last week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Laurium',\n",
       " 'mariner',\n",
       " 'Cononfl',\n",
       " 'Doritis',\n",
       " 'Euploia',\n",
       " 'Voyage',\n",
       " 'Heros',\n",
       " 'Genetyllides',\n",
       " 'Birth',\n",
       " 'Gennaides',\n",
       " 'Colias',\n",
       " 'Alcamenesfl',\n",
       " 'antiope',\n",
       " 'Diopeithes',\n",
       " 'Gonatas',\n",
       " 'society',\n",
       " 'purposely',\n",
       " 'boorishness',\n",
       " 'depreciate',\n",
       " 'acquisition',\n",
       " 'comparison',\n",
       " 'Polybotes',\n",
       " 'Chelone',\n",
       " 'Pulytion',\n",
       " 'parody',\n",
       " 'Melpomenus',\n",
       " 'Minstrel',\n",
       " 'Musegetes',\n",
       " 'Mnemosyne',\n",
       " 'Acratus',\n",
       " 'ware',\n",
       " 'Actaea',\n",
       " 'reputed',\n",
       " 'Royal',\n",
       " 'tiling',\n",
       " 'EvagorasEvagoras',\n",
       " 'Cinyras',\n",
       " 'Democracy',\n",
       " 'democratical',\n",
       " 'science',\n",
       " 'cleidicus',\n",
       " 'leochare',\n",
       " 'Peisias',\n",
       " 'Lyson',\n",
       " 'thesmothetae',\n",
       " 'protogenesa',\n",
       " 'Caunian',\n",
       " 'olbiadesan',\n",
       " 'gauls',\n",
       " 'CassanderAntipater',\n",
       " 'exhausted',\n",
       " 'whelm',\n",
       " 'unperceive',\n",
       " 'obligation',\n",
       " 'outflank',\n",
       " 'Gates',\n",
       " 'Amadocus',\n",
       " 'farther',\n",
       " 'Gordius',\n",
       " 'Pergameni',\n",
       " 'meian',\n",
       " 'reform',\n",
       " 'eponymoithat',\n",
       " 'overstep',\n",
       " 'dishonored',\n",
       " 'mangle',\n",
       " 'damsel',\n",
       " 'attalusthis',\n",
       " 'bounty',\n",
       " 'chronicle',\n",
       " 'Mysians',\n",
       " 'troubled',\n",
       " 'putatively',\n",
       " 'Oxydracae',\n",
       " 'Oxyartes',\n",
       " 'unpopular',\n",
       " 'Anti',\n",
       " 'pater',\n",
       " 'pare',\n",
       " 'confident',\n",
       " 'ptolemy',\n",
       " 'Pelusium',\n",
       " 'ingenuity',\n",
       " 'fancy',\n",
       " 'Argaeus',\n",
       " 'disaffection',\n",
       " 'governorship',\n",
       " 'Cyrenians',\n",
       " 'Marmaridae',\n",
       " 'Apame',\n",
       " 'Docimus',\n",
       " 'paphlagonian',\n",
       " 'episode',\n",
       " 'Eirene',\n",
       " 'Plutus',\n",
       " 'Thurian',\n",
       " 'heartily',\n",
       " 'unsparingly',\n",
       " 'Locrus',\n",
       " 'Calades',\n",
       " 'framed',\n",
       " 'lawsOr',\n",
       " 'Aristogiton',\n",
       " 'Critiusfl',\n",
       " 'Soter',\n",
       " 'sarcastic',\n",
       " 'subservient',\n",
       " 'eunuchs',\n",
       " 'cruelly',\n",
       " 'sycophancy',\n",
       " 'comprise',\n",
       " 'Dromichaetes',\n",
       " 'unverse',\n",
       " 'Dromicliaetes',\n",
       " 'agathocle',\n",
       " 'Lebedos',\n",
       " 'Mermesianax',\n",
       " 'dirge',\n",
       " 'Cardianfl',\n",
       " 'bias',\n",
       " 'unfairly',\n",
       " 'malice',\n",
       " 'Aeacid',\n",
       " 'irreconcilable',\n",
       " 'Cardians',\n",
       " 'aggressive',\n",
       " 'aggrandise',\n",
       " 'Amphipolis',\n",
       " 'Nestians',\n",
       " 'continued',\n",
       " 'mature',\n",
       " 'powerless',\n",
       " 'aggrieve',\n",
       " 'lysimachus',\n",
       " 'Cardia',\n",
       " 'Pactye',\n",
       " 'Aryblas',\n",
       " 'volunteer',\n",
       " 'Thyamis',\n",
       " 'Areius',\n",
       " 'allegiance',\n",
       " 'forgave',\n",
       " 'Oeneadae',\n",
       " 'uncontrollable',\n",
       " 'consolidate',\n",
       " 'invitation',\n",
       " 'cogent',\n",
       " 'entitle',\n",
       " 'memoir',\n",
       " 'observation',\n",
       " 'European',\n",
       " 'Porus',\n",
       " 'Dwarf',\n",
       " 'Italiots',\n",
       " 'conceit',\n",
       " 'saltwith',\n",
       " 'victual',\n",
       " 'remainder',\n",
       " 'asiatic',\n",
       " 'pyrrhu',\n",
       " 'Molossian',\n",
       " 'ItonianAthena',\n",
       " 'hostof',\n",
       " 'tis',\n",
       " 'TheAeacidae',\n",
       " 'wereof',\n",
       " 'Dodonian',\n",
       " 'broughtslavery',\n",
       " 'ownerlessthey',\n",
       " 'boastful',\n",
       " 'readier',\n",
       " 'insufficient',\n",
       " 'desist',\n",
       " 'vulnerable',\n",
       " 'Victorious',\n",
       " 'Cardian',\n",
       " 'royalty',\n",
       " 'justify',\n",
       " 'suppress',\n",
       " 'Enneacrunos',\n",
       " 'Jets',\n",
       " 'embellish',\n",
       " 'Deiope',\n",
       " 'Chrysanthis',\n",
       " 'Trochilus',\n",
       " 'ascribe',\n",
       " 'Rarus',\n",
       " 'Eleusinium',\n",
       " 'lawful',\n",
       " 'Cnossusfl',\n",
       " 'Polymnastus',\n",
       " 'Glory',\n",
       " 'proudest',\n",
       " 'prospect',\n",
       " 'Paphians',\n",
       " 'Ascalon',\n",
       " 'Athmoneis',\n",
       " 'Porphyrion',\n",
       " 'morass',\n",
       " 'scramble',\n",
       " 'Echetlus',\n",
       " 'Scioneans',\n",
       " 'foreshadow',\n",
       " 'unmistakable',\n",
       " 'Pella',\n",
       " 'application',\n",
       " 'rapidly',\n",
       " 'adventurous',\n",
       " 'Seleucea',\n",
       " 'Tigris',\n",
       " 'Bel',\n",
       " 'Chaldeans',\n",
       " 'Mercy',\n",
       " 'humanity',\n",
       " 'Shamefastness',\n",
       " 'Rumour',\n",
       " 'Juba',\n",
       " 'ChrysippusThe',\n",
       " 'intelligible',\n",
       " 'unfamiliar',\n",
       " 'Acherusia',\n",
       " 'Cocytus',\n",
       " 'unlovely',\n",
       " 'doughty',\n",
       " 'marked',\n",
       " 'Accordingly',\n",
       " 'Polygnotusfl',\n",
       " 'concentrate',\n",
       " 'oraclethat',\n",
       " 'pact',\n",
       " 'Auunisus',\n",
       " 'cnossian',\n",
       " 'colossi',\n",
       " 'width',\n",
       " 'deluge',\n",
       " 'diligence',\n",
       " 'restraint',\n",
       " 'cite',\n",
       " 'cloister',\n",
       " 'alabaster',\n",
       " 'Delphinius',\n",
       " 'Delphinian',\n",
       " 'neatly',\n",
       " 'mockingly',\n",
       " 'marriageable',\n",
       " 'Cynosarges',\n",
       " 'gin',\n",
       " 'Termilae',\n",
       " 'Lycii',\n",
       " 'beleaguer',\n",
       " 'ilisian',\n",
       " 'Agrae',\n",
       " 'impressive',\n",
       " 'prytaneum',\n",
       " 'studio',\n",
       " 'confessing',\n",
       " 'Thymilus',\n",
       " 'invisible',\n",
       " 'repose',\n",
       " 'turbulent',\n",
       " 'respectable',\n",
       " 'ensue',\n",
       " 'Magnetes',\n",
       " 'besieging',\n",
       " 'imprison',\n",
       " 'Pherecydes',\n",
       " 'Protector',\n",
       " 'wherein',\n",
       " 'beetling',\n",
       " 'resemblance',\n",
       " 'deflower',\n",
       " 'Alcippe',\n",
       " 'ravisher',\n",
       " 'sauromatic',\n",
       " 'Sauromatae',\n",
       " 'dealing',\n",
       " 'deficiency',\n",
       " 'segment',\n",
       " 'stitch',\n",
       " 'sinew',\n",
       " 'Linen',\n",
       " 'notably',\n",
       " 'Gryneum',\n",
       " 'sepulchral',\n",
       " 'wickedness',\n",
       " 'disgust',\n",
       " 'pin',\n",
       " 'Pandemos',\n",
       " 'Youth',\n",
       " 'Chloe',\n",
       " 'xenophon',\n",
       " 'efface',\n",
       " 'barbarous',\n",
       " 'insight',\n",
       " 'Nausicaa',\n",
       " 'Seriphos',\n",
       " 'TimaenetusAn',\n",
       " 'Anacharsis',\n",
       " 'statecraft',\n",
       " 'Lioness',\n",
       " 'Peisistratidae',\n",
       " 'Diitrephes',\n",
       " 'Chalcidic',\n",
       " 'exterminate',\n",
       " 'Mycalessians',\n",
       " 'smallish',\n",
       " 'Sileni',\n",
       " 'Carian',\n",
       " 'seaman',\n",
       " 'Satyrides',\n",
       " 'haired',\n",
       " 'shocking',\n",
       " 'sprinkler',\n",
       " 'behead',\n",
       " 'breach',\n",
       " 'peep',\n",
       " 'Epicharinus',\n",
       " 'Critius',\n",
       " 'Oenobius',\n",
       " 'Olorus',\n",
       " 'Melitid',\n",
       " 'Hermolycus',\n",
       " 'PhormioA',\n",
       " 'Paeania',\n",
       " 'creditor',\n",
       " 'Ergane',\n",
       " 'limbless',\n",
       " 'beseech',\n",
       " 'LeocharesSee',\n",
       " 'unguarde',\n",
       " 'grain',\n",
       " 'AristeasAn',\n",
       " 'womankind',\n",
       " 'Locust',\n",
       " 'Deinomenesfl',\n",
       " 'thedanger',\n",
       " 'nominally',\n",
       " 'passive',\n",
       " 'Darius',\n",
       " 'deport',\n",
       " 'Long',\n",
       " 'Panactum',\n",
       " 'Phanostratus',\n",
       " 'notwithstanding',\n",
       " 'removable',\n",
       " 'forefather',\n",
       " 'ado',\n",
       " 'memorably',\n",
       " 'Protarchus',\n",
       " 'scribing',\n",
       " 'loiter',\n",
       " 'Endoeusfl',\n",
       " 'Erechtheum',\n",
       " 'Butadae',\n",
       " 'outline',\n",
       " 'symbol',\n",
       " 'unification',\n",
       " 'Polis',\n",
       " 'Callimachusfl',\n",
       " 'wick',\n",
       " 'carpasian',\n",
       " 'asbestos',\n",
       " 'drill',\n",
       " 'Refiner',\n",
       " 'Art',\n",
       " 'bough',\n",
       " 'testimony',\n",
       " 'Bearers',\n",
       " 'Offerings',\n",
       " 'Lysimache',\n",
       " 'Theaenetus',\n",
       " 'Such',\n",
       " 'fragile',\n",
       " 'bodied',\n",
       " 'earnest',\n",
       " 'Tethris',\n",
       " 'Eryrmanthus',\n",
       " 'Crommyon',\n",
       " 'Labours',\n",
       " 'Minotaur',\n",
       " 'Labyrinth',\n",
       " 'chisel',\n",
       " 'Mysfl',\n",
       " 'Parrhasius',\n",
       " 'Evenor',\n",
       " 'Euboeac',\n",
       " 'lemnian',\n",
       " 'Agrolas',\n",
       " 'Hyperbius',\n",
       " 'postpone',\n",
       " 'philippide',\n",
       " 'announcement',\n",
       " 'defendant',\n",
       " 'prosecutor',\n",
       " 'Ruthlessness',\n",
       " 'Theogonyl',\n",
       " 'Erinyes',\n",
       " 'Parabystum',\n",
       " 'Triangle',\n",
       " 'Heliaea',\n",
       " 'involuntary',\n",
       " 'Delphinium',\n",
       " 'justifiable',\n",
       " 'shedder',\n",
       " 'Phreattys',\n",
       " 'defense',\n",
       " 'guiltless',\n",
       " 'Panathenaea',\n",
       " 'Ariste',\n",
       " 'Best',\n",
       " 'abide',\n",
       " 'ChabriasDied',\n",
       " 'Drabescusc',\n",
       " 'unexpectedly',\n",
       " 'Leagrus',\n",
       " 'Sophanes',\n",
       " 'pentathlonA',\n",
       " 'Macartatus',\n",
       " 'Eleon',\n",
       " 'bowman',\n",
       " 'system',\n",
       " 'whereof',\n",
       " 'Melesander',\n",
       " 'secession',\n",
       " 'immemorial',\n",
       " 'Arsites',\n",
       " 'Perinthians',\n",
       " 'He',\n",
       " 'EubulusA',\n",
       " 'accomplice',\n",
       " 'OlympiodorusSee',\n",
       " 'ChrysippusStoic',\n",
       " 'abolition',\n",
       " 'dockyard',\n",
       " 'Charmus',\n",
       " 'Avenged',\n",
       " 'spurn',\n",
       " 'remorse',\n",
       " 'foretelling',\n",
       " 'Swan',\n",
       " 'shun',\n",
       " 'AntigonusSee',\n",
       " 'Alimus',\n",
       " 'Zoster',\n",
       " 'Girdle',\n",
       " 'delivery',\n",
       " 'Prospalta',\n",
       " 'Anagyrus',\n",
       " 'Cephale',\n",
       " 'habitant',\n",
       " 'straw',\n",
       " 'Potami',\n",
       " 'Phlya',\n",
       " 'Flower',\n",
       " 'Anesidora',\n",
       " 'Sender',\n",
       " 'Ctesius',\n",
       " 'Gain',\n",
       " 'Tithrone',\n",
       " 'Amarynthus',\n",
       " 'Euboean',\n",
       " 'Myrrhinusians',\n",
       " 'Acharnae',\n",
       " 'Singer',\n",
       " 'Alazones',\n",
       " 'Russia',\n",
       " 'tamely',\n",
       " 'hive',\n",
       " 'Hymettius',\n",
       " 'Foreseer',\n",
       " 'Parnethius',\n",
       " 'Semaleus',\n",
       " 'Sign',\n",
       " 'giving',\n",
       " 'Ills',\n",
       " 'Anchesmus',\n",
       " 'Anchesmius',\n",
       " 'pointin',\n",
       " 'neighing',\n",
       " 'acknowledge',\n",
       " 'rustic',\n",
       " 'Echetlaeus',\n",
       " 'Plough',\n",
       " 'anyhow',\n",
       " 'Ceyx',\n",
       " 'Artaphernes',\n",
       " 'implacable',\n",
       " 'navigate',\n",
       " 'Ichthyophagi',\n",
       " 'Mauri',\n",
       " 'Atlantes',\n",
       " 'Lixitae',\n",
       " 'inaccessible',\n",
       " 'onto',\n",
       " 'clearness',\n",
       " 'Hippeus',\n",
       " 'pos',\n",
       " 'session',\n",
       " 'Eleus',\n",
       " 'Lebadea',\n",
       " 'Panacea',\n",
       " 'Iaso',\n",
       " 'Mallus',\n",
       " 'Cilicia',\n",
       " 'lustral',\n",
       " 'Iophon',\n",
       " 'unrestrainedly',\n",
       " 'exposition',\n",
       " 'enlightenment',\n",
       " 'sunium',\n",
       " 'Aeschetades',\n",
       " 'eurysace',\n",
       " 'tinge',\n",
       " 'informant',\n",
       " 'pan',\n",
       " 'Cabares',\n",
       " 'pancrationboxe',\n",
       " 'Lade',\n",
       " 'anax',\n",
       " 'Chrysaor',\n",
       " 'criticize',\n",
       " 'Gadeira',\n",
       " 'sojourning',\n",
       " 'Omphale',\n",
       " 'Molottus',\n",
       " 'Plutarch',\n",
       " 'Tyrant',\n",
       " 'Scirum',\n",
       " 'Scirus',\n",
       " 'Elusinians',\n",
       " 'govern',\n",
       " 'Heliodorus',\n",
       " 'Halis',\n",
       " 'Poliarchus',\n",
       " 'Acestium',\n",
       " 'lifetime',\n",
       " 'Theophrastus',\n",
       " 'Lacius',\n",
       " 'Laciadae',\n",
       " 'unique',\n",
       " 'Zephyrus',\n",
       " 'honours',\n",
       " 'Mnesimache',\n",
       " 'Spercheus',\n",
       " 'TheodectesA',\n",
       " 'Mnesitheus',\n",
       " 'Cyamites',\n",
       " 'Cyamos',\n",
       " 'demeter',\n",
       " 'OrphicaA',\n",
       " 'aspect',\n",
       " 'orphic',\n",
       " 'Pythonice',\n",
       " 'Teleboans',\n",
       " 'Chalcinus',\n",
       " 'Daetus',\n",
       " 'hurry',\n",
       " 'Scambonidae',\n",
       " 'manly',\n",
       " 'dependent',\n",
       " 'Diogenia',\n",
       " 'Pammerope',\n",
       " 'Ceryx',\n",
       " 'ceryce',\n",
       " 'Polypemon',\n",
       " 'Procrustes',\n",
       " 'Portal',\n",
       " 'Callichorum',\n",
       " 'Rharium',\n",
       " 'Daeira',\n",
       " 'plataean',\n",
       " 'Formerly',\n",
       " 'Anthium',\n",
       " 'Wrestling',\n",
       " 'Ground',\n",
       " 'teaching',\n",
       " 'Chambers',\n",
       " 'Nisa',\n",
       " 'sciron',\n",
       " 'ignore',\n",
       " 'Crane',\n",
       " 'groaned',\n",
       " 'Destiny',\n",
       " 'apportion',\n",
       " 'overlay',\n",
       " 'galley',\n",
       " 'SolonThe',\n",
       " 'Dorycleans',\n",
       " 'Nyctelius',\n",
       " 'Nocturnal',\n",
       " 'Epistrophia',\n",
       " 'Conius',\n",
       " 'Dusty',\n",
       " 'Bryaxis',\n",
       " 'northward',\n",
       " 'Rhus',\n",
       " 'Stream',\n",
       " 'Hunter',\n",
       " 'captivity',\n",
       " 'evident',\n",
       " 'Witness',\n",
       " 'killing',\n",
       " 'Aethyia',\n",
       " 'amazonian',\n",
       " 'gravel',\n",
       " 'plaintive',\n",
       " 'Prodomeis',\n",
       " 'Builders',\n",
       " 'Pipes',\n",
       " 'Phamenoph',\n",
       " 'Sesostris',\n",
       " 'Aeantis',\n",
       " 'Ajacian',\n",
       " 'Decatephorus',\n",
       " 'Tithes',\n",
       " 'Archegetes',\n",
       " 'medicinal',\n",
       " 'Thesmophorus',\n",
       " 'fencing',\n",
       " 'Cleso',\n",
       " 'Tauropolis',\n",
       " 'Scythia',\n",
       " 'castaway',\n",
       " 'Anaclethris',\n",
       " 'Recall',\n",
       " 'mimic',\n",
       " 'Aesymnium',\n",
       " 'Shrine',\n",
       " 'Hyperion',\n",
       " 'sandion',\n",
       " 'Pyrgo',\n",
       " 'Euaechme',\n",
       " 'Iphiaoe',\n",
       " 'Astycratea',\n",
       " 'Dasyllius',\n",
       " 'Euchenor',\n",
       " 'Praxis',\n",
       " 'Action',\n",
       " 'Consoler',\n",
       " 'Desire',\n",
       " 'Yearning',\n",
       " 'poetical',\n",
       " 'sheepdog',\n",
       " 'Whereat',\n",
       " 'unawares',\n",
       " 'Prostaterius',\n",
       " 'Protecting',\n",
       " 'Carinus',\n",
       " 'Eileithyiae',\n",
       " 'Sheep',\n",
       " 'Apple',\n",
       " 'Epphus',\n",
       " 'relic',\n",
       " 'Aegialeum',\n",
       " 'Erenea',\n",
       " 'telephane',\n",
       " 'Scironian',\n",
       " 'unbridle',\n",
       " 'melicerte',\n",
       " 'molurian',\n",
       " 'Releaser',\n",
       " 'Latous',\n",
       " 'Ephyra',\n",
       " 'lawless',\n",
       " 'Asopia',\n",
       " 'Ephyraea',\n",
       " 'disarmament',\n",
       " 'Cromyon',\n",
       " 'Phaea',\n",
       " 'evildoer',\n",
       " 'Gabala',\n",
       " 'Doto',\n",
       " 'Calm',\n",
       " 'whale',\n",
       " 'Holies',\n",
       " 'Leches',\n",
       " 'EoeaeSaid',\n",
       " 'tepid',\n",
       " 'DiogenesThe',\n",
       " 'cynic',\n",
       " 'Craneum',\n",
       " 'Melaenis',\n",
       " 'paw',\n",
       " 'Hippostratus',\n",
       " 'Hycara',\n",
       " 'despitefully',\n",
       " 'crowning',\n",
       " 'spout',\n",
       " 'Octavia',\n",
       " 'Rich',\n",
       " 'vouchsafe',\n",
       " 'artemis',\n",
       " 'illegal',\n",
       " 'Terror',\n",
       " 'Aria',\n",
       " 'Arii',\n",
       " 'Medus',\n",
       " 'CinaethonAn',\n",
       " 'Medeus',\n",
       " 'Eriopis',\n",
       " 'asopian',\n",
       " 'Epliyraea',\n",
       " 'Alcidamea',\n",
       " 'Ephyraeans',\n",
       " 'Bridler',\n",
       " 'Mycenaean',\n",
       " 'beget',\n",
       " 'thoas',\n",
       " 'Hippotas',\n",
       " 'Bacchis',\n",
       " 'Prumnis',\n",
       " 'Telestes',\n",
       " 'teleste',\n",
       " 'Arieus',\n",
       " 'Perantas',\n",
       " 'Prytanes',\n",
       " 'Presidents',\n",
       " 'Eetion',\n",
       " 'Latin',\n",
       " 'Capitolinus',\n",
       " 'Coryphaeos',\n",
       " 'refresh',\n",
       " 'adjudicator',\n",
       " 'Pelagian',\n",
       " 'Canopus',\n",
       " 'Necessity',\n",
       " 'Force',\n",
       " 'seeker',\n",
       " 'informer',\n",
       " 'Scheria',\n",
       " 'Inopus',\n",
       " 'Teneatic',\n",
       " 'Tenea',\n",
       " 'tenedo',\n",
       " 'Apia',\n",
       " 'Aegyrus',\n",
       " 'Chrysorthe',\n",
       " 'bolder',\n",
       " 'Amphiptolemusfl',\n",
       " 'Daughter',\n",
       " 'eddying',\n",
       " 'Pheno',\n",
       " 'Zeuxippe',\n",
       " 'Aegiale',\n",
       " 'Metion',\n",
       " 'Ibycus',\n",
       " 'Lysianassa',\n",
       " 'Syllis',\n",
       " 'Rhopalus',\n",
       " 'RhodesThat',\n",
       " 'destitute',\n",
       " 'uniform',\n",
       " 'farewell',\n",
       " 'Olympium',\n",
       " 'Eupolis',\n",
       " 'harmonize',\n",
       " 'Dripping',\n",
       " 'Bacchanals',\n",
       " 'Cosmeterium',\n",
       " 'tiring',\n",
       " 'Phanes',\n",
       " 'phane',\n",
       " 'oraclei',\n",
       " 'Dread',\n",
       " 'conformable',\n",
       " 'Aristonymus',\n",
       " 'eclipse',\n",
       " 'ungovernable',\n",
       " 'Euthydemus',\n",
       " 'Timocleidas',\n",
       " 'bargain',\n",
       " 'suddenness',\n",
       " 'liberate',\n",
       " 'Argolian',\n",
       " 'Acte',\n",
       " 'unchallenged',\n",
       " 'PausaniasThe',\n",
       " 'dissatisfied',\n",
       " 'fiery',\n",
       " 'coward',\n",
       " 'otherthere',\n",
       " 'Fathers',\n",
       " 'Antigouus',\n",
       " 'hid',\n",
       " 'dose',\n",
       " 'Eurycleides',\n",
       " 'wd',\n",
       " 'Patroa',\n",
       " 'inartistic',\n",
       " 'Cleisthenean',\n",
       " 'Contemporary',\n",
       " 'Paedize',\n",
       " 'Dream',\n",
       " 'Epidotes',\n",
       " 'lull',\n",
       " 'Nicagora',\n",
       " 'Agasicles',\n",
       " 'Echetimus',\n",
       " 'verger',\n",
       " 'polo',\n",
       " 'paidero',\n",
       " 'esculent',\n",
       " 'Averters',\n",
       " 'Plemnaeis',\n",
       " 'Pioneer',\n",
       " 'Pyraea',\n",
       " 'HeraDemeter',\n",
       " 'Protectress',\n",
       " 'Nymphon',\n",
       " 'nymphon',\n",
       " 'Kindly',\n",
       " 'Ones',\n",
       " 'votary',\n",
       " 'aright',\n",
       " 'Telesphorus',\n",
       " 'Accomplisher',\n",
       " 'Acesis',\n",
       " 'Cure',\n",
       " 'Gortynian',\n",
       " 'Granianus',\n",
       " 'Altar',\n",
       " 'fierceness',\n",
       " 'Port',\n",
       " 'phliasia',\n",
       " 'contradictory',\n",
       " 'hillock',\n",
       " 'Arantia',\n",
       " 'Celusa',\n",
       " 'delightful',\n",
       " 'fathercare',\n",
       " 'Rhodius',\n",
       " 'Argonautica',\n",
       " 'disturbance',\n",
       " 'mathematician',\n",
       " 'Fl',\n",
       " 'Mnesarchus',\n",
       " 'Ganymeda',\n",
       " 'mythical',\n",
       " 'pardoning',\n",
       " 'cutter',\n",
       " 'unpleasant',\n",
       " 'Pratinas',\n",
       " 'satyric',\n",
       " 'Divination',\n",
       " 'supposing',\n",
       " 'terminate',\n",
       " 'Cult',\n",
       " 'telling',\n",
       " 'Anactorum',\n",
       " 'Cleones',\n",
       " 'cleonae',\n",
       " 'Pierced',\n",
       " 'Adrastea',\n",
       " 'isolated',\n",
       " 'argus',\n",
       " 'prediction',\n",
       " 'gossip',\n",
       " 'scabbard',\n",
       " 'mushroom',\n",
       " 'Arestor',\n",
       " 'Myceneus',\n",
       " 'Sparte',\n",
       " 'Teledamus',\n",
       " 'Clytemnestra',\n",
       " 'brook',\n",
       " 'environ',\n",
       " 'pet',\n",
       " 'peacock',\n",
       " 'gleaming',\n",
       " 'Seriphus',\n",
       " 'Dictys',\n",
       " 'debauch',\n",
       " 'prudence',\n",
       " 'wicke',\n",
       " 'Myirtilus',\n",
       " 'Rams',\n",
       " 'stray',\n",
       " 'Neleids',\n",
       " 'Alector',\n",
       " 'Amphilochians',\n",
       " 'dominion',\n",
       " 'prior',\n",
       " 'Erigone',\n",
       " 'tyndareus',\n",
       " 'Sillus',\n",
       " 'Borus',\n",
       " 'Paeonidae',\n",
       " 'Alcmaeonidae',\n",
       " 'Oxyntes',\n",
       " 'Thrasyanor',\n",
       " 'adviser',\n",
       " 'melta',\n",
       " 'Lacedas',\n",
       " 'pitor',\n",
       " 'readingβάθρον',\n",
       " 'πεποιημένηνandἔχον',\n",
       " 'cessation',\n",
       " 'busy',\n",
       " 'Bryas',\n",
       " 'behavior',\n",
       " 'bridegroom',\n",
       " 'escort',\n",
       " 'morning',\n",
       " 'cleobis',\n",
       " 'maenad',\n",
       " 'Timeas',\n",
       " 'Judgment',\n",
       " 'Alcenor',\n",
       " 'Othryadas',\n",
       " 'awful',\n",
       " 'valiantly',\n",
       " 'shameful',\n",
       " 'cheek',\n",
       " 'hdt',\n",
       " 'Cerdo',\n",
       " 'Fight',\n",
       " 'rational',\n",
       " 'Phorcus',\n",
       " 'Eucrates',\n",
       " 'kilIer',\n",
       " 'Pale',\n",
       " 'Arternis',\n",
       " 'pale',\n",
       " 'reliance',\n",
       " 'Haliae',\n",
       " 'Pelasgian',\n",
       " 'Mechaneus',\n",
       " 'swore',\n",
       " 'gainsay',\n",
       " 'constraint',\n",
       " 'Ilus',\n",
       " 'Flooder',\n",
       " 'inundate',\n",
       " 'assessor',\n",
       " 'Anaxis',\n",
       " 'PolycleitusIt',\n",
       " 'rivalry',\n",
       " 'Pania',\n",
       " 'refit',\n",
       " 'Xenophilus',\n",
       " 'Sphyrus',\n",
       " 'Sicyorians',\n",
       " 'Cestrine',\n",
       " 'Deiras',\n",
       " 'becomes',\n",
       " 'Oxyderces',\n",
       " 'Sharp',\n",
       " 'sighted',\n",
       " 'Underworld',\n",
       " 'Persephonea',\n",
       " 'Universe',\n",
       " 'tege',\n",
       " 'Lycone',\n",
       " 'cypresse',\n",
       " 'Steep',\n",
       " 'Chaon',\n",
       " 'Tyrbe',\n",
       " 'Throng',\n",
       " 'Wheel',\n",
       " 'Eurybotus',\n",
       " 'Gully',\n",
       " 'Agrius',\n",
       " 'Calydonia',\n",
       " 'Lyncea',\n",
       " 'ithom',\n",
       " 'Phliasia',\n",
       " 'Arachnaeus',\n",
       " 'wordsσάπυς',\n",
       " 'ἐλάτων',\n",
       " 'Myrtium',\n",
       " 'Aresthanas',\n",
       " 'unturned',\n",
       " 'coroni',\n",
       " 'Apollophanes',\n",
       " 'Pledge',\n",
       " 'Lovely',\n",
       " 'interpolator',\n",
       " 'Aristaechmus',\n",
       " 'sprain',\n",
       " 'Pindasus',\n",
       " 'Balagrae',\n",
       " 'Lebene',\n",
       " 'offerer',\n",
       " 'Arignotus',\n",
       " 'Pausias',\n",
       " 'freeman',\n",
       " 'unequalle',\n",
       " 'PolycleitusProbably',\n",
       " 'splendour',\n",
       " 'Cotys',\n",
       " 'Cynortium',\n",
       " 'appurtenance',\n",
       " 'reservoir',\n",
       " 'yellowish',\n",
       " 'parrot',\n",
       " 'Coryphum',\n",
       " 'Twisted',\n",
       " 'Top',\n",
       " 'Coryphaea',\n",
       " 'TelesillaA',\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "counts = Counter([t.lemma_ for t in pausanias_df['nlp_docs'].explode() if t.is_alpha])\n",
    "hapaxes = [h for (h, i) in counts.items() if i == 1]\n",
    "\n",
    "hapaxes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Discuss: Do you notice any potential issues in the list of hapaxes above? How should we report them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zipf's Law\n",
    "\n",
    "Using the `counts` that we calculated above, we can examine Zipf's law in the context of Pausanias. Zipf's law, to borrow Brezina's summary, \"tells us that when we start with the most frequent item in the wordlist (regardless of the size of the corpus), the second most frequent item will have only half of the frequency of the first item. The third most common word will have one-third of the frequency of the first item; and so on\" [@Brezina2018 44]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 26932), ('of', 14435), ('be', 12456)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.most_common(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The ratios aren't exact, but they're pretty close! Zipf's law might be easier to see if we visualize it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting altair[all]\n",
      "  Downloading altair-5.4.1-py3-none-any.whl.metadata (9.4 kB)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.11/site-packages (from altair[all]) (3.1.4)\n",
      "Requirement already satisfied: jsonschema>=3.0 in /opt/miniconda3/lib/python3.11/site-packages (from altair[all]) (4.19.2)\n",
      "Collecting narwhals>=1.5.2 (from altair[all])\n",
      "  Downloading narwhals-1.8.2-py3-none-any.whl.metadata (6.8 kB)\n",
      "Requirement already satisfied: packaging in /opt/miniconda3/lib/python3.11/site-packages (from altair[all]) (24.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /opt/miniconda3/lib/python3.11/site-packages (from altair[all]) (4.11.0)\n",
      "Collecting altair-tiles>=0.3.0 (from altair[all])\n",
      "  Downloading altair_tiles-0.3.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting anywidget>=0.9.0 (from altair[all])\n",
      "  Downloading anywidget-0.9.13-py3-none-any.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: numpy in /opt/miniconda3/lib/python3.11/site-packages (from altair[all]) (1.26.4)\n",
      "Requirement already satisfied: pandas>=0.25.3 in /opt/miniconda3/lib/python3.11/site-packages (from altair[all]) (2.2.2)\n",
      "Collecting pyarrow>=11 (from altair[all])\n",
      "  Downloading pyarrow-17.0.0-cp311-cp311-macosx_10_15_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting vega-datasets>=0.9.0 (from altair[all])\n",
      "  Downloading vega_datasets-0.9.0-py3-none-any.whl.metadata (5.5 kB)\n",
      "Collecting vegafusion>=1.6.6 (from vegafusion[embed]>=1.6.6; extra == \"all\"->altair[all])\n",
      "  Downloading vegafusion-1.6.9-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting vl-convert-python>=1.6.0 (from altair[all])\n",
      "  Downloading vl_convert_python-1.6.1-cp37-abi3-macosx_10_12_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting mercantile (from altair-tiles>=0.3.0->altair[all])\n",
      "  Downloading mercantile-1.2.1-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting xyzservices (from altair-tiles>=0.3.0->altair[all])\n",
      "  Downloading xyzservices-2024.9.0-py3-none-any.whl.metadata (4.1 kB)\n",
      "Collecting ipywidgets>=7.6.0 (from anywidget>=0.9.0->altair[all])\n",
      "  Downloading ipywidgets-8.1.5-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting psygnal>=0.8.1 (from anywidget>=0.9.0->altair[all])\n",
      "  Downloading psygnal-0.11.1-cp311-cp311-macosx_10_16_x86_64.whl.metadata (7.2 kB)\n",
      "Requirement already satisfied: attrs>=22.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair[all]) (23.1.0)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/miniconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair[all]) (2023.7.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/miniconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair[all]) (0.30.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/miniconda3/lib/python3.11/site-packages (from jsonschema>=3.0->altair[all]) (0.10.6)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.11/site-packages (from pandas>=0.25.3->altair[all]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.11/site-packages (from pandas>=0.25.3->altair[all]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.11/site-packages (from pandas>=0.25.3->altair[all]) (2024.1)\n",
      "Requirement already satisfied: psutil in /opt/miniconda3/lib/python3.11/site-packages (from vegafusion>=1.6.6->vegafusion[embed]>=1.6.6; extra == \"all\"->altair[all]) (5.9.0)\n",
      "Collecting protobuf (from vegafusion>=1.6.6->vegafusion[embed]>=1.6.6; extra == \"all\"->altair[all])\n",
      "  Downloading protobuf-5.28.2-cp38-abi3-macosx_10_9_universal2.whl.metadata (592 bytes)\n",
      "Collecting vegafusion-python-embed==1.6.9 (from vegafusion[embed]>=1.6.6; extra == \"all\"->altair[all])\n",
      "  Downloading vegafusion_python_embed-1.6.9-cp38-abi3-macosx_10_12_x86_64.whl.metadata (394 bytes)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.11/site-packages (from jinja2->altair[all]) (2.1.3)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/miniconda3/lib/python3.11/site-packages (from ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (0.2.1)\n",
      "Requirement already satisfied: ipython>=6.1.0 in /opt/miniconda3/lib/python3.11/site-packages (from ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (8.27.0)\n",
      "Requirement already satisfied: traitlets>=4.3.1 in /opt/miniconda3/lib/python3.11/site-packages (from ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (5.14.3)\n",
      "Collecting widgetsnbextension~=4.0.12 (from ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all])\n",
      "  Downloading widgetsnbextension-4.0.13-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting jupyterlab-widgets~=3.0.12 (from ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all])\n",
      "  Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/miniconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->altair[all]) (1.16.0)\n",
      "Requirement already satisfied: click>=3.0 in /opt/miniconda3/lib/python3.11/site-packages (from mercantile->altair-tiles>=0.3.0->altair[all]) (8.1.7)\n",
      "Requirement already satisfied: decorator in /opt/miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (5.1.1)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (0.19.1)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>=3.0.41 in /opt/miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (3.0.43)\n",
      "Requirement already satisfied: pygments>=2.4.0 in /opt/miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (2.15.1)\n",
      "Requirement already satisfied: stack-data in /opt/miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (0.2.0)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/miniconda3/lib/python3.11/site-packages (from ipython>=6.1.0->ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (4.8.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /opt/miniconda3/lib/python3.11/site-packages (from jedi>=0.16->ipython>=6.1.0->ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (0.8.3)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/miniconda3/lib/python3.11/site-packages (from pexpect>4.3->ipython>=6.1.0->ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (0.7.0)\n",
      "Requirement already satisfied: wcwidth in /opt/miniconda3/lib/python3.11/site-packages (from prompt-toolkit<3.1.0,>=3.0.41->ipython>=6.1.0->ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (0.2.5)\n",
      "Requirement already satisfied: executing in /opt/miniconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (0.8.3)\n",
      "Requirement already satisfied: asttokens in /opt/miniconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (2.0.5)\n",
      "Requirement already satisfied: pure-eval in /opt/miniconda3/lib/python3.11/site-packages (from stack-data->ipython>=6.1.0->ipywidgets>=7.6.0->anywidget>=0.9.0->altair[all]) (0.2.2)\n",
      "Downloading altair_tiles-0.3.0-py3-none-any.whl (8.7 kB)\n",
      "Downloading anywidget-0.9.13-py3-none-any.whl (213 kB)\n",
      "Downloading narwhals-1.8.2-py3-none-any.whl (167 kB)\n",
      "Downloading pyarrow-17.0.0-cp311-cp311-macosx_10_15_x86_64.whl (29.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.0/29.0 MB\u001b[0m \u001b[31m29.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading vega_datasets-0.9.0-py3-none-any.whl (210 kB)\n",
      "Downloading vegafusion-1.6.9-py3-none-any.whl (54 kB)\n",
      "Downloading altair-5.4.1-py3-none-any.whl (658 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m658.1/658.1 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading vegafusion_python_embed-1.6.9-cp38-abi3-macosx_10_12_x86_64.whl (20.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading vl_convert_python-1.6.1-cp37-abi3-macosx_10_12_x86_64.whl (27.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.5/27.5 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading ipywidgets-8.1.5-py3-none-any.whl (139 kB)\n",
      "Downloading psygnal-0.11.1-cp311-cp311-macosx_10_16_x86_64.whl (453 kB)\n",
      "Downloading mercantile-1.2.1-py3-none-any.whl (14 kB)\n",
      "Downloading protobuf-5.28.2-cp38-abi3-macosx_10_9_universal2.whl (414 kB)\n",
      "Downloading xyzservices-2024.9.0-py3-none-any.whl (85 kB)\n",
      "Downloading jupyterlab_widgets-3.0.13-py3-none-any.whl (214 kB)\n",
      "Downloading widgetsnbextension-4.0.13-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: vegafusion-python-embed, xyzservices, widgetsnbextension, vl-convert-python, pyarrow, psygnal, protobuf, narwhals, mercantile, jupyterlab-widgets, vega-datasets, ipywidgets, altair, vegafusion, anywidget, altair-tiles\n",
      "Successfully installed altair-5.4.1 altair-tiles-0.3.0 anywidget-0.9.13 ipywidgets-8.1.5 jupyterlab-widgets-3.0.13 mercantile-1.2.1 narwhals-1.8.2 protobuf-5.28.2 psygnal-0.11.1 pyarrow-17.0.0 vega-datasets-0.9.0 vegafusion-1.6.9 vegafusion-python-embed-1.6.9 vl-convert-python-1.6.1 widgetsnbextension-4.0.13 xyzservices-2024.9.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install \"altair[all]\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "  #altair-viz-ee8dfc2781aa404b8361bc842db022e5.vega-embed {\n",
       "    width: 100%;\n",
       "    display: flex;\n",
       "  }\n",
       "\n",
       "  #altair-viz-ee8dfc2781aa404b8361bc842db022e5.vega-embed details,\n",
       "  #altair-viz-ee8dfc2781aa404b8361bc842db022e5.vega-embed details summary {\n",
       "    position: relative;\n",
       "  }\n",
       "</style>\n",
       "<div id=\"altair-viz-ee8dfc2781aa404b8361bc842db022e5\"></div>\n",
       "<script type=\"text/javascript\">\n",
       "  var VEGA_DEBUG = (typeof VEGA_DEBUG == \"undefined\") ? {} : VEGA_DEBUG;\n",
       "  (function(spec, embedOpt){\n",
       "    let outputDiv = document.currentScript.previousElementSibling;\n",
       "    if (outputDiv.id !== \"altair-viz-ee8dfc2781aa404b8361bc842db022e5\") {\n",
       "      outputDiv = document.getElementById(\"altair-viz-ee8dfc2781aa404b8361bc842db022e5\");\n",
       "    }\n",
       "    const paths = {\n",
       "      \"vega\": \"https://cdn.jsdelivr.net/npm/vega@5?noext\",\n",
       "      \"vega-lib\": \"https://cdn.jsdelivr.net/npm/vega-lib?noext\",\n",
       "      \"vega-lite\": \"https://cdn.jsdelivr.net/npm/vega-lite@5.20.1?noext\",\n",
       "      \"vega-embed\": \"https://cdn.jsdelivr.net/npm/vega-embed@6?noext\",\n",
       "    };\n",
       "\n",
       "    function maybeLoadScript(lib, version) {\n",
       "      var key = `${lib.replace(\"-\", \"\")}_version`;\n",
       "      return (VEGA_DEBUG[key] == version) ?\n",
       "        Promise.resolve(paths[lib]) :\n",
       "        new Promise(function(resolve, reject) {\n",
       "          var s = document.createElement('script');\n",
       "          document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
       "          s.async = true;\n",
       "          s.onload = () => {\n",
       "            VEGA_DEBUG[key] = version;\n",
       "            return resolve(paths[lib]);\n",
       "          };\n",
       "          s.onerror = () => reject(`Error loading script: ${paths[lib]}`);\n",
       "          s.src = paths[lib];\n",
       "        });\n",
       "    }\n",
       "\n",
       "    function showError(err) {\n",
       "      outputDiv.innerHTML = `<div class=\"error\" style=\"color:red;\">${err}</div>`;\n",
       "      throw err;\n",
       "    }\n",
       "\n",
       "    function displayChart(vegaEmbed) {\n",
       "      vegaEmbed(outputDiv, spec, embedOpt)\n",
       "        .catch(err => showError(`Javascript Error: ${err.message}<br>This usually means there's a typo in your chart specification. See the javascript console for the full traceback.`));\n",
       "    }\n",
       "\n",
       "    if(typeof define === \"function\" && define.amd) {\n",
       "      requirejs.config({paths});\n",
       "      require([\"vega-embed\"], displayChart, err => showError(`Error loading script: ${err.message}`));\n",
       "    } else {\n",
       "      maybeLoadScript(\"vega\", \"5\")\n",
       "        .then(() => maybeLoadScript(\"vega-lite\", \"5.20.1\"))\n",
       "        .then(() => maybeLoadScript(\"vega-embed\", \"6\"))\n",
       "        .catch(showError)\n",
       "        .then(() => displayChart(vegaEmbed));\n",
       "    }\n",
       "  })({\"config\": {\"view\": {\"continuousWidth\": 300, \"continuousHeight\": 300}}, \"data\": {\"name\": \"data-e58f7dca115f1f7a10c8a7d80b2b1527\"}, \"mark\": {\"type\": \"point\"}, \"encoding\": {\"x\": {\"field\": \"rank\", \"type\": \"quantitative\"}, \"y\": {\"field\": \"frequency\", \"type\": \"quantitative\"}}, \"$schema\": \"https://vega.github.io/schema/vega-lite/v5.20.1.json\", \"datasets\": {\"data-e58f7dca115f1f7a10c8a7d80b2b1527\": [{\"lemma\": \"the\", \"frequency\": 26932, \"rank\": 0}, {\"lemma\": \"of\", \"frequency\": 14435, \"rank\": 1}, {\"lemma\": \"be\", \"frequency\": 12456, \"rank\": 2}, {\"lemma\": \"and\", \"frequency\": 8547, \"rank\": 3}, {\"lemma\": \"to\", \"frequency\": 7510, \"rank\": 4}, {\"lemma\": \"a\", \"frequency\": 5881, \"rank\": 5}, {\"lemma\": \"in\", \"frequency\": 4931, \"rank\": 6}, {\"lemma\": \"they\", \"frequency\": 3842, \"rank\": 7}, {\"lemma\": \"that\", \"frequency\": 3457, \"rank\": 8}, {\"lemma\": \"he\", \"frequency\": 3010, \"rank\": 9}, {\"lemma\": \"by\", \"frequency\": 2916, \"rank\": 10}, {\"lemma\": \"have\", \"frequency\": 2590, \"rank\": 11}, {\"lemma\": \"on\", \"frequency\": 2314, \"rank\": 12}, {\"lemma\": \"it\", \"frequency\": 2310, \"rank\": 13}, {\"lemma\": \"from\", \"frequency\": 2283, \"rank\": 14}, {\"lemma\": \"at\", \"frequency\": 2068, \"rank\": 15}, {\"lemma\": \"his\", \"frequency\": 2052, \"rank\": 16}, {\"lemma\": \"for\", \"frequency\": 2034, \"rank\": 17}, {\"lemma\": \"with\", \"frequency\": 1862, \"rank\": 18}, {\"lemma\": \"but\", \"frequency\": 1797, \"rank\": 19}, {\"lemma\": \"as\", \"frequency\": 1639, \"rank\": 20}, {\"lemma\": \"this\", \"frequency\": 1620, \"rank\": 21}, {\"lemma\": \"who\", \"frequency\": 1611, \"rank\": 22}, {\"lemma\": \"son\", \"frequency\": 1591, \"rank\": 23}, {\"lemma\": \"their\", \"frequency\": 1587, \"rank\": 24}, {\"lemma\": \"say\", \"frequency\": 1523, \"rank\": 25}, {\"lemma\": \"not\", \"frequency\": 1303, \"rank\": 26}, {\"lemma\": \"when\", \"frequency\": 1149, \"rank\": 27}, {\"lemma\": \"call\", \"frequency\": 1108, \"rank\": 28}, {\"lemma\": \"there\", \"frequency\": 1088, \"rank\": 29}, {\"lemma\": \"which\", \"frequency\": 1076, \"rank\": 30}, {\"lemma\": \"I\", \"frequency\": 1039, \"rank\": 31}, {\"lemma\": \"an\", \"frequency\": 982, \"rank\": 32}, {\"lemma\": \"make\", \"frequency\": 959, \"rank\": 33}, {\"lemma\": \"also\", \"frequency\": 906, \"rank\": 34}, {\"lemma\": \"one\", \"frequency\": 853, \"rank\": 35}, {\"lemma\": \"after\", \"frequency\": 804, \"rank\": 36}, {\"lemma\": \"man\", \"frequency\": 782, \"rank\": 37}, {\"lemma\": \"image\", \"frequency\": 753, \"rank\": 38}, {\"lemma\": \"city\", \"frequency\": 753, \"rank\": 39}, {\"lemma\": \"other\", \"frequency\": 747, \"rank\": 40}, {\"lemma\": \"name\", \"frequency\": 733, \"rank\": 41}, {\"lemma\": \"sanctuary\", \"frequency\": 719, \"rank\": 42}, {\"lemma\": \"come\", \"frequency\": 697, \"rank\": 43}, {\"lemma\": \"all\", \"frequency\": 677, \"rank\": 44}, {\"lemma\": \"so\", \"frequency\": 636, \"rank\": 45}, {\"lemma\": \"she\", \"frequency\": 581, \"rank\": 46}, {\"lemma\": \"give\", \"frequency\": 568, \"rank\": 47}, {\"lemma\": \"time\", \"frequency\": 526, \"rank\": 48}, {\"lemma\": \"take\", \"frequency\": 525, \"rank\": 49}, {\"lemma\": \"no\", \"frequency\": 522, \"rank\": 50}, {\"lemma\": \"temple\", \"frequency\": 501, \"rank\": 51}, {\"lemma\": \"place\", \"frequency\": 497, \"rank\": 52}, {\"lemma\": \"into\", \"frequency\": 484, \"rank\": 53}, {\"lemma\": \"statue\", \"frequency\": 483, \"rank\": 54}, {\"lemma\": \"about\", \"frequency\": 479, \"rank\": 55}, {\"lemma\": \"these\", \"frequency\": 469, \"rank\": 56}, {\"lemma\": \"here\", \"frequency\": 467, \"rank\": 57}, {\"lemma\": \"Lacedaemonians\", \"frequency\": 460, \"rank\": 58}, {\"lemma\": \"up\", \"frequency\": 459, \"rank\": 59}, {\"lemma\": \"those\", \"frequency\": 453, \"rank\": 60}, {\"lemma\": \"first\", \"frequency\": 453, \"rank\": 61}, {\"lemma\": \"god\", \"frequency\": 448, \"rank\": 62}, {\"lemma\": \"do\", \"frequency\": 442, \"rank\": 63}, {\"lemma\": \"see\", \"frequency\": 441, \"rank\": 64}, {\"lemma\": \"against\", \"frequency\": 440, \"rank\": 65}, {\"lemma\": \"daughter\", \"frequency\": 407, \"rank\": 66}, {\"lemma\": \"her\", \"frequency\": 400, \"rank\": 67}, {\"lemma\": \"its\", \"frequency\": 393, \"rank\": 68}, {\"lemma\": \"land\", \"frequency\": 391, \"rank\": 69}, {\"lemma\": \"Zeus\", \"frequency\": 391, \"rank\": 70}, {\"lemma\": \"go\", \"frequency\": 390, \"rank\": 71}, {\"lemma\": \"you\", \"frequency\": 373, \"rank\": 72}, {\"lemma\": \"before\", \"frequency\": 371, \"rank\": 73}, {\"lemma\": \"war\", \"frequency\": 368, \"rank\": 74}, {\"lemma\": \"Apollo\", \"frequency\": 366, \"rank\": 75}, {\"lemma\": \"because\", \"frequency\": 364, \"rank\": 76}, {\"lemma\": \"too\", \"frequency\": 361, \"rank\": 77}, {\"lemma\": \"Athenians\", \"frequency\": 357, \"rank\": 78}, {\"lemma\": \"most\", \"frequency\": 352, \"rank\": 79}, {\"lemma\": \"or\", \"frequency\": 351, \"rank\": 80}, {\"lemma\": \"king\", \"frequency\": 344, \"rank\": 81}, {\"lemma\": \"out\", \"frequency\": 341, \"rank\": 82}, {\"lemma\": \"two\", \"frequency\": 335, \"rank\": 83}, {\"lemma\": \"part\", \"frequency\": 334, \"rank\": 84}, {\"lemma\": \"people\", \"frequency\": 333, \"rank\": 85}, {\"lemma\": \"hold\", \"frequency\": 327, \"rank\": 86}, {\"lemma\": \"river\", \"frequency\": 327, \"rank\": 87}, {\"lemma\": \"my\", \"frequency\": 324, \"rank\": 88}, {\"lemma\": \"some\", \"frequency\": 323, \"rank\": 89}, {\"lemma\": \"win\", \"frequency\": 318, \"rank\": 90}, {\"lemma\": \"bring\", \"frequency\": 313, \"rank\": 91}, {\"lemma\": \"stand\", \"frequency\": 312, \"rank\": 92}, {\"lemma\": \"Heracles\", \"frequency\": 310, \"rank\": 93}, {\"lemma\": \"dedicate\", \"frequency\": 308, \"rank\": 94}, {\"lemma\": \"while\", \"frequency\": 303, \"rank\": 95}, {\"lemma\": \"among\", \"frequency\": 298, \"rank\": 96}, {\"lemma\": \"great\", \"frequency\": 297, \"rank\": 97}, {\"lemma\": \"day\", \"frequency\": 297, \"rank\": 98}, {\"lemma\": \"Greeks\", \"frequency\": 293, \"rank\": 99}]}}, {\"mode\": \"vega-lite\"});\n",
       "</script>"
      ],
      "text/plain": [
       "alt.Chart(...)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import altair as alt\n",
    "\n",
    "top_5000_words = counts.most_common(100)\n",
    "\n",
    "top_5000_words.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "zipfs_df = pd.DataFrame([{'lemma': h, 'frequency': i, 'rank': idx} for idx, (h, i) in enumerate(top_5000_words)])\n",
    "\n",
    "chart = alt.Chart(zipfs_df)\n",
    "\n",
    "chart.mark_point().encode(x='rank', y='frequency')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the rapid decrease in frequencies maps nicely on the Zipf's law visualization at @Brezina2018 [45].\n",
    "\n",
    "> In-class exercise: We can see the visualization well enough here, but how can we improve this chart? Use the [Altair documentation](https://altair-viz.github.io/index.html) to make the chart more readable. As a bonus, see if you can figure out how to show the lemma for each rank when you hover over the point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dispersion\n",
    "\n",
    "> Discuss: In your own words, describe the so-called \"whelk problem\" [@Brezina2018 46--47]. Who coined the phrase, and why?\n",
    "\n",
    "> Generally, dispersion tells us about the distribution of words or phrases throughout the corpus. For example, the definite article the is not only a highly frequent word, it also is fairly evenly distributed in text. This is because the is a grammatical word and we usually cannot put sentences together without using it. Other words which are specific to a particular context (e.g. whelk, hashtag, corpus) will be less evenly distributed. [@Brezina2018 47]\n",
    "\n",
    "### Range<sub>2</sub> (R)\n",
    "\n",
    "Range<sub>2</sub> simply tells us in how many parts of a corpus a given word appears, regardless of the size of each part. It can also be expressed as a percentage, e.g., if a word appears in 8 out of 10 books of Pausanias, it would have an _R_ value of 8/10 or 80%.\n",
    "\n",
    "> In-class exercise: Divide the quotation above into sentences and determine the R<sub>2</sub> dispersion of forms of the word \"be\". Bonus: do the same, but divide the quotation into five-word chunks (you should have one one-word chunk)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# note: typically you will want to use a lemmatizer, but as we are working with sample data, we can \n",
    "# just create a tuple of forms to work with here\n",
    "forms_of_be = (\"be\", \"am\", \"are\", \"is\", \"was\", \"were\", \"been\") \n",
    "\n",
    "quotation = \"\"\"\n",
    "Generally, dispersion tells us about the distribution of words or phrases throughout the corpus. \n",
    "For example, the definite article the is not only a highly frequent word, it also is fairly evenly distributed in text. \n",
    "This is because the is a grammatical word and we usually cannot put sentences together without using it. \n",
    "Other words which are specific to a particular context (e.g. whelk, hashtag, corpus) will be less evenly distributed.\n",
    "\"\"\"\n",
    "\n",
    "# Your code below. Helpful built-in functions: str.split(), str.splitlines().\n",
    "\n",
    "quotation_sents = [l.split() for l in quotation.splitlines() if l != \"\"]\n",
    "\n",
    "#\"l.split\" splints string into list\n",
    "\n",
    "#if l != \"\" gets rid of the empty line at the top of the quote\n",
    "quotation_r_2 = sum([1 for l in quotation_sents if len(set(l).intersection(forms_of_be)) > 0]) /len(quotation_sents)\n",
    "\n",
    "#set is like a list, but item only appears once\n",
    "#set is way to see unique things in list\n",
    "#set(l) gives unique lists in list l\n",
    "#intersection compares forms_of_be to list l and shows the onces they have in common\n",
    "#we do 1 for l to show its presence or not, then we can add up all the 1s to figure out how many intersect, with sum()\n",
    "#then we find the range by dividing by the number of sentences with len(quotation_sents)\n",
    "\n",
    "quotation_r_2\n",
    "#we are calculating # of parts with a form of be divided by the number of parts\n",
    "\n",
    "\n",
    "##bonus, didn't finish in class\n",
    "\n",
    "# quoation_chunks = [quoatation.split()i:i+5] for i in range(0, len)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Deviation\n",
    "\n",
    "The **standard deviation** (σ) attempts to answer how much variation around the mean occurs in the data. You've probably seen this measurement of dispersion outside of corpus linguistics, but here it can show, for example, variation in the relative frequency of a word in different parts of a corpus.\n",
    "\n",
    "Standard deviation is expressed mathematically as `sqrt(sum of squared distances from the mean / total # of corpus parts)`.'\n",
    "\n",
    "> Discuss: Why do we square the differences from the mean if we're also going to take the square root of the ratio?\n",
    "\n",
    "#### Sample standard deviation\n",
    "\n",
    "Sample standard deviation differs from standard deviation (σ) only in the divisor, which is here `total # of corpus parts - 1`.\n",
    "\n",
    "> In-class exercise: calculate the standard deviation and the sample standard deviation of the relative frequency of forms of \"be\" in the quotation from Brezina."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 4.2, 3.6, 3.6]\n",
      "2.85\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(samples) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(samples)\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28msum\u001b[39m[(n\u001b[38;5;241m-\u001b[39mmean \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m samples)]) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(samples \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 25\u001b[0m std_dev_be \u001b[38;5;241m=\u001b[39m std_dev(rel_freqs_be)\n\u001b[1;32m     27\u001b[0m sample_std_dev_be \u001b[38;5;241m=\u001b[39m sample_std_dev(rel_freqs_be)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mσ = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mstd_dev_be\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m | SD = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msample_std_dev_be\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[33], line 19\u001b[0m, in \u001b[0;36mstd_dev\u001b[0;34m(samples)\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstd_dev\u001b[39m(samples):\n\u001b[1;32m     17\u001b[0m     mean \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msum\u001b[39m(samples) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(samples)\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m math\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;28msum\u001b[39m([n\u001b[38;5;241m-\u001b[39mmean \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m samples])) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(samples)\n",
      "\u001b[0;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "# Your code here\n",
    "\n",
    "rel_freqs_be = []\n",
    "\n",
    "for line in quotation_sents:\n",
    "    n_be = len([t for t in line if t in forms_of_be])\n",
    "    rel_freqs_be.append((n_be * len(line)) /10 )\n",
    "print(rel_freqs_be)\n",
    "\n",
    "average_be_per_10_tokens = sum(rel_freqs_be) / len(rel_freqs_be)\n",
    "\n",
    "print (average_be_per_10_tokens)\n",
    "\n",
    "import math\n",
    "\n",
    "def std_dev(samples):\n",
    "    mean = sum(samples) / len(samples)\n",
    "\n",
    "    return math.sqrt(sum([n-mean ** 2 for n in samples])) / len(samples)\n",
    "\n",
    "def sample_std_dev(samples):\n",
    "    mean = sum(samples) / len(samples)\n",
    "\n",
    "    return math.sqrt(sum[(n-mean ** 2 for n in samples)]) / len(samples -1)\n",
    "std_dev_be = std_dev(rel_freqs_be)\n",
    "\n",
    "sample_std_dev_be = sample_std_dev(rel_freqs_be)\n",
    "\n",
    "print(f\"σ = {std_dev_be} | SD = {sample_std_dev_be}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Coefficient of Variation (CV)\n",
    "\n",
    "\"The coefficient of variation (CV) describes the amount of variation relative to the mean relative frequency of a word or phrase in the corpus\" [@Brezina2018 50].\n",
    "\n",
    "We calculate the coefficient of variation by dividing the standard deviation by the mean: `CV = std. deviation / mean`.\n",
    "\n",
    "> In-class exercise: What is the coefficient of variation for forms of the word \"be\" in the quotation from Brezina when dividing by sentence?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "cv_brezina_quotation = \"?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Juilland's _D_\n",
    "\n",
    "> Juilland’s _D_ is a measure of dispersion that builds on the coefficient of variation. It is a number between 0 and 1, with 0 signifying extremely uneven distribution and 1 perfectly even distribution. [@Brezina2018 51]\n",
    "\n",
    "You can think of Juilland's _D_ as the inverse of the coefficient of variation: \"While CV tells us about the amount of variation in the corpus (larger CV means more variation in the frequencies), Juilland’s D tells us about homogeneity of the distribution (larger Juilland’s D means a more even distribution and less variation)\" [@Brezina2018 51].\n",
    "\n",
    "Juilland's _D_ is calculated by `CV / sqrt(# corpus parts - 1)`.\n",
    "\n",
    "> In-class exercise: What is the Juilland's _D_ for forms of the word \"be\" in the quotation from Brezina (split into sentences)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "j_d_brezina_quotation = \"?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deviation of Proportions (DP)\n",
    "\n",
    "**Deviation of Proportions** is similar to Juilland's _D_ insofar as it measures dispersion in a corpus; but it uses the reverse scale, where 0 indicates perfectly even dispersion and 1 indicates an extremely uneven distribution.\n",
    "\n",
    "It is calculated by taking the `sum(| observed - expected proportions |) / 2`.\n",
    "\n",
    "The `expected proportions` are calculated by dividing the sizes of each corpus part (in tokens) divided by the total size of the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "brezina_sents = [l.strip().split(\" \") for l in quotation.splitlines() if l != \"\"]\n",
    "total_brezina_tokens = sum(len(s) for s in brezina_sents)\n",
    "expected_proportions = [len(s) / total_brezina_tokens for s in brezina_sents] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `observed proportions` are then calculated by taking the absolute frequency of a token in each part divided by the absolute frequency of the token in the whole corpus.\n",
    "\n",
    "Calculate the DP for the Brezina quotation below, using the `expected_proportions` provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "\n",
    "dp_brezina_quotation = \"?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Average Reduced Frequency (ARF)\n",
    "\n",
    "The key idea behind **Average Reduced Frequency** is that we can discard occurrences of a word that are close together to get a better picture of the word's significance to the corpus as a whole.\n",
    "\n",
    "**ARF** is calculated as follows (in pseudo-code):\n",
    "\n",
    "```\n",
    "w = word\n",
    "v = total corpus tokens / absolute frequency of w\n",
    "\n",
    "ARF = 1/v * (min(distance_1, v) + min(distance_2, v) + ... min(distance_n, v))\n",
    "```\n",
    "\n",
    "If we think of the corpus as a circle rather than a line, we can imagine repeating the `min(distance, v)` procedure for every occurrence of `w`, wrapping around the text at the end.\n",
    "\n",
    "ARF, in other words, is a \"reduction\" of the word's frequency that based on the dispersion of its occurrences throughout the corpus. [@Brezina2018 53--57]\n",
    "\n",
    "> Discuss: How can ARF be used to address the whelk problem mentioned above?\n",
    "\n",
    "## Lexical Diversity\n",
    "\n",
    "Lexical diversity helps us measure whether a corpus uses a wide or limited range of vocabulary.\n",
    "\n",
    "### Type/Token Ratio (TTR)\n",
    "\n",
    "One of the simplest ways to calculate lexical diversity is the **type/token ration (TTR)**. This calculation is driven by the intuition that a corpus with a relatively high number of word forms (types) compared to total words (tokens) exhibits a wider range of expression than a corpus of the same size with a lower number of types.\n",
    "\n",
    "```\n",
    "TTR = no. types / no. tokens\n",
    "```\n",
    "\n",
    "> In-class exercise: Calculate the TTR for the Brezina quotation. You will need to use the SpaCy lemmatizer.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages/thinc/shims/pytorch.py:114: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(self._mixed_precision):\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "eng_nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(quotation)\n",
    "\n",
    "brezina_ttr = \"?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Discuss: What problems emerge from this simple TTR calculation?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standardized Type/Token Ratio (STTR)\n",
    "\n",
    "As its name implies, **Standardized Type/Token Ratio (STTR)** divides the text into standardized chunks of, e.g., 1000 tokens, discarding the last chunk. It then calculates the TTR for each chunk and reports the mean of all chunks' TTRs.\n",
    "\n",
    "### Moving Average Type/Token Ratio (MATTR)\n",
    "\n",
    "Similarly, **Moving Average Type/Token Ratio (MATTR)** calculates the mean of multiple TTRs as a _moving average_ (i.e., an overlapping window) of chunks through the corpus.\n",
    "\n",
    "> Discuss: How does Brezina's \"transformation of Zipf's law to express rank\" [-@Brezina2018 60] work? How can we use it for Pausanias?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "1. Find a word that appears no more than 20 times in all of Pausanias, and calculate it's R<sub>2</sub> for Pausanias' text when divided by book.\n",
    "2. Find the standard deviation of the relative frequencies of forms of ποιέω in the books of Pausanias.\n",
    "3. Calculate the deviation of proportions for a word of your choosing in the books of Pausanias.\n",
    "4. Calculate the TTR for each book of Pausanias, and for Pausanias as a whole.\n",
    "5. Calculate the MATTR of Pausanias using a sliding window of 5000 tokens."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
