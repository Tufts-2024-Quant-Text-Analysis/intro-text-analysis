{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.2)\n",
      "Requirement already satisfied: jinja2 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (75.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.4)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /workspaces/intro-text-analysis/.conda/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "Installing collected packages: en-core-web-sm\n",
      "Successfully installed en-core-web-sm-3.7.1\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "%run -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2548/1165739777.py:51: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  homer_son_lines['unannotated_tokens'] = homer_son_lines[\"unannotated_strings\"].str.replace('\"', '', regex=False).str.split()\n",
      "/tmp/ipykernel_2548/1165739777.py:52: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  homer_son_lines['son_count'] = homer_son_lines['unannotated_tokens'].apply(lambda x: sum([1 for y in x if y == 'son']))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urn</th>\n",
       "      <th>raw_xml</th>\n",
       "      <th>unannotated_strings</th>\n",
       "      <th>nlp_docs</th>\n",
       "      <th>unannotated_tokens</th>\n",
       "      <th>son_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:1.1</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>tell me, o muse, of that many-sided hero who\n",
       " ...</td>\n",
       "      <td>(Tell, me, ,, O, Muse, ,, of, that, many, -, s...</td>\n",
       "      <td>[tell, me,, o, muse,, of, that, many-sided, he...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:1.44</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>then athena said, \"father, son of kronos, king...</td>\n",
       "      <td>(Then, Athena, said, ,, \", Father, ,, son, of,...</td>\n",
       "      <td>[then, athena, said,, father,, son, of, kronos...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:1...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>\"i hope, sir,\" said he, \"that you will not be\n",
       "...</td>\n",
       "      <td>(\", I, hope, ,, sir, ,, \", said, he, ,, \", tha...</td>\n",
       "      <td>[i, hope,, sir,, said, he,, that, you, will, n...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:1...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>\"sir,\" said telemakhos, \"as regards your\n",
       "     ...</td>\n",
       "      <td>(\", Sir, ,, \", said, Telemakhos, ,, \", as, reg...</td>\n",
       "      <td>[sir,, said, telemakhos,, as, regards, your, q...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:1...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>athena answered, \"do not try to keep me, for i...</td>\n",
       "      <td>(Athena, answered, ,, \", Do, not, try, to, kee...</td>\n",
       "      <td>[athena, answered,, do, not, try, to, keep, me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>261</th>\n",
       "      <td>urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:2...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>laertes answered, \"would, by\n",
       "                 ...</td>\n",
       "      <td>(Laertes, answered, ,, \", Would, ,, by, \\n    ...</td>\n",
       "      <td>[laertes, answered,, would,, by, father, zeus,...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:2...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>while they were thus busy getting their dinner...</td>\n",
       "      <td>(While, they, were, thus, busy, getting, their...</td>\n",
       "      <td>[while, they, were, thus, busy, getting, their...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:2...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>this was what he said, and more than half\n",
       "    ...</td>\n",
       "      <td>(This, was, what, he, said, ,, and, more, than...</td>\n",
       "      <td>[this, was, what, he, said,, and, more, than, ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>264</th>\n",
       "      <td>urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:2...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>now when laertes and the others had done dinne...</td>\n",
       "      <td>(Now, when, Laertes, and, the, others, had, do...</td>\n",
       "      <td>[now, when, laertes, and, the, others, had, do...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>265</th>\n",
       "      <td>urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:2...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>laertes was delighted when he\n",
       "                ...</td>\n",
       "      <td>(Laertes, was, delighted, when, he, \\n        ...</td>\n",
       "      <td>[laertes, was, delighted, when, he, heard, thi...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>180 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   urn  \\\n",
       "0     urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:1.1   \n",
       "1    urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:1.44   \n",
       "3    urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:1...   \n",
       "4    urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:1...   \n",
       "5    urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:1...   \n",
       "..                                                 ...   \n",
       "261  urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:2...   \n",
       "262  urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:2...   \n",
       "263  urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:2...   \n",
       "264  urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:2...   \n",
       "265  urn:cts:greekLit:tlg0012.tlg002.perseus-eng4:2...   \n",
       "\n",
       "                                               raw_xml  \\\n",
       "0    <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1    <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "3    <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "4    <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "5    <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "..                                                 ...   \n",
       "261  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "262  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "263  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "264  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "265  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "\n",
       "                                   unannotated_strings  \\\n",
       "0    tell me, o muse, of that many-sided hero who\n",
       " ...   \n",
       "1    then athena said, \"father, son of kronos, king...   \n",
       "3    \"i hope, sir,\" said he, \"that you will not be\n",
       "...   \n",
       "4    \"sir,\" said telemakhos, \"as regards your\n",
       "     ...   \n",
       "5    athena answered, \"do not try to keep me, for i...   \n",
       "..                                                 ...   \n",
       "261  laertes answered, \"would, by\n",
       "                 ...   \n",
       "262  while they were thus busy getting their dinner...   \n",
       "263  this was what he said, and more than half\n",
       "    ...   \n",
       "264  now when laertes and the others had done dinne...   \n",
       "265  laertes was delighted when he\n",
       "                ...   \n",
       "\n",
       "                                              nlp_docs  \\\n",
       "0    (Tell, me, ,, O, Muse, ,, of, that, many, -, s...   \n",
       "1    (Then, Athena, said, ,, \", Father, ,, son, of,...   \n",
       "3    (\", I, hope, ,, sir, ,, \", said, he, ,, \", tha...   \n",
       "4    (\", Sir, ,, \", said, Telemakhos, ,, \", as, reg...   \n",
       "5    (Athena, answered, ,, \", Do, not, try, to, kee...   \n",
       "..                                                 ...   \n",
       "261  (Laertes, answered, ,, \", Would, ,, by, \\n    ...   \n",
       "262  (While, they, were, thus, busy, getting, their...   \n",
       "263  (This, was, what, he, said, ,, and, more, than...   \n",
       "264  (Now, when, Laertes, and, the, others, had, do...   \n",
       "265  (Laertes, was, delighted, when, he, \\n        ...   \n",
       "\n",
       "                                    unannotated_tokens  son_count  \n",
       "0    [tell, me,, o, muse,, of, that, many-sided, he...          1  \n",
       "1    [then, athena, said,, father,, son, of, kronos...          4  \n",
       "3    [i, hope,, sir,, said, he,, that, you, will, n...          4  \n",
       "4    [sir,, said, telemakhos,, as, regards, your, q...          1  \n",
       "5    [athena, answered,, do, not, try, to, keep, me...          0  \n",
       "..                                                 ...        ...  \n",
       "261  [laertes, answered,, would,, by, father, zeus,...          0  \n",
       "262  [while, they, were, thus, busy, getting, their...          2  \n",
       "263  [this, was, what, he, said,, and, more, than, ...          1  \n",
       "264  [now, when, laertes, and, the, others, had, do...          1  \n",
       "265  [laertes, was, delighted, when, he, heard, thi...          5  \n",
       "\n",
       "[180 rows x 6 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from MyCapytain.resources.texts.local.capitains.cts import CapitainsCtsText\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])\n",
    "\n",
    "with open(\"tlg0012.tlg002.perseus-eng4.xml\") as f:\n",
    "    text_2 = CapitainsCtsText(urn=\"urn:cts:greekLit:tlg0012.tlg002.perseus-eng4\", resource=f)\n",
    "\n",
    "from lxml import etree\n",
    "from MyCapytain.common.constants import Mimetypes\n",
    "\n",
    "urns = []\n",
    "raw_xmls = []\n",
    "unannotated_strings = []\n",
    "\n",
    "for ref in text_2.getReffs(level=len(text_2.citation)):\n",
    "    urn = f\"{text_2.urn}:{ref}\"\n",
    "    node = text_2.getTextualNode(ref)\n",
    "    raw_xml = node.export(Mimetypes.XML.TEI)\n",
    "    tree = node.export(Mimetypes.PYTHON.ETREE)\n",
    "    s = etree.tostring(tree, encoding=\"unicode\", method=\"text\")\n",
    "\n",
    "    urns.append(urn)\n",
    "    raw_xmls.append(raw_xml)\n",
    "    unannotated_strings.append(s)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "d_2 = {\n",
    "    \"urn\": pd.Series(urns, dtype=\"string\"),\n",
    "    \"raw_xml\": raw_xmls,\n",
    "    \"unannotated_strings\": pd.Series(unannotated_strings, dtype=\"string\")\n",
    "}\n",
    "homer_df = pd.DataFrame(d_2)\n",
    "\n",
    "raw_texts = [t for t in homer_df['unannotated_strings']]\n",
    "\n",
    "annotated_texts = nlp.pipe(raw_texts, batch_size=100)\n",
    "\n",
    "# we want to count Son and son in our son count, lowering cases of all unannotated_strings does that\n",
    "homer_df['unannotated_strings'] = homer_df['unannotated_strings'].str.lower()\n",
    "\n",
    "homer_df['nlp_docs'] = list(annotated_texts)\n",
    "\n",
    "n_son_homer = [t for t in homer_df['nlp_docs'].explode() if t.lemma_ == \"son\"]\n",
    "#print(n_son_homer)\n",
    "#homer_son_lines['son_count'] = [t for t in homer_son_lines['nlp_docs'].explode() if t.lemma_ == \"son\"]\n",
    "# transform unannotated strings to all lowercase\n",
    "\n",
    "homer_son_lines = homer_df.loc[homer_df[\"unannotated_strings\"].str.contains('son', regex =False)]\n",
    "homer_son_lines['unannotated_tokens'] = homer_son_lines[\"unannotated_strings\"].str.replace('\"', '', regex=False).str.split()\n",
    "homer_son_lines['son_count'] = homer_son_lines['unannotated_tokens'].apply(lambda x: sum([1 for y in x if y == 'son']))\n",
    "\n",
    "#str.count('son')\n",
    "homer_son_lines\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
