{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2\n",
    "\n",
    "## Resources\n",
    "\n",
    "- https://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "- https://www.opengreekandlatin.org/what-is-a-cts-urn/\n",
    "- https://cite-architecture.github.io/xcite/ctsurn-quick/\n",
    "\n",
    "## Catch up and review\n",
    "\n",
    "### Reading a file into memory\n",
    "\n",
    "Can you read one of the files from last week into memory? Enter the code to do so below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},

   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It is a truth universally acknowledged, that a single man in possession of a good fortune must be in want of a wife.\\n', '\\n', 'However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered as the rightful property of some one or other of their daughters.\\n']\n"
     ]
    }
   ],

   "source": [
    "# your code for reading a file goes here.\n",
    "\n",
    "with open('../week-01/austen-pride-and-prejudice.txt') as f:\n",
    "    print(f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Git forking, branching, and pushing\n",
    "\n",
    "In this section, we're going to talk about git forking, branching, and pushing, as this will be the main way that you'll submit homework.\n",
    "\n",
    "First, you'll want to navigate to the GitHub repository for this course (https://github.com/Tufts-2024-Quant-Text-Analysis/intro-text-analysis) and press the \"Fork\" button:\n",
    "\n",
    "![Screenshot of the Fork button](./img/fork.png)\n",
    "\n",
    "You should then see a menu that looks something like this:\n",
    "\n",
    "![Screenshot of Fork menu](./img/fork-menu.png)\n",
    "\n",
    "You can rename the repository if you wish, just make sure to keep track of what you rename it to!\n",
    "\n",
    "Once you have forked the main repository, go to your fork and click the \"Code\" button:\n",
    "\n",
    "![Screenshot of the Code button](./img/code.png)\n",
    "\n",
    "You can then clone your fork by copying the URL from the dropdown and entering the following in your terminal:\n",
    "\n",
    "```sh\n",
    "git clone YOUR_GIT_URL_HERE\n",
    "```\n",
    "\n",
    "### Setting up an upstream\n",
    "\n",
    "By default, your own fork of the repository will be the `origin` for this clone. It is a convention when working with git forks to call the \"main\" repository `upstream`. You can add `upstream` as a remote by running the following from within your clone:\n",
    "\n",
    "```sh\n",
    "git remote add upstream https://github.com/Tufts-2024-Quant-Text-Analysis/intro-text-analysis.git\n",
    "```\n",
    "\n",
    "If you know run `git remote -v` from that directory, you should see both `origin` and `upstream`.\n",
    "\n",
    "**NEVER** push directly to `upstream`. Instead, **`pull`** from `upstream` and **`push`** to your fork.\n",
    "\n",
    "Whenever you push your work to your fork, you can navigate to it (on the web) and see an option to create a Pull Request:\n",
    "\n",
    "![Screenshot of pull request](./img/pull-request.png)\n",
    "\n",
    "Try it now: create a small change (you can just add one of your answers to Week 01), and push it to your fork.\n",
    "\n",
    "I will create a branch that matches each of your usernames on the main repository. Open your pull request against this branch.\n",
    "\n",
    "Now we have an easy way of looking at the changes that you've made and comparing them to the main repository without clobbering each other's work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Data \n",
    "\n",
    "### Discuss \n",
    "\n",
    "- What kind(s) of visualization would be best for showing the relative frequencies of a verb like καλός in the Platonic corpus versus Thucydides?\n",
    "\n",
    "Refer to @Brezina2018 [ch. 1] if you feel stuck.\n",
    "\n",
    "## Installing packages\n",
    "\n",
    "Inside a Jupyter/Colab notebook (they're functionally the same thing), you can install packages with the magic command `%pip`. See [here](https://ipython.readthedocs.io/en/stable/interactive/magics.html) for more info on iPython/Jupyter Notebook magic commands.\n",
    "\n",
    "We're going to need the `lxml` package in a moment, so let's go ahead and install it."
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (5.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],

   "source": [
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTS URNs\n",
    "\n",
    "Before we go further, we're going to need to talk a bit about Canonical Text Services Universal Resource Names -- or **CTS URN**s for short.\n",
    "\n",
    "### Collection\n",
    "\n",
    "CTS URNs allow us to specify text down to the token level. They work as references to specific components of a larger corpus, starting with the **collection**.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit\n",
    "```\n",
    "\n",
    "The prefix `urn:cts:` is required by the protocol; `greekLit` refers to the collection of Greek texts known to the CTS implementation.\n",
    "\n",
    "### Work Component\n",
    "\n",
    "The next element in a CTS URN is collectively referred to as the **work component**. At a minimum, it contains a reference to a **text group**. \n",
    "\n",
    "#### Text Group\n",
    "\n",
    "Text groups are often what we think of as authors, but by treating them as placeholders not for a specific writer but for canonically related texts, we can stay one step ahead of issues about attribution etc. Text groups are not meant to make any assertions about authorship; they're just a convenient way to find things.\n",
    "\n",
    "For example, the _Rhesus_ is contained within the Euripides text group by convention; we aren't weighing in on that vexed authorship question.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525\n",
    "```\n",
    "\n",
    "`tlg0525` refers to Pausanias. You can use https://cts.perseids.org/ to look up URNs, but since we'll be working a lot with Pausanias' _Periegesis_, it might be a good idea to get used to tlg0525.\n",
    "\n",
    "Why `tlg0525` and not just `pausanias`? Names and their orthography are hard to standardize. CTS URNs are designed to be **universal** and portable. Using names as identifiers too early on would lead to unnecessary confusion.\n",
    "\n",
    "Should we have settled on a system other than the numbering that the TLG came up with? Probably, but we're decades too late to change that now.\n",
    "\n",
    "\n",
    "#### Work\n",
    "\n",
    "Next comes the **work**. This refers to the item -- in our case it will usually be a text -- under the text group.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001\n",
    "```\n",
    "\n",
    "Notice that `tlg001` is separated from `tlg0525` by a `.`, rather than a `:`. This is because only major components of the URN are separated by `:`; minor components, such as the sub-components of the major **work component**, are separated by `.`.\n",
    "\n",
    "Works within the work component are usually numbered sequentially for the items that we're dealing with. For Sophocles, the sequence starts with _Trachiniae_, so `urn:cts:greekLit:tlg0011.tlg001` refers to that text; `urn:cts:greekLit:tlg0011.tlg003`, for example, refers to _Ajax_.\n",
    "\n",
    "#### Version\n",
    "\n",
    "For classical texts, which have any number of editions published over the years, the **version** is essential. It helps us point to a specific edition of the work, complete with that editions editorial interventions.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001.perseus-grc2\n",
    "```\n",
    "\n",
    "The `perseus-grc2` version refers to the second Greek edition of the _Periegesis_ as published by the Perseus Digital Library.\n",
    "\n",
    "#### Exemplar\n",
    "\n",
    "There is another element in the work component of CTS URNs, the **exemplar**. You might think of this as a reference to the specific _witness_ that you're dealing with.\n",
    "\n",
    "We won't need to use this much for retrieving texts, but if you're working on different ways of handling textual material, you might want to append an exemplar fragment to the work component.\n",
    "\n",
    "For example, if I've made additional annotations to the Perseus _Periegesis_ for my own research that don't necessarily belong in the canonical version (via a pull request vel sim.), I might dub my local exemplar:\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001.perseus-grc2.charles-annotations\n",
    "```\n",
    "\n",
    "That way I know that this URN refers to an exemplar that contains annotations that might not be present in the parent `perseus-grc2`.\n",
    "\n",
    "I want to emphasize, again, you can get through this course just fine without ever using an exemplar fragment. They're under-specified and confusing, but I mention them here for the sake of completeness.\n",
    "\n",
    "### Passage Component\n",
    "\n",
    "Finally, CTS URNs can have a **passage component**. This is the most specific part of the CTS URN, containing references to precise passages and even words within a text.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:1\n",
    "```\n",
    "\n",
    "The `1` above refers to Pausanias Book 1.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:1.1\n",
    "```\n",
    "\n",
    "Now it references Book 1, Chapter 1.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:1.1-2.2\n",
    "```\n",
    "\n",
    "Now we're talking about a passage spanning Book 1, Chapter 1, to Book 2, Chapter 2.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:1.1.5@Κωλιάς\n",
    "```\n",
    "\n",
    "Now we're referencing the token `Κωλιάς` in Book 1, Chapter 1, Section 5.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:1.1.5@Κωλιάδος-1.1.5@θεαί\n",
    "```\n",
    "\n",
    "As a final example, this URN references the span from Κωλιάδος to θεαί in Book 1, Chapter 1, Section 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting text to work with\n",
    "\n",
    "So why this detour on CTS URNs? Because it will make it easier for you to find the texts that you need. I've already added the perseus-grc2 version of Pausanias to this repository; you can find it under `tei/tlg0525.tlg001.perseus-grc2.xml`. (The URN is abbreviated because the file comes from the [PerseusDL/canonical-greekLit](https://github.com/PerseusDL/canonical-greekLit/) repo on GitHub.)\n",
    "\n",
    "Ideally, we would be able to request these texts from an API, but as of this writing in August 2024, all of the known APIs are not working. So for now, we will parse these files locally and transform them into data structures that facilitate our analyses.\n",
    "\n",
    "We'll first need to install the MyCapytains library."
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MyCapytain in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (3.0.2)\n",
      "Requirement already satisfied: requests>=2.8.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from MyCapytain) (2.32.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from MyCapytain) (1.16.0)\n",
      "Requirement already satisfied: lxml>=3.6.4 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from MyCapytain) (5.3.0)\n",
      "Requirement already satisfied: future>=0.16.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from MyCapytain) (1.0.0)\n",
      "Requirement already satisfied: rdflib-jsonld>=0.4.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from MyCapytain) (0.6.2)\n",
      "Requirement already satisfied: LinkHeader>=0.4.3 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from MyCapytain) (0.4.3)\n",
      "Requirement already satisfied: pyld>=1.0.3 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from MyCapytain) (2.0.4)\n",
      "Requirement already satisfied: typing in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from MyCapytain) (3.7.4.3)\n",
      "Requirement already satisfied: cachetools in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from pyld>=1.0.3->MyCapytain) (5.5.0)\n",
      "Requirement already satisfied: frozendict in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from pyld>=1.0.3->MyCapytain) (2.4.4)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from rdflib-jsonld>=0.4.0->MyCapytain) (7.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests>=2.8.1->MyCapytain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests>=2.8.1->MyCapytain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests>=2.8.1->MyCapytain) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests>=2.8.1->MyCapytain) (2024.8.30)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from rdflib>=5.0.0->rdflib-jsonld>=0.4.0->MyCapytain) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from rdflib>=5.0.0->rdflib-jsonld>=0.4.0->MyCapytain) (3.1.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],

   "source": [
    "%pip install MyCapytain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can import this module and use it to ingest the text of Pausanias, stored in the `tei/` directory of this repo."
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 3,

   "metadata": {},
   "outputs": [],
   "source": [
    "from MyCapytain.resources.texts.local.capitains.cts import CapitainsCtsText\n",
    "\n",
    "with open(\"../tei/tlg0525.tlg001.perseus-grc2.xml\") as f:\n",
    "    text = CapitainsCtsText(urn=\"urn:cts:greekLit:tlg0525.tlg001.perseus-grc2\", resource=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try turning the text into just a [Pandas DataFrame](https://pandas.pydata.org/docs/index.html) with columns for the CTS URN, the corresponding XML, and the unannotated text of the passage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block might take a while\n",
    "\n",
    "from lxml import etree\n",
    "from MyCapytain.common.constants import Mimetypes\n",
    "\n",
    "urns = []\n",
    "raw_xmls = []\n",
    "unannotated_strings = []\n",
    "\n",
    "for ref in text.getReffs(level=len(text.citation)):\n",
    "    urn = f\"{text.urn}:{ref}\"\n",
    "    node = text.getTextualNode(ref)\n",
    "    raw_xml = node.export(Mimetypes.XML.TEI)\n",
    "    tree = node.export(Mimetypes.PYTHON.ETREE)\n",
    "    s = etree.tostring(tree, encoding=\"unicode\", method=\"text\")\n",
    "\n",
    "    urns.append(urn)\n",
    "    raw_xmls.append(raw_xml)\n",
    "    unannotated_strings.append(s)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from pandas) (2.9.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: six>=1.5 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [

    "%pip install pandas"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (1.26.4)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,

   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {\n",
    "    \"urn\": pd.Series(urns, dtype=\"string\"),\n",
    "    \"raw_xml\": raw_xmls,\n",
    "    \"unannotated_strings\": pd.Series(unannotated_strings, dtype=\"string\")\n",
    "}\n",
    "pausanias_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with textual data\n",
    "\n",
    "Now that we have some text to work with -- and by \"some text,\" I mean all 3170 sections of Pausanias in the above DataFrame -- we can start working with the data.\n",
    "\n",
    "Before doing so, however, we should ask _how_ we're going to make the data more manageable -- it isn't exactly feasible to dive headfirst into a corpus of this size.\n",
    "\n",
    "> Discuss: What units can we break Pausanias down into to make it more manageable? Don't worry about how you would do it in code yet, just think about how you might explore the units of the text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_book_of_pausanias(df: pd.DataFrame, book_n: int):\n",
    "    return df[df['urn'].str.startswith(f\"urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:{book_n}\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "pausanias_book = get_book_of_pausanias(pausanias_df, 8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of words\n",
    "\n",
    "With all languages, but especially with heavily-inflected languages like ancient Greek and Latin, it is important to be precise about the kinds of word forms that we're dealing with.\n",
    "\n",
    "#### Tokens \n",
    "\n",
    "A **token** or **running word** \"is a single occurrence of a word form in the text\" [@Brezina2018 39].\n",
    "\n",
    "How can we count the number of tokens in all of Pausanias? First we need to **tokenize** the `unannotated_strings` column of `pausanias_df`.\n",
    "\n",
    "Tokenization is a surprisingly complicated process depending on the language of study, and we will learn more sophisticated methods for tokenizing Greek text as we go along.\n",
    "\n",
    "For now, however, let's define a token as \"whitespace-delimited text\" -- we're not going to worry about punctuation etc. just yet.\n",
    "\n",
    "So to tokenize the `unannotated_strings` column of `pausanias_df`, we can run:"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vn/gnrqw1qd3w316009bryjxfxc0000gn/T/ipykernel_34677/1034302631.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pausanias_book['whitespaced_tokens'] = pausanias_book['unannotated_strings'].str.split()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urn</th>\n",
       "      <th>raw_xml</th>\n",
       "      <th>unannotated_strings</th>\n",
       "      <th>whitespaced_tokens</th>\n",
       "      <th>tokens</th>\n",
       "      <th>nlp_docs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2033</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>Ἀρκάδων δὲ τὰ πρὸς τῆς Ἀργείας Τεγεᾶταί τε ἔχο...</td>\n",
       "      <td>[Ἀρκάδων, δὲ, τὰ, πρὸς, τῆς, Ἀργείας, Τεγεᾶταί...</td>\n",
       "      <td>(Ἀρκάδων, δὲ, τὰ, πρὸς, τῆς, Ἀργείας, Τεγεᾶταί...</td>\n",
       "      <td>(Ἀρκάδων, δὲ, τὰ, πρὸς, τῆς, Ἀργείας, Τεγεᾶταί...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2034</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>τὰ δὲ πρὸς Λεχαίου Κορινθίοις Σικυώνιοι προσοι...</td>\n",
       "      <td>[τὰ, δὲ, πρὸς, Λεχαίου, Κορινθίοις, Σικυώνιοι,...</td>\n",
       "      <td>(τὰ, δὲ, πρὸς, Λεχαίου, Κορινθίοις, Σικυώνιοι,...</td>\n",
       "      <td>(τὰ, δὲ, πρὸς, Λεχαίου, Κορινθίοις, Σικυώνιοι,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2035</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>τούτων τῶν κατειλεγμένων καθηκόντων ἐπὶ θάλασσ...</td>\n",
       "      <td>[τούτων, τῶν, κατειλεγμένων, καθηκόντων, ἐπὶ, ...</td>\n",
       "      <td>(τούτων, τῶν, κατειλεγμένων, καθηκόντων, ἐπὶ, ...</td>\n",
       "      <td>(τούτων, τῶν, κατειλεγμένων, καθηκόντων, ἐπὶ, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2036</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>φασὶ δὲ Ἀρκάδες ὡς Πελασγὸς γένοιτο ἐν τῇ γῇ τ...</td>\n",
       "      <td>[φασὶ, δὲ, Ἀρκάδες, ὡς, Πελασγὸς, γένοιτο, ἐν,...</td>\n",
       "      <td>(φασὶ, δὲ, Ἀρκάδες, ὡς, Πελασγὸς, γένοιτο, ἐν,...</td>\n",
       "      <td>(φασὶ, δὲ, Ἀρκάδες, ὡς, Πελασγὸς, γένοιτο, ἐν,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2037</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>Πελασγὸς δὲ βασιλεύσας τοῦτο μὲν ποιήσασθαι κα...</td>\n",
       "      <td>[Πελασγὸς, δὲ, βασιλεύσας, τοῦτο, μὲν, ποιήσασ...</td>\n",
       "      <td>(Πελασγὸς, δὲ, βασιλεύσας, τοῦτο, μὲν, ποιήσασ...</td>\n",
       "      <td>(Πελασγὸς, δὲ, βασιλεύσας, τοῦτο, μὲν, ποιήσασ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2478</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>ἀνασχὼν δὲ ἔνθα Πηγὰς ὀνομάζουσιν οἱ Ἀρκάδες κ...</td>\n",
       "      <td>[ἀνασχὼν, δὲ, ἔνθα, Πηγὰς, ὀνομάζουσιν, οἱ, Ἀρ...</td>\n",
       "      <td>(ἀνασχὼν, δὲ, ἔνθα, Πηγὰς, ὀνομάζουσιν, οἱ, Ἀρ...</td>\n",
       "      <td>(ἀνασχὼν, δὲ, ἔνθα, Πηγὰς, ὀνομάζουσιν, οἱ, Ἀρ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2479</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>ἡ δὲ εὐθεῖα ἡ ἐπὶ Θυρέαν τε καὶ κώμας τὰς ἐν τ...</td>\n",
       "      <td>[ἡ, δὲ, εὐθεῖα, ἡ, ἐπὶ, Θυρέαν, τε, καὶ, κώμας...</td>\n",
       "      <td>(ἡ, δὲ, εὐθεῖα, ἡ, ἐπὶ, Θυρέαν, τε, καὶ, κώμας...</td>\n",
       "      <td>(ἡ, δὲ, εὐθεῖα, ἡ, ἐπὶ, Θυρέαν, τε, καὶ, κώμας...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2480</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>ἡ δὲ ἐς Ἄργος ἐκ Τεγέας ὀχήματι ἐπιτηδειοτάτη ...</td>\n",
       "      <td>[ἡ, δὲ, ἐς, Ἄργος, ἐκ, Τεγέας, ὀχήματι, ἐπιτηδ...</td>\n",
       "      <td>(ἡ, δὲ, ἐς, Ἄργος, ἐκ, Τεγέας, ὀχήματι, ἐπιτηδ...</td>\n",
       "      <td>(ἡ, δὲ, ἐς, Ἄργος, ἐκ, Τεγέας, ὀχήματι, ἐπιτηδ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2481</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>τὸ ἀπὸ τούτου δὲ ἄρχεται τὸ ὄρος τὸ Παρθένιον·...</td>\n",
       "      <td>[τὸ, ἀπὸ, τούτου, δὲ, ἄρχεται, τὸ, ὄρος, τὸ, Π...</td>\n",
       "      <td>(τὸ, ἀπὸ, τούτου, δὲ, ἄρχεται, τὸ, ὄρος, τὸ, Π...</td>\n",
       "      <td>(τὸ, ἀπὸ, τούτου, δὲ, ἄρχεται, τὸ, ὄρος, τὸ, Π...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2482</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>παρέχεται δὲ τὸ Παρθένιον καὶ ἐς λύρας ποίησιν...</td>\n",
       "      <td>[παρέχεται, δὲ, τὸ, Παρθένιον, καὶ, ἐς, λύρας,...</td>\n",
       "      <td>(παρέχεται, δὲ, τὸ, Παρθένιον, καὶ, ἐς, λύρας,...</td>\n",
       "      <td>(παρέχεται, δὲ, τὸ, Παρθένιον, καὶ, ἐς, λύρας,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>450 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    urn  \\\n",
       "2033  urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...   \n",
       "2034  urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...   \n",
       "2035  urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...   \n",
       "2036  urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...   \n",
       "2037  urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...   \n",
       "...                                                 ...   \n",
       "2478  urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...   \n",
       "2479  urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...   \n",
       "2480  urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...   \n",
       "2481  urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...   \n",
       "2482  urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:8...   \n",
       "\n",
       "                                                raw_xml  \\\n",
       "2033  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "2034  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "2035  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "2036  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "2037  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "...                                                 ...   \n",
       "2478  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "2479  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "2480  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "2481  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "2482  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "\n",
       "                                    unannotated_strings  \\\n",
       "2033  Ἀρκάδων δὲ τὰ πρὸς τῆς Ἀργείας Τεγεᾶταί τε ἔχο...   \n",
       "2034  τὰ δὲ πρὸς Λεχαίου Κορινθίοις Σικυώνιοι προσοι...   \n",
       "2035  τούτων τῶν κατειλεγμένων καθηκόντων ἐπὶ θάλασσ...   \n",
       "2036  φασὶ δὲ Ἀρκάδες ὡς Πελασγὸς γένοιτο ἐν τῇ γῇ τ...   \n",
       "2037  Πελασγὸς δὲ βασιλεύσας τοῦτο μὲν ποιήσασθαι κα...   \n",
       "...                                                 ...   \n",
       "2478  ἀνασχὼν δὲ ἔνθα Πηγὰς ὀνομάζουσιν οἱ Ἀρκάδες κ...   \n",
       "2479  ἡ δὲ εὐθεῖα ἡ ἐπὶ Θυρέαν τε καὶ κώμας τὰς ἐν τ...   \n",
       "2480  ἡ δὲ ἐς Ἄργος ἐκ Τεγέας ὀχήματι ἐπιτηδειοτάτη ...   \n",
       "2481  τὸ ἀπὸ τούτου δὲ ἄρχεται τὸ ὄρος τὸ Παρθένιον·...   \n",
       "2482  παρέχεται δὲ τὸ Παρθένιον καὶ ἐς λύρας ποίησιν...   \n",
       "\n",
       "                                     whitespaced_tokens  \\\n",
       "2033  [Ἀρκάδων, δὲ, τὰ, πρὸς, τῆς, Ἀργείας, Τεγεᾶταί...   \n",
       "2034  [τὰ, δὲ, πρὸς, Λεχαίου, Κορινθίοις, Σικυώνιοι,...   \n",
       "2035  [τούτων, τῶν, κατειλεγμένων, καθηκόντων, ἐπὶ, ...   \n",
       "2036  [φασὶ, δὲ, Ἀρκάδες, ὡς, Πελασγὸς, γένοιτο, ἐν,...   \n",
       "2037  [Πελασγὸς, δὲ, βασιλεύσας, τοῦτο, μὲν, ποιήσασ...   \n",
       "...                                                 ...   \n",
       "2478  [ἀνασχὼν, δὲ, ἔνθα, Πηγὰς, ὀνομάζουσιν, οἱ, Ἀρ...   \n",
       "2479  [ἡ, δὲ, εὐθεῖα, ἡ, ἐπὶ, Θυρέαν, τε, καὶ, κώμας...   \n",
       "2480  [ἡ, δὲ, ἐς, Ἄργος, ἐκ, Τεγέας, ὀχήματι, ἐπιτηδ...   \n",
       "2481  [τὸ, ἀπὸ, τούτου, δὲ, ἄρχεται, τὸ, ὄρος, τὸ, Π...   \n",
       "2482  [παρέχεται, δὲ, τὸ, Παρθένιον, καὶ, ἐς, λύρας,...   \n",
       "\n",
       "                                                 tokens  \\\n",
       "2033  (Ἀρκάδων, δὲ, τὰ, πρὸς, τῆς, Ἀργείας, Τεγεᾶταί...   \n",
       "2034  (τὰ, δὲ, πρὸς, Λεχαίου, Κορινθίοις, Σικυώνιοι,...   \n",
       "2035  (τούτων, τῶν, κατειλεγμένων, καθηκόντων, ἐπὶ, ...   \n",
       "2036  (φασὶ, δὲ, Ἀρκάδες, ὡς, Πελασγὸς, γένοιτο, ἐν,...   \n",
       "2037  (Πελασγὸς, δὲ, βασιλεύσας, τοῦτο, μὲν, ποιήσασ...   \n",
       "...                                                 ...   \n",
       "2478  (ἀνασχὼν, δὲ, ἔνθα, Πηγὰς, ὀνομάζουσιν, οἱ, Ἀρ...   \n",
       "2479  (ἡ, δὲ, εὐθεῖα, ἡ, ἐπὶ, Θυρέαν, τε, καὶ, κώμας...   \n",
       "2480  (ἡ, δὲ, ἐς, Ἄργος, ἐκ, Τεγέας, ὀχήματι, ἐπιτηδ...   \n",
       "2481  (τὸ, ἀπὸ, τούτου, δὲ, ἄρχεται, τὸ, ὄρος, τὸ, Π...   \n",
       "2482  (παρέχεται, δὲ, τὸ, Παρθένιον, καὶ, ἐς, λύρας,...   \n",
       "\n",
       "                                               nlp_docs  \n",
       "2033  (Ἀρκάδων, δὲ, τὰ, πρὸς, τῆς, Ἀργείας, Τεγεᾶταί...  \n",
       "2034  (τὰ, δὲ, πρὸς, Λεχαίου, Κορινθίοις, Σικυώνιοι,...  \n",
       "2035  (τούτων, τῶν, κατειλεγμένων, καθηκόντων, ἐπὶ, ...  \n",
       "2036  (φασὶ, δὲ, Ἀρκάδες, ὡς, Πελασγὸς, γένοιτο, ἐν,...  \n",
       "2037  (Πελασγὸς, δὲ, βασιλεύσας, τοῦτο, μὲν, ποιήσασ...  \n",
       "...                                                 ...  \n",
       "2478  (ἀνασχὼν, δὲ, ἔνθα, Πηγὰς, ὀνομάζουσιν, οἱ, Ἀρ...  \n",
       "2479  (ἡ, δὲ, εὐθεῖα, ἡ, ἐπὶ, Θυρέαν, τε, καὶ, κώμας...  \n",
       "2480  (ἡ, δὲ, ἐς, Ἄργος, ἐκ, Τεγέας, ὀχήματι, ἐπιτηδ...  \n",
       "2481  (τὸ, ἀπὸ, τούτου, δὲ, ἄρχεται, τὸ, ὄρος, τὸ, Π...  \n",
       "2482  (παρέχεται, δὲ, τὸ, Παρθένιον, καὶ, ἐς, λύρας,...  \n",
       "\n",
       "[450 rows x 6 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],

   "source": [
    "# See https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html for\n",
    "# panda's string-splitting utilities; it splits on whitespace by default\n",
    "pausanias_book['whitespaced_tokens'] = pausanias_book['unannotated_strings'].str.split()\n",
    "\n",
    "pausanias_book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now that we have some arrays of tokens in `whitespaced_tokens` column, how do we count them?"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28665"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],

   "source": [
    "sum(len(ts) for ts in pausanias_book['whitespaced_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Discuss: What does the above line of code do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line of code is not very idiomatic for Pandas, however. Instead, we should write something like the following:"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28665"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],

   "source": [
    "pausanias_book['whitespaced_tokens'].explode().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('καὶ', 1591),\n",
       " ('δὲ', 1439),\n",
       " ('ἐς', 531),\n",
       " ('τοῦ', 514),\n",
       " ('τὸ', 513),\n",
       " ('ἐν', 468),\n",
       " ('τε', 380),\n",
       " ('μὲν', 373),\n",
       " ('τὴν', 340),\n",
       " ('ὁ', 310),\n",
       " ('τῷ', 304),\n",
       " ('τῆς', 302),\n",
       " ('τὸν', 290),\n",
       " ('τῶν', 284),\n",
       " ('τὰ', 243),\n",
       " ('τῇ', 242),\n",
       " ('ἐπὶ', 231),\n",
       " ('οἱ', 216),\n",
       " ('ἡ', 168),\n",
       " ('ἐκ', 147),\n",
       " ('ἐστιν', 147),\n",
       " ('οὐ', 140),\n",
       " ('δὴ', 125),\n",
       " ('τοῖς', 124),\n",
       " ('ἀπὸ', 120),\n",
       " ('ὑπὸ', 119),\n",
       " ('κατὰ', 114),\n",
       " ('ὡς', 113),\n",
       " ('πρὸς', 111),\n",
       " ('εἶναι', 95),\n",
       " ('παρὰ', 92),\n",
       " ('τοὺς', 89),\n",
       " ('γὰρ', 88),\n",
       " ('ἔτι', 88),\n",
       " ('οὐκ', 85),\n",
       " ('ἱερὸν', 80),\n",
       " ('ἐστὶν', 70),\n",
       " ('ἔστι', 68),\n",
       " ('τοῦτο', 65),\n",
       " ('δέ', 63),\n",
       " ('τὰς', 62),\n",
       " ('αὐτὸν', 62),\n",
       " ('αὐτῷ', 60),\n",
       " ('ἐστι', 60),\n",
       " ('μετὰ', 55),\n",
       " ('μάλιστα', 54),\n",
       " ('ἄγαλμα', 53),\n",
       " ('ἦν', 49),\n",
       " ('ἐξ', 47),\n",
       " ('ὕδωρ', 47),\n",
       " ('Ἀρκάδων', 46),\n",
       " ('αὐτῶν', 46),\n",
       " ('ἐνταῦθα', 45),\n",
       " ('τούτου', 43),\n",
       " ('ἢ', 42),\n",
       " ('αἱ', 42),\n",
       " ('γενέσθαι', 41),\n",
       " ('περὶ', 41),\n",
       " ('ὄνομα', 40),\n",
       " ('διὰ', 40),\n",
       " ('ὕστερον', 39),\n",
       " ('αὐτὴν', 38),\n",
       " ('γε', 37),\n",
       " ('ἐφʼ', 37),\n",
       " ('ὄρος', 36),\n",
       " ('ἂν', 34),\n",
       " ('ταῖς', 34),\n",
       " ('σταδίους', 34),\n",
       " ('Λακεδαιμονίων', 33),\n",
       " ('θεῶν', 33),\n",
       " ('αὐτὸ', 33),\n",
       " ('ὅτι', 32),\n",
       " ('λίθου', 32),\n",
       " ('αὐτοῦ', 32),\n",
       " ('ὑπὲρ', 31),\n",
       " ('ὅσον', 31),\n",
       " ('ἄλλα', 31),\n",
       " ('ἐγένετο', 31),\n",
       " ('μὴ', 30),\n",
       " ('αὐτόθι', 30),\n",
       " ('ἐπʼ', 30),\n",
       " ('ἤδη', 30),\n",
       " ('ἀλλὰ', 29),\n",
       " ('φασὶν', 29),\n",
       " ('οὗτος', 29),\n",
       " ('τότε', 29),\n",
       " ('σφᾶς', 28),\n",
       " ('σφισιν', 28),\n",
       " ('οὖν', 28),\n",
       " ('εἰ', 27),\n",
       " ('σφίσιν', 27),\n",
       " ('χωρίον', 27),\n",
       " ('ἐρείπια', 27),\n",
       " ('ἕνεκα', 26),\n",
       " ('τι', 26),\n",
       " ('ἐπίκλησιν', 26),\n",
       " ('πόλεως', 26),\n",
       " ('μέν', 26),\n",
       " ('οὔτε', 26),\n",
       " ('ἀπωτέρω', 26)]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "token_list = pausanias_book['whitespaced_tokens'].explode().tolist()\n",
    "token_counts = Counter(token_list)\n",
    "most_common_tokens = token_counts.most_common(100)\n",
    "\n",
    "most_common_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types\n",
    "\n",
    "A **type** is a unique word form in the corpus. For example, the inflected forms βουλεύεται and βουλεύομεν are each a type. (See @Brezina2018 [39-40].)\n",
    "\n",
    "In other words, **types** are **tokens** grouped by form. So to count the number of **types** in Pausanias, we can do the following:"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8704"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],

   "source": [
    "len(pausanias_book['whitespaced_tokens'].explode().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Discuss: Break the above line of code down method by method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to see the top `n` types in the corpus?"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('καὶ', 1591),\n",
       " ('δὲ', 1439),\n",
       " ('ἐς', 531),\n",
       " ('τοῦ', 514),\n",
       " ('τὸ', 513),\n",
       " ('ἐν', 468),\n",
       " ('τε', 380),\n",
       " ('μὲν', 373),\n",
       " ('τὴν', 340),\n",
       " ('ὁ', 310),\n",
       " ('τῷ', 304),\n",
       " ('τῆς', 302),\n",
       " ('τὸν', 290),\n",
       " ('τῶν', 284),\n",
       " ('τὰ', 243),\n",
       " ('τῇ', 242),\n",
       " ('ἐπὶ', 231),\n",
       " ('οἱ', 216),\n",
       " ('ἡ', 168),\n",
       " ('ἐκ', 147),\n",
       " ('ἐστιν', 147),\n",
       " ('οὐ', 140),\n",
       " ('δὴ', 125),\n",
       " ('τοῖς', 124),\n",
       " ('ἀπὸ', 120),\n",
       " ('ὑπὸ', 119),\n",
       " ('κατὰ', 114),\n",
       " ('ὡς', 113),\n",
       " ('πρὸς', 111),\n",
       " ('εἶναι', 95),\n",
       " ('παρὰ', 92),\n",
       " ('τοὺς', 89),\n",
       " ('γὰρ', 88),\n",
       " ('ἔτι', 88),\n",
       " ('οὐκ', 85),\n",
       " ('ἱερὸν', 80),\n",
       " ('ἐστὶν', 70),\n",
       " ('ἔστι', 68),\n",
       " ('τοῦτο', 65),\n",
       " ('δέ', 63),\n",
       " ('τὰς', 62),\n",
       " ('αὐτὸν', 62),\n",
       " ('αὐτῷ', 60),\n",
       " ('ἐστι', 60),\n",
       " ('μετὰ', 55),\n",
       " ('μάλιστα', 54),\n",
       " ('ἄγαλμα', 53),\n",
       " ('ἦν', 49),\n",
       " ('ἐξ', 47),\n",
       " ('ὕδωρ', 47),\n",
       " ('Ἀρκάδων', 46),\n",
       " ('αὐτῶν', 46),\n",
       " ('ἐνταῦθα', 45),\n",
       " ('τούτου', 43),\n",
       " ('ἢ', 42),\n",
       " ('αἱ', 42),\n",
       " ('γενέσθαι', 41),\n",
       " ('περὶ', 41),\n",
       " ('ὄνομα', 40),\n",
       " ('διὰ', 40),\n",
       " ('ὕστερον', 39),\n",
       " ('αὐτὴν', 38),\n",
       " ('γε', 37),\n",
       " ('ἐφʼ', 37),\n",
       " ('ὄρος', 36),\n",
       " ('ἂν', 34),\n",
       " ('ταῖς', 34),\n",
       " ('σταδίους', 34),\n",
       " ('Λακεδαιμονίων', 33),\n",
       " ('θεῶν', 33),\n",
       " ('αὐτὸ', 33),\n",
       " ('ὅτι', 32),\n",
       " ('λίθου', 32),\n",
       " ('αὐτοῦ', 32),\n",
       " ('ὑπὲρ', 31),\n",
       " ('ὅσον', 31),\n",
       " ('ἄλλα', 31),\n",
       " ('ἐγένετο', 31),\n",
       " ('μὴ', 30),\n",
       " ('αὐτόθι', 30),\n",
       " ('ἐπʼ', 30),\n",
       " ('ἤδη', 30),\n",
       " ('ἀλλὰ', 29),\n",
       " ('φασὶν', 29),\n",
       " ('οὗτος', 29),\n",
       " ('τότε', 29),\n",
       " ('σφᾶς', 28),\n",
       " ('σφισιν', 28),\n",
       " ('οὖν', 28),\n",
       " ('εἰ', 27),\n",
       " ('σφίσιν', 27),\n",
       " ('χωρίον', 27),\n",
       " ('ἐρείπια', 27),\n",
       " ('ἕνεκα', 26),\n",
       " ('τι', 26),\n",
       " ('ἐπίκλησιν', 26),\n",
       " ('πόλεως', 26),\n",
       " ('μέν', 26),\n",
       " ('οὔτε', 26),\n",
       " ('ἀπωτέρω', 26)]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],

   "source": [
    "from collections import Counter\n",
    "\n",
    "type_counts = Counter(pausanias_book['whitespaced_tokens'].explode())\n",
    "\n",
    "type_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words\n",
    "\n",
    "Hm, that's not particularly interesting -- most of these words are fairly common and will rank highly in almost any corpus. Further, since we haven't accounted for punctuation, we're probably generating frequencies incorrectly based on whether or not a type is joined to any punctuation. We need to get a bit more sophisticated.\n",
    "\n",
    "Let's install `spacy` and `grecy` to perform better tokenization and incorporate the notion of a **stop word**: a token that is so common that including it in most statistical analyses will just generate noise."
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (2.9.1)\n",
      "Requirement already satisfied: jinja2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (73.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from jinja2->spacy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: grecy in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (1.0)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.5 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from grecy) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.9.1)\n",
      "Requirement already satisfied: jinja2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (73.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.5->grecy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5->grecy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5->grecy) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5->grecy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.5->grecy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.5->grecy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.5->grecy) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.5->grecy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from jinja2->spacy<4.0.0,>=3.5->grecy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.5->grecy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.5->grecy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Uncomment the line for your system's architecture\n",
    "%pip install spacy\n",
    "#%pip install 'spacy[apple]'\n",

    "%pip install grecy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to install a model for `grecy` to use. Note that there is a known but so-far unpatched issue where this command will only work with Python 3.11.9 and pip 24.0 (or a bit older in either case)."
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Installing grc_proiel_sm.....\n",
      "\n",
      "Please wait, this could take some minutes.....\n",
      "\n",
      "Collecting grc-proiel-sm==any\n",
      "Downloading https://huggingface.co/Jacobo/grc_proiel_sm/resolve/main/grc_proiel_sm-any-py3-none-any.whl (65.5 MB)\n",
      "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/65.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.2/65.5 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:15\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.6/65.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.8/65.5 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/65.5 MB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/65.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/65.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/65.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/65.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/65.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/65.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/65.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/65.5 MB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:17\u001b[0m\n",
      "\u001b[2K     \u001b[91m━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/65.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:14\u001b[0m\n",
      "\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/65.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:13\u001b[0m\n",
      "\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/65.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:12\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/65.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:11\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/65.5 MB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:11\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/65.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:10\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.0/65.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/65.5 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/65.5 MB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.4/65.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/65.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.3/65.5 MB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/65.5 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/65.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/65.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/65.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.9/65.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/65.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.8/65.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.2/65.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/65.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.2/65.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/65.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/65.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/65.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.9/65.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.3/65.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.8/65.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.3/65.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.6/65.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.1/65.5 MB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.5/65.5 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/65.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/65.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.9/65.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/65.5 MB\u001b[0m \u001b[31m11.1 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.6/65.5 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.8/65.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.1/65.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.4/65.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.8/65.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/65.5 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/65.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/65.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.5/65.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/65.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.4/65.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.8/65.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.6/65.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/65.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.2/65.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.3/65.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.9/65.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.3/65.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/65.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.2/65.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.2/65.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.0/65.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.4/65.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.8/65.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.3/65.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.4/65.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.7/65.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.4/65.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.9/65.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.3/65.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29.6/65.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.0/65.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.4/65.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.8/65.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.1/65.5 MB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.5/65.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.8/65.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.1/65.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.2/65.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.4/65.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.5/65.5 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m33.5/65.5 MB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.7/65.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.6/65.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/65.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.4/65.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36.6/65.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.0/65.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.4/65.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/65.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.0/65.5 MB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/65.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.0/65.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/65.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.6/65.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/65.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/65.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.0/65.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.4/65.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.7/65.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/65.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/65.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.5/65.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m42.9/65.5 MB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m43.2/65.5 MB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/65.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m44.2/65.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/65.5 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/65.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m45.4/65.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m45.8/65.5 MB\u001b[0m \u001b[31m9.5 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m46.4/65.5 MB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m46.4/65.5 MB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m46.5/65.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m46.6/65.5 MB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m46.7/65.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m46.8/65.5 MB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m47.0/65.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m47.4/65.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m47.8/65.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m48.2/65.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m48.3/65.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m48.8/65.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m49.2/65.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m49.6/65.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m49.8/65.5 MB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m50.3/65.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m50.3/65.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m51.1/65.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m51.5/65.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━\u001b[0m \u001b[32m52.0/65.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m52.5/65.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m52.8/65.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m53.5/65.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m53.8/65.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━\u001b[0m \u001b[32m54.0/65.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━\u001b[0m \u001b[32m55.3/65.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m55.9/65.5 MB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m56.7/65.5 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m57.4/65.5 MB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m58.0/65.5 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m58.5/65.5 MB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m58.7/65.5 MB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m58.8/65.5 MB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m60.1/65.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m61.5/65.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m62.0/65.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m62.2/65.5 MB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m62.5/65.5 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m \u001b[32m64.0/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m64.7/65.5 MB\u001b[0m \u001b[31m12.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.0/65.5 MB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.2/65.5 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m65.4/65.5 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 MB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.5 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from grc-proiel-sm==any) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (2.9.1)\n",
      "Requirement already satisfied: jinja2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (73.0.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from jinja2->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/alicia/miniconda3/envs/intro-qta/lib/python3.12/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.5->grc-proiel-sm==any) (0.1.2)\n",
      "\n"
     ]
    }
   ],

   "source": [
    "%run -m grecy install grc_proiel_sm"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"grc_proiel_sm\", disable=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vn/gnrqw1qd3w316009bryjxfxc0000gn/T/ipykernel_34677/4180847992.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pausanias_book['tokens'] = pausanias_book['unannotated_strings'].apply(tokenizer)\n"
     ]
    }
   ],
   "source": [

    "tokenizer = nlp.tokenizer\n",
    "\n",
    "pausanias_book['tokens'] = pausanias_book['unannotated_strings'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenization process through SpaCy adds some features to each of the tokens in the `tokens` column. Now we can collect the types and exclude stop words using the `token.is_stop` attribute."
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ἱερὸν', 82),\n",
       " ('ἄγαλμα', 61),\n",
       " ('μάλιστα', 58),\n",
       " ('ἐνταῦθα', 53),\n",
       " ('Ἀρκάδων', 52),\n",
       " ('ὕδωρ', 51),\n",
       " ('ὄνομα', 48),\n",
       " ('πόλιν', 44),\n",
       " ('γενέσθαι', 42),\n",
       " ('ὕστερον', 41),\n",
       " ('λίθου', 41),\n",
       " ('ὄρος', 40),\n",
       " ('σταδίους', 38),\n",
       " ('ἐφʼ', 37),\n",
       " ('Ἀρκάδες', 36),\n",
       " ('θεῶν', 35),\n",
       " ('χωρίον', 34),\n",
       " ('Λακεδαιμονίων', 33),\n",
       " ('αὐτόθι', 33),\n",
       " ('ἐγένετο', 33),\n",
       " ('πόλεως', 32),\n",
       " ('ὅσον', 31),\n",
       " ('ἤδη', 31),\n",
       " ('ἐπίκλησιν', 31),\n",
       " ('ἐρείπια', 31),\n",
       " ('σφισιν', 30),\n",
       " ('ἐπʼ', 30),\n",
       " ('λέγουσιν', 30),\n",
       " ('σφᾶς', 29),\n",
       " ('ἕνεκα', 29),\n",
       " ('φασὶν', 29),\n",
       " ('τότε', 29),\n",
       " ('λέγουσι', 29),\n",
       " ('γῆς', 28),\n",
       " ('Ἀρτέμιδος', 28),\n",
       " ('σφίσιν', 28),\n",
       " ('παῖδα', 27),\n",
       " ('Δήμητρος', 26),\n",
       " ('ἀπωτέρω', 26),\n",
       " ('ἱερόν', 25),\n",
       " ('πεποίηται', 24),\n",
       " ('φασιν', 24),\n",
       " ('μνήμην', 24),\n",
       " ('ἐποίησεν', 24),\n",
       " ('δʼ', 24),\n",
       " ('καλούμενον', 24),\n",
       " ('πολὺ', 24),\n",
       " ('ἀριστερᾷ', 24),\n",
       " ('ἀγάλματα', 24),\n",
       " ('λόγος', 23),\n",
       " ('αὖθις', 23),\n",
       " ('ἔνθα', 23),\n",
       " ('πρότερον', 23),\n",
       " ('Ἀπόλλωνος', 23),\n",
       " ('ὄρους', 23),\n",
       " ('δεξιᾷ', 23),\n",
       " ('που', 22),\n",
       " ('λόγῳ', 22),\n",
       " ('πρὸ', 22),\n",
       " ('σφισι', 22),\n",
       " ('σταδίοις', 22),\n",
       " ('ἔχει', 21),\n",
       " ('πόλις', 21),\n",
       " ('ἀρχαῖον', 21),\n",
       " ('δέκα', 21),\n",
       " ('Ἑλλήνων', 20),\n",
       " ('πεδίον', 20),\n",
       " ('ναὸς', 20),\n",
       " ('Ἀθηνᾶς', 20),\n",
       " ('ναός', 20),\n",
       " ('λόγου', 19),\n",
       " ('ἀνθρώπων', 19),\n",
       " ('ὄρει', 19),\n",
       " ('ὅσοι', 19),\n",
       " ('πέντε', 19),\n",
       " ('πόλει', 19),\n",
       " ('δύο', 19),\n",
       " ('πάντα', 19),\n",
       " ('χρόνον', 19),\n",
       " ('καλοῦσιν', 18),\n",
       " ('λέγεται', 18),\n",
       " ('Λυκάονος', 18),\n",
       " ('θυγατέρα', 18),\n",
       " ('ναοῦ', 18),\n",
       " ('ἅτε', 18),\n",
       " ('Φιλοποίμην', 18),\n",
       " ('ἕτερον', 17),\n",
       " ('ὅροι', 17),\n",
       " ('ἐντὸς', 17),\n",
       " ('Ὅμηρος', 17),\n",
       " ('ὁμοῦ', 17),\n",
       " ('γένος', 17),\n",
       " ('ὁδοῦ', 17),\n",
       " ('Μαντινεῖς', 16),\n",
       " ('ἀντὶ', 16),\n",
       " ('πολλὰ', 16),\n",
       " ('παίδων', 16),\n",
       " ('μάχῃ', 16),\n",
       " ('Ἀχαιῶν', 16),\n",
       " ('κάτεισιν', 16)]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],

   "source": [
    "types = [t.text for t in pausanias_book['tokens'].explode() if not t.is_stop and t.is_alpha]\n",
    "\n",
    "type_counts = Counter(types)\n",
    "\n",
    "type_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ἱερὸν', 82),\n",
       " ('ἄγαλμα', 61),\n",
       " ('μάλιστα', 58),\n",
       " ('ἐνταῦθα', 53),\n",
       " ('Ἀρκάδων', 52),\n",
       " ('ὕδωρ', 51),\n",
       " ('ὄνομα', 48),\n",
       " ('πόλιν', 44),\n",
       " ('γενέσθαι', 42),\n",
       " ('ὕστερον', 41),\n",
       " ('λίθου', 41),\n",
       " ('ὄρος', 40),\n",
       " ('σταδίους', 38),\n",
       " ('ἐφʼ', 37),\n",
       " ('Ἀρκάδες', 36),\n",
       " ('θεῶν', 35),\n",
       " ('χωρίον', 34),\n",
       " ('Λακεδαιμονίων', 33),\n",
       " ('αὐτόθι', 33),\n",
       " ('ἐγένετο', 33),\n",
       " ('πόλεως', 32),\n",
       " ('ὅσον', 31),\n",
       " ('ἤδη', 31),\n",
       " ('ἐπίκλησιν', 31),\n",
       " ('ἐρείπια', 31),\n",
       " ('σφισιν', 30),\n",
       " ('ἐπʼ', 30),\n",
       " ('λέγουσιν', 30),\n",
       " ('σφᾶς', 29),\n",
       " ('ἕνεκα', 29),\n",
       " ('φασὶν', 29),\n",
       " ('τότε', 29),\n",
       " ('λέγουσι', 29),\n",
       " ('γῆς', 28),\n",
       " ('Ἀρτέμιδος', 28),\n",
       " ('σφίσιν', 28),\n",
       " ('παῖδα', 27),\n",
       " ('Δήμητρος', 26),\n",
       " ('ἀπωτέρω', 26),\n",
       " ('ἱερόν', 25),\n",
       " ('πεποίηται', 24),\n",
       " ('φασιν', 24),\n",
       " ('μνήμην', 24),\n",
       " ('ἐποίησεν', 24),\n",
       " ('δʼ', 24),\n",
       " ('καλούμενον', 24),\n",
       " ('πολὺ', 24),\n",
       " ('ἀριστερᾷ', 24),\n",
       " ('ἀγάλματα', 24),\n",
       " ('λόγος', 23),\n",
       " ('αὖθις', 23),\n",
       " ('ἔνθα', 23),\n",
       " ('πρότερον', 23),\n",
       " ('Ἀπόλλωνος', 23),\n",
       " ('ὄρους', 23),\n",
       " ('δεξιᾷ', 23),\n",
       " ('που', 22),\n",
       " ('λόγῳ', 22),\n",
       " ('πρὸ', 22),\n",
       " ('σφισι', 22),\n",
       " ('σταδίοις', 22),\n",
       " ('ἔχει', 21),\n",
       " ('πόλις', 21),\n",
       " ('ἀρχαῖον', 21),\n",
       " ('δέκα', 21),\n",
       " ('Ἑλλήνων', 20),\n",
       " ('πεδίον', 20),\n",
       " ('ναὸς', 20),\n",
       " ('Ἀθηνᾶς', 20),\n",
       " ('ναός', 20),\n",
       " ('λόγου', 19),\n",
       " ('ἀνθρώπων', 19),\n",
       " ('ὄρει', 19),\n",
       " ('ὅσοι', 19),\n",
       " ('πέντε', 19),\n",
       " ('πόλει', 19),\n",
       " ('δύο', 19),\n",
       " ('πάντα', 19),\n",
       " ('χρόνον', 19),\n",
       " ('καλοῦσιν', 18),\n",
       " ('λέγεται', 18),\n",
       " ('Λυκάονος', 18),\n",
       " ('θυγατέρα', 18),\n",
       " ('ναοῦ', 18),\n",
       " ('ἅτε', 18),\n",
       " ('Φιλοποίμην', 18),\n",
       " ('ἕτερον', 17),\n",
       " ('ὅροι', 17),\n",
       " ('ἐντὸς', 17),\n",
       " ('Ὅμηρος', 17),\n",
       " ('ὁμοῦ', 17),\n",
       " ('γένος', 17),\n",
       " ('ὁδοῦ', 17),\n",
       " ('Μαντινεῖς', 16),\n",
       " ('ἀντὶ', 16),\n",
       " ('πολλὰ', 16),\n",
       " ('παίδων', 16),\n",
       " ('μάχῃ', 16),\n",
       " ('Ἀχαιῶν', 16),\n",
       " ('κάτεισιν', 16)]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "tokens = [t.text for t in pausanias_book['tokens'].explode() if not t.is_stop and t.is_alpha]\n",
    "token_counts = Counter(tokens)\n",
    "most_common_token = token_counts.most_common(100)\n",
    "\n",
    "most_common_token"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! We now have a list of the most common types, exluding stop words and punctuation.\n",
    "\n",
    "Be careful, though: these are still just raw counts, and they tell us very little about how we might characterize Pausanias vis-à-vis a larger corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmata/lemmas\n",
    "\n",
    "A **lemma** (plural **lemmata** or **lemmas**) represents \"a group of all inflectional forms related to one stem that belong to the same word class (Kučera & Francis 1967: 1)\" [@Brezina2018 40]. In simpler terms, a **lemma** is the dictionary form of a word, so **lemmata** give us a way of further reducing the word count. ἐστίν, ἔσμεν, and εἰσίν all have the same **lemma**: εἰμί.\n",
    "\n",
    "Lemmatization, as you might guess, often involves additional processing. Luckily, we can use the SpaCy and GreCy models again."
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/vn/gnrqw1qd3w316009bryjxfxc0000gn/T/ipykernel_34677/1706745553.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  pausanias_book['nlp_docs'] = list(annotated_texts)\n"
     ]
    }
   ],

   "source": [
    "raw_texts = [t for t in pausanias_book['unannotated_strings']]\n",
    "annotated_texts = nlp.pipe(raw_texts, batch_size=100)\n",
    "\n",
    "pausanias_book['nlp_docs'] = list(annotated_texts)"
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('ποιέω', 167),\n",
       " ('καλέω', 149),\n",
       " ('ἔχω', 147),\n",
       " ('γίγνομαι', 146),\n",
       " ('πόλις', 143),\n",
       " ('λέγω', 139),\n",
       " ('Ἀρκάς', 132),\n",
       " ('ἱερόν', 129),\n",
       " ('σφεῖς', 123),\n",
       " ('πολύς', 122),\n",
       " ('ἄγαλμα', 102),\n",
       " ('θεός', 101),\n",
       " ('στάδιον', 99),\n",
       " ('ὄρος', 96),\n",
       " ('φημί', 88),\n",
       " ('μέγας', 86),\n",
       " ('παῖς', 83),\n",
       " ('λόγος', 80),\n",
       " ('ποταμός', 76),\n",
       " ('ναός', 74),\n",
       " ('Λακεδαιμόνιος', 73),\n",
       " ('ὀνομάζω', 71),\n",
       " ('ὅσος', 69),\n",
       " ('ἐπί', 67),\n",
       " ('μάλα', 67),\n",
       " ('πᾶς', 66),\n",
       " ('ὕδωρ', 66),\n",
       " ('γῆ', 58),\n",
       " ('ἀνήρ', 57),\n",
       " ('ὄνομα', 57),\n",
       " ('ἐνταῦθα', 57),\n",
       " ('Ἄρτεμις', 57),\n",
       " ('πηγή', 57),\n",
       " ('ἄνθρωπος', 56),\n",
       " ('λίθος', 52),\n",
       " ('ὁδός', 51),\n",
       " ('ἄγω', 49),\n",
       " ('Μαντινεύς', 48),\n",
       " ('Ἀπόλλων', 46),\n",
       " ('Δημήτηρ', 46),\n",
       " ('ἕτερος', 45),\n",
       " ('ἐπίκλησις', 45),\n",
       " ('ἀρχαῖος', 45),\n",
       " ('Τεγεάτης', 44),\n",
       " ('ὕστερος', 42),\n",
       " ('Ἕλλην', 42),\n",
       " ('χωρίον', 42),\n",
       " ('πρῶτος', 40),\n",
       " ('Μεγαλοπολίτης', 38),\n",
       " ('χρόνος', 37),\n",
       " ('ἀφικνέομαι', 36),\n",
       " ('Φιλοποίμην', 36),\n",
       " ('θυγάτηρ', 35),\n",
       " ('γυνή', 35),\n",
       " ('παρέχω', 35),\n",
       " ('ἔργον', 35),\n",
       " ('ἵππος', 35),\n",
       " ('χώρα', 34),\n",
       " ('Ζεύς', 34),\n",
       " ('πεδίον', 34),\n",
       " ('πρότερος', 33),\n",
       " ('αὐτόθι', 33),\n",
       " ('βασιλεύς', 33),\n",
       " ('Ἀλφειός', 32),\n",
       " ('πόλεμος', 32),\n",
       " ('θάλασσα', 31),\n",
       " ('ἕνεκα', 31),\n",
       " ('ἤδη', 31),\n",
       " ('Ἀθήνη', 31),\n",
       " ('μάχη', 31),\n",
       " ('ἐρείπιον', 31),\n",
       " ('ἀρχή', 30),\n",
       " ('κάτειμι', 30),\n",
       " ('Ποσειδῶν', 30),\n",
       " ('Ῥωμαῖος', 30),\n",
       " ('ὅρος', 29),\n",
       " ('ἔοικα', 29),\n",
       " ('τότε', 29),\n",
       " ('ἀριστερός', 29),\n",
       " ('λείπω', 29),\n",
       " ('Ἀχαιός', 28),\n",
       " ('γένος', 28),\n",
       " ('τίθημι', 28),\n",
       " ('Ἑρμῆς', 28),\n",
       " ('Φιγαλεύς', 28),\n",
       " ('διά', 27),\n",
       " ('βωμός', 27),\n",
       " ('μνήμη', 27),\n",
       " ('τάφος', 27),\n",
       " ('μνῆμα', 27),\n",
       " ('Ὅμηρος', 26),\n",
       " ('ἔτος', 26),\n",
       " ('ἀπωτέρω', 26),\n",
       " ('δεξιός', 26),\n",
       " ('Πάν', 26),\n",
       " ('μέγεθος', 25),\n",
       " ('οἰκέω', 24),\n",
       " ('Λυκάων', 24),\n",
       " ('δέ', 24),\n",
       " ('Ἀθηναῖος', 23)]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],

   "source": [
    "lemmata = [t.lemma_ for t in pausanias_book['nlp_docs'].explode() if not t.is_stop and t.is_alpha]\n",
    "\n",
    "lemmata_counts = Counter(lemmata)\n",
    "\n",
    "lemmata_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lexemes\n",
    "\n",
    "Finally, \"a **lexeme** is a lemma with a particular meaning attached to it.... The best way of conceptualizing a lexeme is as a subentry in a dictionary\" [@Brezina2018 40].\n",
    "\n",
    "One challenge of working with lexemes is that, even with the advances of large language models like ChatGPT, there is no surefire way to annotate them automatically. We still need \"human-in-the-loop\" pipelines to catch errors and ambiguities. And keep in mind that even two humans might disagree on the lexeme for a particular word!\n",
    "\n",
    "But we can inspect the `lex` attributes of the tokens that SpaCy has generated for us and see if they make sense."
   ]
  },
  {
   "cell_type": "code",

   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Ἠλείων', <spacy.lexeme.Lexeme at 0x120324f80>), 46),\n",
       " (('ἐπʼ', <spacy.lexeme.Lexeme at 0x1204a7a00>), 41),\n",
       " (('Διὸς', <spacy.lexeme.Lexeme at 0x12033d080>), 38),\n",
       " (('Ὀλυμπίᾳ', <spacy.lexeme.Lexeme at 0x1204a7ac0>), 34),\n",
       " (('πεποίηται', <spacy.lexeme.Lexeme at 0x1182310c0>), 33),\n",
       " (('ἄγαλμα', <spacy.lexeme.Lexeme at 0x120325300>), 31),\n",
       " (('μάλιστα', <spacy.lexeme.Lexeme at 0x1203243c0>), 29),\n",
       " (('Ἠλεῖοι', <spacy.lexeme.Lexeme at 0x1182bd540>), 28),\n",
       " (('ἀγῶνα', <spacy.lexeme.Lexeme at 0x1204a7b80>), 28),\n",
       " (('ὕστερον', <spacy.lexeme.Lexeme at 0x120326dc0>), 28),\n",
       " (('σφισιν', <spacy.lexeme.Lexeme at 0x1204a73c0>), 27),\n",
       " (('ὄνομα', <spacy.lexeme.Lexeme at 0x12031df80>), 27),\n",
       " (('λέγουσιν', <spacy.lexeme.Lexeme at 0x1204a6240>), 26),\n",
       " (('δύο', <spacy.lexeme.Lexeme at 0x120325180>), 25),\n",
       " (('σφᾶς', <spacy.lexeme.Lexeme at 0x1182bc100>), 24),\n",
       " (('γενέσθαι', <spacy.lexeme.Lexeme at 0x1204a6280>), 23),\n",
       " (('Ὀλυμπίαν', <spacy.lexeme.Lexeme at 0x12031d040>), 23),\n",
       " (('ἐνταῦθα', <spacy.lexeme.Lexeme at 0x1203245c0>), 23),\n",
       " (('ἐπίγραμμα', <spacy.lexeme.Lexeme at 0x12033af00>), 23),\n",
       " (('φασιν', <spacy.lexeme.Lexeme at 0x1182bdc00>), 22),\n",
       " (('πρὸ', <spacy.lexeme.Lexeme at 0x12033ad80>), 22),\n",
       " (('ἵππων', <spacy.lexeme.Lexeme at 0x11825f600>), 22),\n",
       " (('Ἡρακλέους', <spacy.lexeme.Lexeme at 0x12031ff00>), 21),\n",
       " (('ἤδη', <spacy.lexeme.Lexeme at 0x12031e580>), 20),\n",
       " (('ἔχει', <spacy.lexeme.Lexeme at 0x120325c80>), 20),\n",
       " (('Ἠλείοις', <spacy.lexeme.Lexeme at 0x120325dc0>), 20),\n",
       " (('Ὀλυμπιάδι', <spacy.lexeme.Lexeme at 0x11824d8c0>), 20),\n",
       " (('γένος', <spacy.lexeme.Lexeme at 0x12031c940>), 19),\n",
       " (('ἔχων', <spacy.lexeme.Lexeme at 0x1203272c0>), 19),\n",
       " (('αὖθις', <spacy.lexeme.Lexeme at 0x120328480>), 19),\n",
       " (('ἀνάθημα', <spacy.lexeme.Lexeme at 0x11822cb80>), 19),\n",
       " (('ἀναθήματα', <spacy.lexeme.Lexeme at 0x1181faa80>), 19),\n",
       " (('δεξιᾷ', <spacy.lexeme.Lexeme at 0x12033dc80>), 18),\n",
       " (('ἐγένετο', <spacy.lexeme.Lexeme at 0x12031c900>), 17),\n",
       " (('λέγεται', <spacy.lexeme.Lexeme at 0x12032b340>), 17),\n",
       " (('ἀγάλματα', <spacy.lexeme.Lexeme at 0x1182321c0>), 17),\n",
       " (('ὅσοι', <spacy.lexeme.Lexeme at 0x118858940>), 16),\n",
       " (('ἐφʼ', <spacy.lexeme.Lexeme at 0x12031d780>), 16),\n",
       " (('Ἡρακλεῖ', <spacy.lexeme.Lexeme at 0x12031eb00>), 16),\n",
       " (('Διὶ', <spacy.lexeme.Lexeme at 0x120325380>), 16),\n",
       " (('ἀνὴρ', <spacy.lexeme.Lexeme at 0x120329fc0>), 16),\n",
       " (('ἀνέθεσαν', <spacy.lexeme.Lexeme at 0x118233940>), 16),\n",
       " (('Διός', <spacy.lexeme.Lexeme at 0x1204a70c0>), 15),\n",
       " (('Πέλοπος', <spacy.lexeme.Lexeme at 0x12031ce40>), 15),\n",
       " (('Ἡρακλῆς', <spacy.lexeme.Lexeme at 0x120324280>), 15),\n",
       " (('θεῶν', <spacy.lexeme.Lexeme at 0x12033fb80>), 15),\n",
       " (('ναοῦ', <spacy.lexeme.Lexeme at 0x118230e40>), 15),\n",
       " (('Ἑλλήνων', <spacy.lexeme.Lexeme at 0x1182bf340>), 14),\n",
       " (('ἀρχῆς', <spacy.lexeme.Lexeme at 0x1204a5b00>), 14),\n",
       " (('Ἠλείους', <spacy.lexeme.Lexeme at 0x1204a6b00>), 14),\n",
       " (('πρῶτον', <spacy.lexeme.Lexeme at 0x1204a5fc0>), 14),\n",
       " (('δʼ', <spacy.lexeme.Lexeme at 0x1204a7880>), 14),\n",
       " (('ἔργον', <spacy.lexeme.Lexeme at 0x12031ec00>), 14),\n",
       " (('ἐντὸς', <spacy.lexeme.Lexeme at 0x120339800>), 14),\n",
       " (('πρότερον', <spacy.lexeme.Lexeme at 0x12033c140>), 14),\n",
       " (('Ἄλτεως', <spacy.lexeme.Lexeme at 0x11821c740>), 14),\n",
       " (('βωμὸς', <spacy.lexeme.Lexeme at 0x1182b8680>), 14),\n",
       " (('Ἡρακλέα', <spacy.lexeme.Lexeme at 0x12031e6c0>), 13),\n",
       " (('ἄνδρα', <spacy.lexeme.Lexeme at 0x12031ef40>), 13),\n",
       " (('πρὶν', <spacy.lexeme.Lexeme at 0x1203254c0>), 13),\n",
       " (('σφίσιν', <spacy.lexeme.Lexeme at 0x120327a00>), 13),\n",
       " (('βωμός', <spacy.lexeme.Lexeme at 0x1182b0f40>), 13),\n",
       " (('κατʼ', <spacy.lexeme.Lexeme at 0x12031c9c0>), 12),\n",
       " (('ὕδωρ', <spacy.lexeme.Lexeme at 0x1203282c0>), 12),\n",
       " (('ὁμοῦ', <spacy.lexeme.Lexeme at 0x12033ba40>), 12),\n",
       " (('μέγεθος', <spacy.lexeme.Lexeme at 0x11824fe40>), 12),\n",
       " (('βωμοῦ', <spacy.lexeme.Lexeme at 0x1182b9a80>), 12),\n",
       " (('ἀρχαῖον', <spacy.lexeme.Lexeme at 0x1204a72c0>), 11),\n",
       " (('ἔχουσιν', <spacy.lexeme.Lexeme at 0x1204a59c0>), 11),\n",
       " (('ἀπʼ', <spacy.lexeme.Lexeme at 0x12031c180>), 11),\n",
       " (('παῖδας', <spacy.lexeme.Lexeme at 0x12031f100>), 11),\n",
       " (('ἅτε', <spacy.lexeme.Lexeme at 0x12031fc80>), 11),\n",
       " (('ἀνδρὶ', <spacy.lexeme.Lexeme at 0x120325d80>), 11),\n",
       " (('ἱερὸν', <spacy.lexeme.Lexeme at 0x120327dc0>), 11),\n",
       " (('ἵπποι', <spacy.lexeme.Lexeme at 0x12033d6c0>), 11),\n",
       " (('ἐφεξῆς', <spacy.lexeme.Lexeme at 0x11823c9c0>), 11),\n",
       " (('ὁπόσα', <spacy.lexeme.Lexeme at 0x1181fb100>), 11),\n",
       " (('γέγραπται', <spacy.lexeme.Lexeme at 0x11f4d1940>), 11),\n",
       " (('ἔργα', <spacy.lexeme.Lexeme at 0x11f4bd1c0>), 11),\n",
       " (('γῆν', <spacy.lexeme.Lexeme at 0x1204a7380>), 10),\n",
       " (('παῖδα', <spacy.lexeme.Lexeme at 0x1204a7080>), 10),\n",
       " (('θεοῦ', <spacy.lexeme.Lexeme at 0x1204a74c0>), 10),\n",
       " (('χώρας', <spacy.lexeme.Lexeme at 0x12031d100>), 10),\n",
       " (('ἐπίκλησιν', <spacy.lexeme.Lexeme at 0x120327e00>), 10),\n",
       " (('ἕνεκα', <spacy.lexeme.Lexeme at 0x12032b6c0>), 10),\n",
       " (('λέγουσι', <spacy.lexeme.Lexeme at 0x120339140>), 10),\n",
       " (('λόγον', <spacy.lexeme.Lexeme at 0x120339dc0>), 10),\n",
       " (('Ἀθηναίων', <spacy.lexeme.Lexeme at 0x12033b8c0>), 10),\n",
       " (('λόγῳ', <spacy.lexeme.Lexeme at 0x12033c180>), 10),\n",
       " (('ἐποίησεν', <spacy.lexeme.Lexeme at 0x12033e240>), 10),\n",
       " (('ἀριστερᾷ', <spacy.lexeme.Lexeme at 0x12033e4c0>), 10),\n",
       " (('παρέχεται', <spacy.lexeme.Lexeme at 0x120348d40>), 10),\n",
       " (('Δία', <spacy.lexeme.Lexeme at 0x11826f240>), 10),\n",
       " (('Ὀλυμπιάδος', <spacy.lexeme.Lexeme at 0x11824e240>), 10),\n",
       " (('ἔχουσα', <spacy.lexeme.Lexeme at 0x11823e9c0>), 10),\n",
       " (('ἐλέφαντος', <spacy.lexeme.Lexeme at 0x11823b8c0>), 10),\n",
       " (('ποδῶν', <spacy.lexeme.Lexeme at 0x118225880>), 10),\n",
       " (('Ἀρτέμιδος', <spacy.lexeme.Lexeme at 0x1181f8e80>), 10),\n",
       " (('Ζεὺς', <spacy.lexeme.Lexeme at 0x118208a80>), 10),\n",
       " (('δρόμου', <spacy.lexeme.Lexeme at 0x1204a7b00>), 9)]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],

   "source": [
    "lexemes = [(t.text, t.lex) for t in pausanias_book['nlp_docs'].explode() if not t.is_stop and t.is_alpha]\n",
    "\n",
    "lexeme_counts = Counter(lexemes)\n",
    "\n",
    "lexeme_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait a second -- this list looks identical to our list of word types.\n",
    "\n",
    "Sure enough, when we check the SpaCy documentation for [Lexeme](https://spacy.io/api/lexeme):\n",
    "\n",
    "> A Lexeme has no string context – it’s a word type, as opposed to a word token. It therefore has no part-of-speech tag, dependency parse, or lemma (if lemmatization depends on the part-of-speech tag)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Review\n",
    "\n",
    "> Discuss: Define **token**, **type**, **stop word**, **lemma**, and **lexeme** in your own words.\n",
    "\n",
    "> Discuss: How can we use these different notions of \"word\" in our analysis of corpora? Why is it important to be precise about what kind of word(s) we're using?\n",
    "\n",
    "## Homework\n",
    "\n",
    "1. Read @Brezina2018 [ch. 2, pp. 41--65].\n",
    "2. Choose 3 books of Pausanias and calculate the most common tokens, types, and lemmata for each. In a paragraph or so, describe your findings relative to the work we have done in class today.\n",
    "3. Using your findings from 2., write a short (1-page) evaluation of one of the books of Pausanias that you have analyzed. Does your qualitative -- which is not to say \"subjective\" -- experience of reading the text cohere with your quantitative evaluation?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
