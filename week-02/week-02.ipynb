{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Week 2\n",
    "\n",
    "## Resources\n",
    "\n",
    "- https://ipython.readthedocs.io/en/stable/interactive/magics.html\n",
    "- https://www.opengreekandlatin.org/what-is-a-cts-urn/\n",
    "- https://cite-architecture.github.io/xcite/ctsurn-quick/\n",
    "\n",
    "## Catch up and review\n",
    "\n",
    "### Reading a file into memory\n",
    "\n",
    "Can you read one of the files from last week into memory? Enter the code to do so below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "It is a truth universally acknowledged, that a single man in possession of a good fortune must be in want of a wife.\n",
      "\n",
      "However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered as the rightful property of some one or other of their daughters.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# your code for reading a file goes here.\n",
    "\n",
    "with open('../week-01/austen-pride-and-prejudice.txt') as f:\n",
    "    print(f.readlines())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Git forking, branching, and pushing\n",
    "\n",
    "In this section, we're going to talk about git forking, branching, and pushing, as this will be the main way that you'll submit homework.\n",
    "\n",
    "First, you'll want to navigate to the GitHub repository for this course (https://github.com/Tufts-2024-Quant-Text-Analysis/intro-text-analysis) and press the \"Fork\" button:\n",
    "\n",
    "![Screenshot of the Fork button](./img/fork.png)\n",
    "\n",
    "You should then see a menu that looks something like this:\n",
    "\n",
    "![Screenshot of Fork menu](./img/fork-menu.png)\n",
    "\n",
    "You can rename the repository if you wish, just make sure to keep track of what you rename it to!\n",
    "\n",
    "Once you have forked the main repository, go to your fork and click the \"Code\" button:\n",
    "\n",
    "![Screenshot of the Code button](./img/code.png)\n",
    "\n",
    "You can then clone your fork by copying the URL from the dropdown and entering the following in your terminal:\n",
    "\n",
    "```sh\n",
    "git clone YOUR_GIT_URL_HERE\n",
    "```\n",
    "\n",
    "### Setting up an upstream\n",
    "\n",
    "By default, your own fork of the repository will be the `origin` for this clone. It is a convention when working with git forks to call the \"main\" repository `upstream`. You can add `upstream` as a remote by running the following from within your clone:\n",
    "\n",
    "```sh\n",
    "git remote add upstream https://github.com/Tufts-2024-Quant-Text-Analysis/intro-text-analysis.git\n",
    "```\n",
    "\n",
    "If you know run `git remote -v` from that directory, you should see both `origin` and `upstream`.\n",
    "\n",
    "**NEVER** push directly to `upstream`. Instead, **`pull`** from `upstream` and **`push`** to your fork.\n",
    "\n",
    "Whenever you push your work to your fork, you can navigate to it (on the web) and see an option to create a Pull Request:\n",
    "\n",
    "![Screenshot of pull request](./img/pull-request.png)\n",
    "\n",
    "Try it now: create a small change (you can just add one of your answers to Week 01), and push it to your fork.\n",
    "\n",
    "I will create a branch that matches each of your usernames on the main repository. Open your pull request against this branch.\n",
    "\n",
    "Now we have an easy way of looking at the changes that you've made and comparing them to the main repository without clobbering each other's work.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Data \n",
    "\n",
    "### Discuss \n",
    "\n",
    "- What kind(s) of visualization would be best for showing the relative frequencies of a verb like καλός in the Platonic corpus versus Thucydides?\n",
    "\n",
    "Refer to @Brezina2018 [ch. 1] if you feel stuck.\n",
    "\n",
    "## Installing packages\n",
    "\n",
    "Inside a Jupyter/Colab notebook (they're functionally the same thing), you can install packages with the magic command `%pip`. See [here](https://ipython.readthedocs.io/en/stable/interactive/magics.html) for more info on iPython/Jupyter Notebook magic commands.\n",
    "\n",
    "We're going to need the `lxml` package in a moment, so let's go ahead and install it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CTS URNs\n",
    "\n",
    "Before we go further, we're going to need to talk a bit about Canonical Text Services Universal Resource Names -- or **CTS URN**s for short.\n",
    "\n",
    "### Collection\n",
    "\n",
    "CTS URNs allow us to specify text down to the token level. They work as references to specific components of a larger corpus, starting with the **collection**.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit\n",
    "```\n",
    "\n",
    "The prefix `urn:cts:` is required by the protocol; `greekLit` refers to the collection of Greek texts known to the CTS implementation.\n",
    "\n",
    "### Work Component\n",
    "\n",
    "The next element in a CTS URN is collectively referred to as the **work component**. At a minimum, it contains a reference to a **text group**. \n",
    "\n",
    "#### Text Group\n",
    "\n",
    "Text groups are often what we think of as authors, but by treating them as placeholders not for a specific writer but for canonically related texts, we can stay one step ahead of issues about attribution etc. Text groups are not meant to make any assertions about authorship; they're just a convenient way to find things.\n",
    "\n",
    "For example, the _Rhesus_ is contained within the Euripides text group by convention; we aren't weighing in on that vexed authorship question.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525\n",
    "```\n",
    "\n",
    "`tlg0525` refers to Pausanias. You can use https://cts.perseids.org/ to look up URNs, but since we'll be working a lot with Pausanias' _Periegesis_, it might be a good idea to get used to tlg0525.\n",
    "\n",
    "Why `tlg0525` and not just `pausanias`? Names and their orthography are hard to standardize. CTS URNs are designed to be **universal** and portable. Using names as identifiers too early on would lead to unnecessary confusion.\n",
    "\n",
    "Should we have settled on a system other than the numbering that the TLG came up with? Probably, but we're decades too late to change that now.\n",
    "\n",
    "\n",
    "#### Work\n",
    "\n",
    "Next comes the **work**. This refers to the item -- in our case it will usually be a text -- under the text group.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001\n",
    "```\n",
    "\n",
    "Notice that `tlg001` is separated from `tlg0525` by a `.`, rather than a `:`. This is because only major components of the URN are separated by `:`; minor components, such as the sub-components of the major **work component**, are separated by `.`.\n",
    "\n",
    "Works within the work component are usually numbered sequentially for the items that we're dealing with. For Sophocles, the sequence starts with _Trachiniae_, so `urn:cts:greekLit:tlg0011.tlg001` refers to that text; `urn:cts:greekLit:tlg0011.tlg003`, for example, refers to _Ajax_.\n",
    "\n",
    "#### Version\n",
    "\n",
    "For classical texts, which have any number of editions published over the years, the **version** is essential. It helps us point to a specific edition of the work, complete with that editions editorial interventions.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001.perseus-grc2\n",
    "```\n",
    "\n",
    "The `perseus-grc2` version refers to the second Greek edition of the _Periegesis_ as published by the Perseus Digital Library.\n",
    "\n",
    "#### Exemplar\n",
    "\n",
    "There is another element in the work component of CTS URNs, the **exemplar**. You might think of this as a reference to the specific _witness_ that you're dealing with.\n",
    "\n",
    "We won't need to use this much for retrieving texts, but if you're working on different ways of handling textual material, you might want to append an exemplar fragment to the work component.\n",
    "\n",
    "For example, if I've made additional annotations to the Perseus _Periegesis_ for my own research that don't necessarily belong in the canonical version (via a pull request vel sim.), I might dub my local exemplar:\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001.perseus-grc2.charles-annotations\n",
    "```\n",
    "\n",
    "That way I know that this URN refers to an exemplar that contains annotations that might not be present in the parent `perseus-grc2`.\n",
    "\n",
    "I want to emphasize, again, you can get through this course just fine without ever using an exemplar fragment. They're under-specified and confusing, but I mention them here for the sake of completeness.\n",
    "\n",
    "### Passage Component\n",
    "\n",
    "Finally, CTS URNs can have a **passage component**. This is the most specific part of the CTS URN, containing references to precise passages and even words within a text.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:1\n",
    "```\n",
    "\n",
    "The `1` above refers to Pausanias Book 1.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:1.1\n",
    "```\n",
    "\n",
    "Now it references Book 1, Chapter 1.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:1.1-2.2\n",
    "```\n",
    "\n",
    "Now we're talking about a passage spanning Book 1, Chapter 1, to Book 2, Chapter 2.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:1.1.5@Κωλιάς\n",
    "```\n",
    "\n",
    "Now we're referencing the token `Κωλιάς` in Book 1, Chapter 1, Section 5.\n",
    "\n",
    "```\n",
    "urn:cts:greekLit:tlg0525.tlg001.perseus-grc2:1.1.5@Κωλιάδος-1.1.5@θεαί\n",
    "```\n",
    "\n",
    "As a final example, this URN references the span from Κωλιάδος to θεαί in Book 1, Chapter 1, Section 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting text to work with\n",
    "\n",
    "So why this detour on CTS URNs? Because it will make it easier for you to find the texts that you need. I've already added the perseus-grc2 version of Pausanias to this repository; you can find it under `tei/tlg0525.tlg001.perseus-grc2.xml`. (The URN is abbreviated because the file comes from the [PerseusDL/canonical-greekLit](https://github.com/PerseusDL/canonical-greekLit/) repo on GitHub.)\n",
    "\n",
    "Ideally, we would be able to request these texts from an API, but as of this writing in August 2024, all of the known APIs are not working. So for now, we will parse these files locally and transform them into data structures that facilitate our analyses.\n",
    "\n",
    "We'll first need to install the MyCapytains library."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MyCapytain in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (3.0.2)\n",
      "Requirement already satisfied: requests>=2.8.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from MyCapytain) (2.32.3)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from MyCapytain) (1.16.0)\n",
      "Requirement already satisfied: lxml>=3.6.4 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from MyCapytain) (5.2.2)\n",
      "Requirement already satisfied: future>=0.16.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from MyCapytain) (1.0.0)\n",
      "Requirement already satisfied: rdflib-jsonld>=0.4.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from MyCapytain) (0.6.2)\n",
      "Requirement already satisfied: LinkHeader>=0.4.3 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from MyCapytain) (0.4.3)\n",
      "Requirement already satisfied: pyld>=1.0.3 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from MyCapytain) (2.0.4)\n",
      "Requirement already satisfied: typing in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from MyCapytain) (3.7.4.3)\n",
      "Requirement already satisfied: cachetools in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from pyld>=1.0.3->MyCapytain) (5.4.0)\n",
      "Requirement already satisfied: frozendict in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from pyld>=1.0.3->MyCapytain) (2.4.4)\n",
      "Requirement already satisfied: rdflib>=5.0.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from rdflib-jsonld>=0.4.0->MyCapytain) (7.0.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests>=2.8.1->MyCapytain) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests>=2.8.1->MyCapytain) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests>=2.8.1->MyCapytain) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests>=2.8.1->MyCapytain) (2024.7.4)\n",
      "Requirement already satisfied: isodate<0.7.0,>=0.6.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from rdflib>=5.0.0->rdflib-jsonld>=0.4.0->MyCapytain) (0.6.1)\n",
      "Requirement already satisfied: pyparsing<4,>=2.1.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from rdflib>=5.0.0->rdflib-jsonld>=0.4.0->MyCapytain) (3.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/pletcher/code/classes/quant-text-analysis/.venv/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install MyCapytain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can import this module and use it to ingest the text of Pausanias, stored in the `tei/` directory of this repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyCapytain.resources.texts.local.capitains.cts import CapitainsCtsText\n",
    "\n",
    "with open(\"../tei/tlg0525.tlg001.perseus-eng2.xml\") as f:\n",
    "    text = CapitainsCtsText(urn=\"urn:cts:greekLit:tlg0525.tlg001.perseus-eng2\", resource=f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try turning the text into just a [Pandas DataFrame](https://pandas.pydata.org/docs/index.html) with columns for the CTS URN, the corresponding XML, and the unannotated text of the passage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this block might take a while\n",
    "\n",
    "from lxml import etree\n",
    "from MyCapytain.common.constants import Mimetypes\n",
    "\n",
    "urns = []\n",
    "raw_xmls = []\n",
    "unannotated_strings = []\n",
    "\n",
    "for ref in text.getReffs(level=len(text.citation)):\n",
    "    urn = f\"{text.urn}:{ref}\"\n",
    "    node = text.getTextualNode(ref)\n",
    "    raw_xml = node.export(Mimetypes.XML.TEI)\n",
    "    tree = node.export(Mimetypes.PYTHON.ETREE)\n",
    "    s = etree.tostring(tree, encoding=\"unicode\", method=\"text\")\n",
    "\n",
    "    urns.append(urn)\n",
    "    raw_xmls.append(raw_xml)\n",
    "    unannotated_strings.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {\n",
    "    \"urn\": pd.Series(urns, dtype=\"string\"),\n",
    "    \"raw_xml\": raw_xmls,\n",
    "    \"unannotated_strings\": pd.Series(unannotated_strings, dtype=\"string\")\n",
    "}\n",
    "pausanias_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with textual data\n",
    "\n",
    "Now that we have some text to work with -- and by \"some text,\" I mean all 3170 sections of Pausanias in the above DataFrame -- we can start working with the data.\n",
    "\n",
    "Before doing so, however, we should ask _how_ we're going to make the data more manageable -- it isn't exactly feasible to dive headfirst into a corpus of this size.\n",
    "\n",
    "> Discuss: What units can we break Pausanias down into to make it more manageable? Don't worry about how you would do it in code yet, just think about how you might explore the units of the text.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Types of words\n",
    "\n",
    "With all languages, but especially with heavily-inflected languages like ancient Greek and Latin, it is important to be precise about the kinds of word forms that we're dealing with.\n",
    "\n",
    "#### Tokens \n",
    "\n",
    "A **token** or **running word** \"is a single occurrence of a word form in the text\" [@Brezina2018 39].\n",
    "\n",
    "How can we count the number of tokens in all of Pausanias? First we need to **tokenize** the `unannotated_strings` column of `pausanias_df`.\n",
    "\n",
    "Tokenization is a surprisingly complicated process depending on the language of study, and we will learn more sophisticated methods for tokenizing Greek text as we go along.\n",
    "\n",
    "For now, however, let's define a token as \"whitespace-delimited text\" -- we're not going to worry about punctuation etc. just yet.\n",
    "\n",
    "So to tokenize the `unannotated_strings` column of `pausanias_df`, we can run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urn</th>\n",
       "      <th>raw_xml</th>\n",
       "      <th>unannotated_strings</th>\n",
       "      <th>whitespaced_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>On the Greek mainland facing the Cyclades Isla...</td>\n",
       "      <td>[On, the, Greek, mainland, facing, the, Cyclad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The Peiraeus was a parish from early times, th...</td>\n",
       "      <td>[The, Peiraeus, was, a, parish, from, early, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The most noteworthy sight in the Peiraeus is a...</td>\n",
       "      <td>[The, most, noteworthy, sight, in, the, Peirae...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The Athenians have also another harbor, at Mun...</td>\n",
       "      <td>[The, Athenians, have, also, another, harbor,,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>Twenty stades away is the Coliad promontory; o...</td>\n",
       "      <td>[Twenty, stades, away, is, the, Coliad, promon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3165</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>These, then, live above Amphissa. On the coast...</td>\n",
       "      <td>[These,, then,, live, above, Amphissa., On, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3166</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>I gather that the city got its name from a wom...</td>\n",
       "      <td>[I, gather, that, the, city, got, its, name, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3167</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The epic poem called the Naupactia by the Gree...</td>\n",
       "      <td>[The, epic, poem, called, the, Naupactia, by, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3168</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>Here there is on the coast a temple of Poseido...</td>\n",
       "      <td>[Here, there, is, on, the, coast, a, temple, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3169</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The sanctuary of Asclepius I found in ruins, b...</td>\n",
       "      <td>[The, sanctuary, of, Asclepius, I, found, in, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3170 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    urn  \\\n",
       "0     urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...   \n",
       "1     urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...   \n",
       "2     urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...   \n",
       "3     urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...   \n",
       "4     urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...   \n",
       "...                                                 ...   \n",
       "3165  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...   \n",
       "3166  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...   \n",
       "3167  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...   \n",
       "3168  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...   \n",
       "3169  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:1...   \n",
       "\n",
       "                                                raw_xml  \\\n",
       "0     <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1     <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "2     <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "3     <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "4     <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "...                                                 ...   \n",
       "3165  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "3166  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "3167  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "3168  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "3169  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "\n",
       "                                    unannotated_strings  \\\n",
       "0     On the Greek mainland facing the Cyclades Isla...   \n",
       "1     The Peiraeus was a parish from early times, th...   \n",
       "2     The most noteworthy sight in the Peiraeus is a...   \n",
       "3     The Athenians have also another harbor, at Mun...   \n",
       "4     Twenty stades away is the Coliad promontory; o...   \n",
       "...                                                 ...   \n",
       "3165  These, then, live above Amphissa. On the coast...   \n",
       "3166  I gather that the city got its name from a wom...   \n",
       "3167  The epic poem called the Naupactia by the Gree...   \n",
       "3168  Here there is on the coast a temple of Poseido...   \n",
       "3169  The sanctuary of Asclepius I found in ruins, b...   \n",
       "\n",
       "                                     whitespaced_tokens  \n",
       "0     [On, the, Greek, mainland, facing, the, Cyclad...  \n",
       "1     [The, Peiraeus, was, a, parish, from, early, t...  \n",
       "2     [The, most, noteworthy, sight, in, the, Peirae...  \n",
       "3     [The, Athenians, have, also, another, harbor,,...  \n",
       "4     [Twenty, stades, away, is, the, Coliad, promon...  \n",
       "...                                                 ...  \n",
       "3165  [These,, then,, live, above, Amphissa., On, th...  \n",
       "3166  [I, gather, that, the, city, got, its, name, f...  \n",
       "3167  [The, epic, poem, called, the, Naupactia, by, ...  \n",
       "3168  [Here, there, is, on, the, coast, a, temple, o...  \n",
       "3169  [The, sanctuary, of, Asclepius, I, found, in, ...  \n",
       "\n",
       "[3170 rows x 4 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See https://pandas.pydata.org/docs/reference/api/pandas.Series.str.split.html for\n",
    "# panda's string-splitting utilities; it splits on whitespace by default\n",
    "pausanias_df['whitespaced_tokens'] = pausanias_df['unannotated_strings'].str.split()\n",
    "\n",
    "pausanias_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, now that we have some arrays of tokens in `whitespaced_tokens` column, how do we count them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "272522"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(ts) for ts in pausanias_df['whitespaced_tokens'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Discuss: What does the above line of code do? gets number of tokens in data frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above line of code is not very idiomatic for Pandas, however. Instead, we should write something like the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "217416"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pausanias_df['whitespaced_tokens'].explode().count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Types\n",
    "\n",
    "A **type** is a unique word form in the corpus. For example, the inflected forms βουλεύεται and βουλεύομεν are each a type. (See @Brezina2018 [39-40].)\n",
    "\n",
    "In other words, **types** are **tokens** grouped by form. So to count the number of **types** in Pausanias, we can do the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "41363"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(pausanias_df['whitespaced_tokens'].explode().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Discuss: Break the above line of code down method by method. Answer: Amount of tokens that only appear once in the data frame aka, we have 25716 different types\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if we want to see the top `n` types in the corpus?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2075),\n",
       " ('of', 1296),\n",
       " ('and', 662),\n",
       " ('to', 658),\n",
       " ('a', 532),\n",
       " ('in', 384),\n",
       " ('is', 377),\n",
       " ('was', 308),\n",
       " ('that', 265),\n",
       " ('they', 199),\n",
       " ('by', 197),\n",
       " ('from', 195),\n",
       " ('he', 190),\n",
       " ('his', 178),\n",
       " ('with', 149),\n",
       " ('son', 148),\n",
       " ('The', 146),\n",
       " ('at', 141),\n",
       " ('it', 138),\n",
       " ('on', 136),\n",
       " ('for', 122),\n",
       " ('are', 119),\n",
       " ('this', 118),\n",
       " ('who', 116),\n",
       " ('had', 113),\n",
       " ('as', 111),\n",
       " ('their', 111),\n",
       " ('were', 102),\n",
       " ('but', 102),\n",
       " ('an', 100),\n",
       " ('which', 97),\n",
       " ('not', 92),\n",
       " ('sanctuary', 87),\n",
       " ('have', 85),\n",
       " ('Lacedaemonians', 84),\n",
       " ('I', 83),\n",
       " ('called', 83),\n",
       " ('when', 79),\n",
       " ('also', 78),\n",
       " ('image', 68),\n",
       " ('be', 64),\n",
       " ('them', 61),\n",
       " ('him', 61),\n",
       " ('say', 61),\n",
       " ('been', 58),\n",
       " ('there', 55),\n",
       " ('one', 53),\n",
       " ('made', 51),\n",
       " ('On', 50),\n",
       " ('against', 50),\n",
       " ('after', 48),\n",
       " ('temple', 45),\n",
       " ('into', 39),\n",
       " ('other', 39),\n",
       " ('In', 39),\n",
       " ('because', 39),\n",
       " ('There', 39),\n",
       " ('place', 38),\n",
       " ('has', 38),\n",
       " ('all', 38),\n",
       " ('her', 37),\n",
       " ('stades', 37),\n",
       " ('time', 36),\n",
       " ('They', 35),\n",
       " ('king', 34),\n",
       " ('came', 33),\n",
       " ('up', 33),\n",
       " ('B.C.', 33),\n",
       " ('first', 32),\n",
       " ('said', 32),\n",
       " ('being', 30),\n",
       " ('those', 29),\n",
       " ('name', 29),\n",
       " ('so', 29),\n",
       " ('out', 29),\n",
       " ('what', 28),\n",
       " ('most', 28),\n",
       " ('Heracles', 28),\n",
       " ('upon', 28),\n",
       " ('For', 28),\n",
       " ('about', 27),\n",
       " ('But', 27),\n",
       " ('city', 27),\n",
       " ('war', 27),\n",
       " ('you', 27),\n",
       " ('left', 26),\n",
       " ('than', 26),\n",
       " ('before', 26),\n",
       " ('Apollo', 26),\n",
       " ('where', 26),\n",
       " ('my', 26),\n",
       " ('here', 26),\n",
       " ('When', 25),\n",
       " ('took', 25),\n",
       " ('sons', 25),\n",
       " ('people', 25),\n",
       " ('It', 25),\n",
       " ('she', 25),\n",
       " ('set', 24),\n",
       " ('brought', 24)]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#shows us the top 100 types in the data frame\n",
    "from collections import Counter\n",
    "#counter is a python library\n",
    "\n",
    "type_counts = Counter(pausanias_df['whitespaced_tokens'].explode())\n",
    "#counts the amount of types in dataframe\n",
    "\n",
    "type_counts.most_common(100)\n",
    "#finds 100 most common types"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stop words\n",
    "\n",
    "Hm, that's not particularly interesting -- most of these words are fairly common and will rank highly in almost any corpus. Further, since we haven't accounted for punctuation, we're probably generating frequencies incorrectly based on whether or not a type is joined to any punctuation. We need to get a bit more sophisticated.\n",
    "\n",
    "Let's install `spacy` and `grecy` to perform better tokenization and incorporate the notion of a **stop word**: a token that is so common that including it in most statistical analyses will just generate noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy[apple] in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy[apple]) (1.26.4)\n",
      "Collecting thinc-apple-ops<1.0.0,>=0.1.0.dev0 (from spacy[apple])\n",
      "  Downloading thinc_apple_ops-0.1.5-cp311-cp311-macosx_11_0_arm64.whl.metadata (5.6 kB)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy[apple]) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[apple]) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[apple]) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy[apple]) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy[apple]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy[apple]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy[apple]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy[apple]) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy[apple]) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy[apple]) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy[apple]) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy[apple]) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy[apple]) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy[apple]) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy[apple]) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from jinja2->spacy[apple]) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy[apple]) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[apple]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[apple]) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy[apple]) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy[apple]) (0.1.2)\n",
      "Downloading thinc_apple_ops-0.1.5-cp311-cp311-macosx_11_0_arm64.whl (155 kB)\n",
      "\u001b[2K   \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.5/155.5 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mm eta \u001b[36m0:00:01\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: thinc-apple-ops\n",
      "Successfully installed thinc-apple-ops-0.1.5\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/pletcher/code/classes/quant-text-analysis/.venv/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: grecy in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (1.0)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.5 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from grecy) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.5->grecy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5->grecy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5->grecy) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5->grecy) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.5->grecy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.5->grecy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.5->grecy) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.5->grecy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from jinja2->spacy<4.0.0,>=3.5->grecy) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.5->grecy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.5->grecy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (0.1.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49m/Users/pletcher/code/classes/quant-text-analysis/.venv/bin/python -m pip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Uncomment the line for your system's architecture\n",
    "%pip install spacy\n",
    "# %pip install 'spacy[apple]'\n",
    "%pip install grecy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to install a model for `grecy` to use. Note that there is a known but so-far unpatched issue where this command will only work with Python 3.11.9 and pip 24.0 (or a bit older in either case)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Installing grc_proiel_trf.....\n",
      "\n",
      "Please wait, this could take some minutes.....\n",
      "\n",
      "Collecting grc-proiel-trf==any\n",
      "Downloading https://huggingface.co/Jacobo/grc_proiel_trf/resolve/main/grc_proiel_trf-any-py3-none-any.whl (497.5 MB)\n",
      "\u001b[?25l     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/497.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\n",
      "\u001b[2K     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/497.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:04:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.4/497.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:01:40\u001b[0m\n",
      "\u001b[2K     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.5/497.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:01:42\u001b[0m\n",
      "\u001b[2K     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/497.5 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:01:44\u001b[0m\n",
      "\u001b[2K     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.9/497.5 MB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:01:40\u001b[0m\n",
      "\u001b[2K     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/497.5 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:01:37\u001b[0m\n",
      "\u001b[2K     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/497.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:01:32\u001b[0m\n",
      "\u001b[2K     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/497.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:01:25\u001b[0m\n",
      "\u001b[2K     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/497.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:01:18\u001b[0m\n",
      "\u001b[2K     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/497.5 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:01:13\u001b[0m\n",
      "\u001b[2K     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/497.5 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:01:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/497.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:01:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/497.5 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:57\u001b[0m\n",
      "\u001b[2K     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/497.5 MB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:51\u001b[0m\n",
      "\u001b[2K     \u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/497.5 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:46\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/497.5 MB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:43\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/497.5 MB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:38\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/497.5 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:34\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/497.5 MB\u001b[0m \u001b[31m21.2 MB/s\u001b[0m eta \u001b[36m0:00:23\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/497.5 MB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:16\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.4/497.5 MB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:13\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.6/497.5 MB\u001b[0m \u001b[31m46.6 MB/s\u001b[0m eta \u001b[36m0:00:11\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.9/497.5 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.7/497.5 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m25.1/497.5 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.8/497.5 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30.4/497.5 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.0/497.5 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m32.4/497.5 MB\u001b[0m \u001b[31m52.2 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.9/497.5 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.7/497.5 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.1/497.5 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:10\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.4/497.5 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.7/497.5 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.4/497.5 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/497.5 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/497.5 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/497.5 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.5/497.5 MB\u001b[0m \u001b[31m33.5 MB/s\u001b[0m eta \u001b[36m0:00:14\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.3/497.5 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:13\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.8/497.5 MB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:14\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.4/497.5 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:14\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.0/497.5 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:13\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.5/497.5 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.1/497.5 MB\u001b[0m \u001b[31m67.5 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/497.5 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.4/497.5 MB\u001b[0m \u001b[31m65.3 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/497.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:11\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/497.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:11\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/497.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:11\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/497.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:11\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.4/497.5 MB\u001b[0m \u001b[31m25.3 MB/s\u001b[0m eta \u001b[36m0:00:18\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.5/497.5 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:18\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.1/497.5 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:18\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.8/497.5 MB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:17\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.6/497.5 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.3/497.5 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.1/497.5 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.6/497.5 MB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.2/497.5 MB\u001b[0m \u001b[31m62.8 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.7/497.5 MB\u001b[0m \u001b[31m66.6 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/497.5 MB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.5/497.5 MB\u001b[0m \u001b[31m65.6 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.2/497.5 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m96.4/497.5 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/497.5 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.8/497.5 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.7/497.5 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.9/497.5 MB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m107.2/497.5 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m109.3/497.5 MB\u001b[0m \u001b[31m48.4 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m111.7/497.5 MB\u001b[0m \u001b[31m56.0 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.0/497.5 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m112.4/497.5 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:10\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.8/497.5 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:11\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.2/497.5 MB\u001b[0m \u001b[31m44.2 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m119.6/497.5 MB\u001b[0m \u001b[31m45.4 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.0/497.5 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.4/497.5 MB\u001b[0m \u001b[31m62.9 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.0/497.5 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.0/497.5 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.2/497.5 MB\u001b[0m \u001b[31m47.5 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.5/497.5 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.4/497.5 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m135.5/497.5 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.0/497.5 MB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.5/497.5 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/497.5 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.0/497.5 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.0/497.5 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.0/497.5 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.8/497.5 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:10\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.3/497.5 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:10\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.9/497.5 MB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.0/497.5 MB\u001b[0m \u001b[31m38.0 MB/s\u001b[0m eta \u001b[36m0:00:10\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m154.0/497.5 MB\u001b[0m \u001b[31m37.2 MB/s\u001b[0m eta \u001b[36m0:00:10\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.6/497.5 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.9/497.5 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.1/497.5 MB\u001b[0m \u001b[31m56.6 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.5/497.5 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/497.5 MB\u001b[0m \u001b[31m51.6 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m165.5/497.5 MB\u001b[0m \u001b[31m50.5 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.5/497.5 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.5/497.5 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m171.8/497.5 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.7/497.5 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.5/497.5 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m175.5/497.5 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/497.5 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/497.5 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.0/497.5 MB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m176.7/497.5 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:12\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.9/497.5 MB\u001b[0m \u001b[31m32.0 MB/s\u001b[0m eta \u001b[36m0:00:10\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.1/497.5 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:11\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m182.8/497.5 MB\u001b[0m \u001b[31m27.9 MB/s\u001b[0m eta \u001b[36m0:00:12\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m185.0/497.5 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:12\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.5/497.5 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.3/497.5 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.3/497.5 MB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.2/497.5 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.0/497.5 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.6/497.5 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.4/497.5 MB\u001b[0m \u001b[31m47.6 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m198.4/497.5 MB\u001b[0m \u001b[31m48.8 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.0/497.5 MB\u001b[0m \u001b[31m45.3 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.5/497.5 MB\u001b[0m \u001b[31m35.7 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m201.1/497.5 MB\u001b[0m \u001b[31m34.5 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m203.2/497.5 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.4/497.5 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m206.1/497.5 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.9/497.5 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/497.5 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/497.5 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/497.5 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.0/497.5 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m208.1/497.5 MB\u001b[0m \u001b[31m21.5 MB/s\u001b[0m eta \u001b[36m0:00:14\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.7/497.5 MB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:12\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.6/497.5 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:12\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m213.4/497.5 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:12\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.0/497.5 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:12\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m217.6/497.5 MB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:11\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.9/497.5 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m222.0/497.5 MB\u001b[0m \u001b[31m54.4 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.6/497.5 MB\u001b[0m \u001b[31m56.7 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m225.8/497.5 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m227.6/497.5 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.2/497.5 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m231.3/497.5 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/497.5 MB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.0/497.5 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m234.9/497.5 MB\u001b[0m \u001b[31m38.1 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.7/497.5 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.1/497.5 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.4/497.5 MB\u001b[0m \u001b[31m81.6 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m246.8/497.5 MB\u001b[0m \u001b[31m71.6 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m249.1/497.5 MB\u001b[0m \u001b[31m61.1 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m251.2/497.5 MB\u001b[0m \u001b[31m61.9 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.7/497.5 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m256.1/497.5 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m258.5/497.5 MB\u001b[0m \u001b[31m62.7 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m260.7/497.5 MB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.2/497.5 MB\u001b[0m \u001b[31m61.2 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m265.2/497.5 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m267.4/497.5 MB\u001b[0m \u001b[31m60.3 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.5/497.5 MB\u001b[0m \u001b[31m58.9 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m271.7/497.5 MB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.0/497.5 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m273.3/497.5 MB\u001b[0m \u001b[31m46.0 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.2/497.5 MB\u001b[0m \u001b[31m44.7 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m277.4/497.5 MB\u001b[0m \u001b[31m44.8 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.7/497.5 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m282.1/497.5 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.6/497.5 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m286.5/497.5 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.0/497.5 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.0/497.5 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.0/497.5 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.0/497.5 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m288.1/497.5 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m289.6/497.5 MB\u001b[0m \u001b[31m28.9 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m291.9/497.5 MB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m294.5/497.5 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m297.0/497.5 MB\u001b[0m \u001b[31m29.5 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━━\u001b[0m \u001b[32m299.4/497.5 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.9/497.5 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.5/497.5 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.0/497.5 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.0/497.5 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.0/497.5 MB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m305.1/497.5 MB\u001b[0m \u001b[31m33.3 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.2/497.5 MB\u001b[0m \u001b[31m33.1 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m309.4/497.5 MB\u001b[0m \u001b[31m32.8 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.3/497.5 MB\u001b[0m \u001b[31m32.2 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━━\u001b[0m \u001b[32m313.2/497.5 MB\u001b[0m \u001b[31m31.4 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m315.8/497.5 MB\u001b[0m \u001b[31m55.8 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m318.0/497.5 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m319.4/497.5 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m319.4/497.5 MB\u001b[0m \u001b[31m58.7 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m319.9/497.5 MB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m320.0/497.5 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m320.0/497.5 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m320.0/497.5 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m320.0/497.5 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m320.0/497.5 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m320.0/497.5 MB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m320.8/497.5 MB\u001b[0m \u001b[31m20.1 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m324.6/497.5 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━━\u001b[0m \u001b[32m326.8/497.5 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━\u001b[0m \u001b[32m329.4/497.5 MB\u001b[0m \u001b[31m21.3 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━\u001b[0m \u001b[32m331.6/497.5 MB\u001b[0m \u001b[31m71.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━\u001b[0m \u001b[32m334.2/497.5 MB\u001b[0m \u001b[31m62.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━\u001b[0m \u001b[32m336.0/497.5 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━\u001b[0m \u001b[32m336.0/497.5 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━\u001b[0m \u001b[32m337.1/497.5 MB\u001b[0m \u001b[31m45.6 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━━\u001b[0m \u001b[32m338.5/497.5 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m340.6/497.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m340.6/497.5 MB\u001b[0m \u001b[31m40.6 MB/s\u001b[0m eta \u001b[36m0:00:04\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m342.6/497.5 MB\u001b[0m \u001b[31m33.9 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m345.1/497.5 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m345.4/497.5 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m345.4/497.5 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m345.4/497.5 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m345.4/497.5 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m345.4/497.5 MB\u001b[0m \u001b[31m33.7 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m345.6/497.5 MB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m347.8/497.5 MB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m348.9/497.5 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m348.9/497.5 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m348.9/497.5 MB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:07\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m350.5/497.5 MB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m352.0/497.5 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m352.0/497.5 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m352.0/497.5 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:08\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━━\u001b[0m \u001b[32m352.1/497.5 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━\u001b[0m \u001b[32m354.2/497.5 MB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:09\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━\u001b[0m \u001b[32m356.5/497.5 MB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━━\u001b[0m \u001b[32m358.9/497.5 MB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:06\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━\u001b[0m \u001b[32m361.2/497.5 MB\u001b[0m \u001b[31m34.0 MB/s\u001b[0m eta \u001b[36m0:00:05\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━\u001b[0m \u001b[32m363.4/497.5 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━━\u001b[0m \u001b[32m365.8/497.5 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━\u001b[0m \u001b[32m368.0/497.5 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━\u001b[0m \u001b[32m370.1/497.5 MB\u001b[0m \u001b[31m59.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━━\u001b[0m \u001b[32m372.5/497.5 MB\u001b[0m \u001b[31m60.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━\u001b[0m \u001b[32m374.6/497.5 MB\u001b[0m \u001b[31m58.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━\u001b[0m \u001b[32m375.5/497.5 MB\u001b[0m \u001b[31m52.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━━\u001b[0m \u001b[32m377.5/497.5 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m380.2/497.5 MB\u001b[0m \u001b[31m53.5 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m382.7/497.5 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m385.0/497.5 MB\u001b[0m \u001b[31m55.6 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m386.8/497.5 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m386.8/497.5 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m390.4/497.5 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━━\u001b[0m \u001b[32m392.6/497.5 MB\u001b[0m \u001b[31m51.8 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━\u001b[0m \u001b[32m394.3/497.5 MB\u001b[0m \u001b[31m48.9 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━\u001b[0m \u001b[32m396.8/497.5 MB\u001b[0m \u001b[31m49.8 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━━\u001b[0m \u001b[32m398.9/497.5 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━\u001b[0m \u001b[32m400.7/497.5 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━\u001b[0m \u001b[32m400.7/497.5 MB\u001b[0m \u001b[31m55.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━━\u001b[0m \u001b[32m402.2/497.5 MB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━\u001b[0m \u001b[32m406.3/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━\u001b[0m \u001b[32m408.7/497.5 MB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━\u001b[0m \u001b[32m410.4/497.5 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━━\u001b[0m \u001b[32m412.4/497.5 MB\u001b[0m \u001b[31m69.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━\u001b[0m \u001b[32m414.4/497.5 MB\u001b[0m \u001b[31m60.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━\u001b[0m \u001b[32m416.3/497.5 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━━\u001b[0m \u001b[32m418.7/497.5 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m421.0/497.5 MB\u001b[0m \u001b[31m56.8 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m423.4/497.5 MB\u001b[0m \u001b[31m57.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m425.9/497.5 MB\u001b[0m \u001b[31m62.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m427.2/497.5 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m427.3/497.5 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m427.3/497.5 MB\u001b[0m \u001b[31m48.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m427.3/497.5 MB\u001b[0m \u001b[31m36.5 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m427.3/497.5 MB\u001b[0m \u001b[31m31.7 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m427.3/497.5 MB\u001b[0m \u001b[31m28.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m429.3/497.5 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━━\u001b[0m \u001b[32m431.6/497.5 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━\u001b[0m \u001b[32m434.1/497.5 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━━\u001b[0m \u001b[32m436.2/497.5 MB\u001b[0m \u001b[31m27.0 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━\u001b[0m \u001b[32m438.6/497.5 MB\u001b[0m \u001b[31m59.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━\u001b[0m \u001b[32m441.2/497.5 MB\u001b[0m \u001b[31m60.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━━\u001b[0m \u001b[32m443.8/497.5 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m446.5/497.5 MB\u001b[0m \u001b[31m67.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m448.0/497.5 MB\u001b[0m \u001b[31m63.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m449.1/497.5 MB\u001b[0m \u001b[31m54.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m451.6/497.5 MB\u001b[0m \u001b[31m54.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m454.1/497.5 MB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━━\u001b[0m \u001b[32m456.3/497.5 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━\u001b[0m \u001b[32m458.4/497.5 MB\u001b[0m \u001b[31m63.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━\u001b[0m \u001b[32m458.8/497.5 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━\u001b[0m \u001b[32m463.0/497.5 MB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━━\u001b[0m \u001b[32m464.0/497.5 MB\u001b[0m \u001b[31m60.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━\u001b[0m \u001b[32m465.1/497.5 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━\u001b[0m \u001b[32m467.3/497.5 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━━\u001b[0m \u001b[32m469.8/497.5 MB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m472.2/497.5 MB\u001b[0m \u001b[31m53.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m474.7/497.5 MB\u001b[0m \u001b[31m65.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m477.1/497.5 MB\u001b[0m \u001b[31m65.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m479.4/497.5 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m479.4/497.5 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m479.4/497.5 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m479.4/497.5 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m479.4/497.5 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m479.4/497.5 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m479.4/497.5 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m479.4/497.5 MB\u001b[0m \u001b[31m64.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m479.8/497.5 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m479.8/497.5 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m479.8/497.5 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m479.8/497.5 MB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m479.8/497.5 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m480.0/497.5 MB\u001b[0m \u001b[31m15.7 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m481.6/497.5 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:02\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m\u001b[38;5;237m━\u001b[0m \u001b[32m483.9/497.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m \u001b[32m486.5/497.5 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;5;237m╺\u001b[0m \u001b[32m488.8/497.5 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m491.3/497.5 MB\u001b[0m \u001b[31m63.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m492.8/497.5 MB\u001b[0m \u001b[31m58.2 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m494.6/497.5 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m494.6/497.5 MB\u001b[0m \u001b[31m57.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;249;38;114m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[38;2;249;38;114m╸\u001b[0m \u001b[32m497.4/497.5 MB\u001b[0m \u001b[31m49.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[2K     \u001b[38;2;114;156;31m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m497.5/497.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.5 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from grc-proiel-trf==any) (3.7.5)\n",
      "Requirement already satisfied: spacy-transformers<1.4.0,>=1.3.5 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from grc-proiel-trf==any) (1.3.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (0.12.3)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (2.8.2)\n",
      "Requirement already satisfied: jinja2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (65.5.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (1.26.4)\n",
      "Requirement already satisfied: transformers<4.37.0,>=3.4.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy-transformers<1.4.0,>=1.3.5->grc-proiel-trf==any) (4.36.2)\n",
      "Requirement already satisfied: torch>=1.8.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy-transformers<1.4.0,>=1.3.5->grc-proiel-trf==any) (2.4.0)\n",
      "Requirement already satisfied: spacy-alignments<1.0.0,>=0.7.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from spacy-transformers<1.4.0,>=1.3.5->grc-proiel-trf==any) (0.9.1)\n",
      "Requirement already satisfied: language-data>=1.2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (4.12.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (2024.7.4)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (0.1.5)\n",
      "Requirement already satisfied: filelock in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.5->grc-proiel-trf==any) (3.15.4)\n",
      "Requirement already satisfied: sympy in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.5->grc-proiel-trf==any) (1.13.2)\n",
      "Requirement already satisfied: networkx in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.5->grc-proiel-trf==any) (3.3)\n",
      "Requirement already satisfied: fsspec in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.5->grc-proiel-trf==any) (2024.6.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.5->grc-proiel-trf==any) (0.24.5)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.5->grc-proiel-trf==any) (6.0.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.5->grc-proiel-trf==any) (2024.7.24)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.5->grc-proiel-trf==any) (0.15.2)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from transformers<4.37.0,>=3.4.0->spacy-transformers<1.4.0,>=1.3.5->grc-proiel-trf==any) (0.4.4)\n",
      "Requirement already satisfied: click>=8.0.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (13.7.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (0.18.1)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (2.1.5)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (2.18.0)\n",
      "Requirement already satisfied: wrapt in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (1.16.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from sympy->torch>=1.8.0->spacy-transformers<1.4.0,>=1.3.5->grc-proiel-trf==any) (1.3.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Users/pletcher/code/classes/quant-text-analysis/.venv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.5->grc-proiel-trf==any) (0.1.2)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%run -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nlp.tokenizer\n",
    "\n",
    "pausanias_df['tokens'] = pausanias_df['unannotated_strings'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The tokenization process through SpaCy adds some features to each of the tokens in the `tokens` column. Now we can collect the types and exclude stop words using the `token.is_stop` attribute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('son', 155),\n",
       " ('Lacedaemonians', 108),\n",
       " ('sanctuary', 94),\n",
       " ('called', 91),\n",
       " ('image', 71),\n",
       " ('place', 56),\n",
       " ('city', 46),\n",
       " ('temple', 46),\n",
       " ('king', 45),\n",
       " ('Heracles', 45),\n",
       " ('time', 45),\n",
       " ('Sparta', 44),\n",
       " ('stades', 42),\n",
       " ('Apollo', 37),\n",
       " ('said', 37),\n",
       " ('sea', 35),\n",
       " ('came', 35),\n",
       " ('Athena', 35),\n",
       " ('war', 34),\n",
       " ('sons', 33),\n",
       " ('Artemis', 33),\n",
       " ('throne', 32),\n",
       " ('Athenians', 29),\n",
       " ('Agesilaus', 28),\n",
       " ('land', 27),\n",
       " ('left', 27),\n",
       " ('people', 27),\n",
       " ('road', 27),\n",
       " ('Zeus', 26),\n",
       " ('took', 25),\n",
       " ('man', 25),\n",
       " ('Asclepius', 25),\n",
       " ('Cleomenes', 25),\n",
       " ('set', 24),\n",
       " ('daughter', 24),\n",
       " ('brought', 24),\n",
       " ('far', 24),\n",
       " ('Pausanias', 24),\n",
       " ('Agis', 23),\n",
       " ('statue', 23),\n",
       " ('hero', 22),\n",
       " ('Tyndareus', 21),\n",
       " ('oracle', 21),\n",
       " ('army', 21),\n",
       " ('old', 21),\n",
       " ('away', 20),\n",
       " ('tomb', 20),\n",
       " ('house', 20),\n",
       " ('battle', 20),\n",
       " ('Achilles', 20),\n",
       " ('Dionysus', 20),\n",
       " ('named', 19),\n",
       " ('death', 19),\n",
       " ('water', 19),\n",
       " ('Lacedaemon', 19),\n",
       " ('account', 19),\n",
       " ('Argives', 19),\n",
       " ('won', 19),\n",
       " ('god', 19),\n",
       " ('bronze', 19),\n",
       " ('Leonidas', 19),\n",
       " ('town', 18),\n",
       " ('died', 18),\n",
       " ('Archidamus', 18),\n",
       " ('Helen', 18),\n",
       " ('reason', 17),\n",
       " ('men', 17),\n",
       " ('come', 17),\n",
       " ('altar', 17),\n",
       " ('wooden', 17),\n",
       " ('built', 16),\n",
       " ('Hippocoon', 16),\n",
       " ('story', 16),\n",
       " ('Athens', 16),\n",
       " ('Leotychides', 16),\n",
       " ('way', 16),\n",
       " ('sacrifice', 16),\n",
       " ('surnamed', 16),\n",
       " ('race', 16),\n",
       " ('Aphrodite', 16),\n",
       " ('Dorians', 15),\n",
       " ('given', 15),\n",
       " ('sent', 15),\n",
       " ('know', 15),\n",
       " ('Lysander', 15),\n",
       " ('fight', 15),\n",
       " ('goddess', 15),\n",
       " ('images', 15),\n",
       " ('found', 14),\n",
       " ('island', 14),\n",
       " ('expedition', 14),\n",
       " ('think', 14),\n",
       " ('Messenians', 14),\n",
       " ('Lacedaemonian', 14),\n",
       " ('sacred', 14),\n",
       " ('gods', 14),\n",
       " ('seeing', 14),\n",
       " ('home', 14),\n",
       " ('right', 14),\n",
       " ('market', 14)]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "types = [t.text for t in pausanias_df['tokens'].explode() if not t.is_stop and t.is_alpha]\n",
    "#is_alpha is alphabetical characters\n",
    "\n",
    "type_counts = Counter(types)\n",
    "\n",
    "type_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Much better! We now have a list of the most common types, exluding stop words and punctuation.\n",
    "\n",
    "Be careful, though: these are still just raw counts, and they tell us very little about how we might characterize Pausanias vis-à-vis a larger corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lemmata/lemmas\n",
    "\n",
    "A **lemma** (plural **lemmata** or **lemmas**) represents \"a group of all inflectional forms related to one stem that belong to the same word class (Kučera & Francis 1967: 1)\" [@Brezina2018 40]. In simpler terms, a **lemma** is the dictionary form of a word, so **lemmata** give us a way of further reducing the word count. ἐστίν, ἔσμεν, and εἰσίν all have the same **lemma**: εἰμί.\n",
    "\n",
    "Lemmatization, as you might guess, often involves additional processing. Luckily, we can use the SpaCy and GreCy models again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_texts = [t for t in pausanias_df['unannotated_strings']]\n",
    "annotated_texts = nlp.pipe(raw_texts, batch_size=100)\n",
    "\n",
    "pausanias_df['nlp_docs'] = list(annotated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Messenians', 192),\n",
       " ('Lacedaemonians', 143),\n",
       " ('son', 142),\n",
       " ('man', 119),\n",
       " ('come', 83),\n",
       " ('Aristomenes', 75),\n",
       " ('say', 67),\n",
       " ('war', 67),\n",
       " ('call', 60),\n",
       " ('time', 56),\n",
       " ('Messene', 53),\n",
       " ('city', 53),\n",
       " ('king', 52),\n",
       " ('battle', 47),\n",
       " ('god', 46),\n",
       " ('daughter', 45),\n",
       " ('give', 45),\n",
       " ('take', 44),\n",
       " ('people', 44),\n",
       " ('Ithome', 43),\n",
       " ('Messenia', 41),\n",
       " ('messenian', 40),\n",
       " ('bring', 40),\n",
       " ('year', 40),\n",
       " ('town', 37),\n",
       " ('Aristodemus', 37),\n",
       " ('country', 36),\n",
       " ('receive', 36),\n",
       " ('death', 36),\n",
       " ('know', 36),\n",
       " ('capture', 35),\n",
       " ('Arcadians', 34),\n",
       " ('land', 33),\n",
       " ('great', 32),\n",
       " ('account', 31),\n",
       " ('see', 31),\n",
       " ('day', 30),\n",
       " ('troop', 30),\n",
       " ('fight', 29),\n",
       " ('statue', 29),\n",
       " ('place', 29),\n",
       " ('send', 29),\n",
       " ('kill', 28),\n",
       " ('Sparta', 28),\n",
       " ('force', 27),\n",
       " ('return', 27),\n",
       " ('house', 25),\n",
       " ('carry', 24),\n",
       " ('drive', 24),\n",
       " ('temple', 24),\n",
       " ('wall', 24),\n",
       " ('go', 23),\n",
       " ('having', 23),\n",
       " ('water', 23),\n",
       " ('Zeus', 23),\n",
       " ('attack', 23),\n",
       " ('join', 23),\n",
       " ('Eira', 23),\n",
       " ('spring', 22),\n",
       " ('child', 22),\n",
       " ('Heracles', 22),\n",
       " ('way', 22),\n",
       " ('night', 22),\n",
       " ('enemy', 22),\n",
       " ('think', 21),\n",
       " ('Homer', 21),\n",
       " ('Paus', 21),\n",
       " ('woman', 21),\n",
       " ('cattle', 21),\n",
       " ('hold', 21),\n",
       " ('lie', 21),\n",
       " ('long', 21),\n",
       " ('oracle', 21),\n",
       " ('Greeks', 20),\n",
       " ('Euphaes', 20),\n",
       " ('Peloponnese', 20),\n",
       " ('sea', 20),\n",
       " ('later', 19),\n",
       " ('wound', 19),\n",
       " ('point', 19),\n",
       " ('rest', 19),\n",
       " ('Theopompus', 19),\n",
       " ('like', 19),\n",
       " ('seer', 19),\n",
       " ('form', 18),\n",
       " ('wife', 18),\n",
       " ('Hom', 18),\n",
       " ('follow', 18),\n",
       " ('side', 18),\n",
       " ('courage', 18),\n",
       " ('fall', 18),\n",
       " ('lacedaemonian', 18),\n",
       " ('line', 17),\n",
       " ('Il', 17),\n",
       " ('Apollo', 17),\n",
       " ('sanctuary', 17),\n",
       " ('Cresphontes', 17),\n",
       " ('hear', 17),\n",
       " ('Argives', 17),\n",
       " ('second', 17)]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmata = [t.lemma_ for t in pausanias_df['nlp_docs'].explode() if not t.is_stop and t.is_alpha]\n",
    "\n",
    "lemmata_counts = Counter(lemmata)\n",
    "\n",
    "lemmata_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lexemes\n",
    "\n",
    "Finally, \"a **lexeme** is a lemma with a particular meaning attached to it.... The best way of conceptualizing a lexeme is as a subentry in a dictionary\" [@Brezina2018 40].\n",
    "\n",
    "One challenge of working with lexemes is that, even with the advances of large language models like ChatGPT, there is no surefire way to annotate them automatically. We still need \"human-in-the-loop\" pipelines to catch errors and ambiguities. And keep in mind that even two humans might disagree on the lexeme for a particular word!\n",
    "\n",
    "But we can inspect the `lex` attributes of the tokens that SpaCy has generated for us and see if they make sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('ἐνταῦθα', <spacy.lexeme.Lexeme at 0x39f333c80>), 491),\n",
       " (('μάλιστα', <spacy.lexeme.Lexeme at 0x39f333980>), 421),\n",
       " (('ἄγαλμα', <spacy.lexeme.Lexeme at 0x392a7dbc0>), 411),\n",
       " (('ἱερὸν', <spacy.lexeme.Lexeme at 0x392abfe40>), 369),\n",
       " (('ὕστερον', <spacy.lexeme.Lexeme at 0x392a7f840>), 351),\n",
       " (('σφισιν', <spacy.lexeme.Lexeme at 0x39f332b00>), 347),\n",
       " (('ὄνομα', <spacy.lexeme.Lexeme at 0x392a89180>), 345),\n",
       " (('γενέσθαι', <spacy.lexeme.Lexeme at 0x392a88300>), 329),\n",
       " (('λέγουσιν', <spacy.lexeme.Lexeme at 0x392a7e240>), 328),\n",
       " (('τότε', <spacy.lexeme.Lexeme at 0x392a80980>), 287),\n",
       " (('ἐπʼ', <spacy.lexeme.Lexeme at 0x392a851c0>), 268),\n",
       " (('πόλιν', <spacy.lexeme.Lexeme at 0x392a7e3c0>), 258),\n",
       " (('ἤδη', <spacy.lexeme.Lexeme at 0x392aa1b00>), 257),\n",
       " (('σφᾶς', <spacy.lexeme.Lexeme at 0x392a92680>), 250),\n",
       " (('φασιν', <spacy.lexeme.Lexeme at 0x392a7d500>), 238),\n",
       " (('δʼ', <spacy.lexeme.Lexeme at 0x392ac2a80>), 234),\n",
       " (('πρότερον', <spacy.lexeme.Lexeme at 0x39f331d80>), 227),\n",
       " (('σφίσιν', <spacy.lexeme.Lexeme at 0x39f3322c0>), 216),\n",
       " (('παῖδα', <spacy.lexeme.Lexeme at 0x392a8a500>), 215),\n",
       " (('ἐγένετο', <spacy.lexeme.Lexeme at 0x392aa4cc0>), 203),\n",
       " (('πεποίηται', <spacy.lexeme.Lexeme at 0x392a7e700>), 199),\n",
       " (('ὕδωρ', <spacy.lexeme.Lexeme at 0x392a95e40>), 196),\n",
       " (('λέγουσι', <spacy.lexeme.Lexeme at 0x392a9a180>), 194),\n",
       " (('Λακεδαιμονίων', <spacy.lexeme.Lexeme at 0x392a7c840>), 190),\n",
       " (('ἐφʼ', <spacy.lexeme.Lexeme at 0x392a83a80>), 186),\n",
       " (('ἔχει', <spacy.lexeme.Lexeme at 0x39f333b40>), 184),\n",
       " (('αὖθις', <spacy.lexeme.Lexeme at 0x39f333f00>), 183),\n",
       " (('ἱερόν', <spacy.lexeme.Lexeme at 0x392a7c7c0>), 183),\n",
       " (('λίθου', <spacy.lexeme.Lexeme at 0x392b27300>), 183),\n",
       " (('Ἀθηνᾶς', <spacy.lexeme.Lexeme at 0x39f33d640>), 178),\n",
       " (('θεῶν', <spacy.lexeme.Lexeme at 0x392a7d240>), 176),\n",
       " (('Ἀθηναίων', <spacy.lexeme.Lexeme at 0x392a85040>), 168),\n",
       " (('λέγεται', <spacy.lexeme.Lexeme at 0x392a8d1c0>), 167),\n",
       " (('Ἀπόλλωνος', <spacy.lexeme.Lexeme at 0x392b14400>), 166),\n",
       " (('ἀγάλματα', <spacy.lexeme.Lexeme at 0x39f333b00>), 164),\n",
       " (('Ἑλλήνων', <spacy.lexeme.Lexeme at 0x392a93300>), 164),\n",
       " (('σφισι', <spacy.lexeme.Lexeme at 0x392a91d00>), 162),\n",
       " (('δύο', <spacy.lexeme.Lexeme at 0x392ab8e00>), 162),\n",
       " (('πρὸ', <spacy.lexeme.Lexeme at 0x392a844c0>), 160),\n",
       " (('φασὶν', <spacy.lexeme.Lexeme at 0x39f332bc0>), 159),\n",
       " (('ἔνθα', <spacy.lexeme.Lexeme at 0x39f330bc0>), 158),\n",
       " (('ὁμοῦ', <spacy.lexeme.Lexeme at 0x392a8ffc0>), 154),\n",
       " (('ἅτε', <spacy.lexeme.Lexeme at 0x392a93500>), 154),\n",
       " (('ἀρχῆς', <spacy.lexeme.Lexeme at 0x392a7fc40>), 153),\n",
       " (('Διὸς', <spacy.lexeme.Lexeme at 0x39f333a00>), 151),\n",
       " (('Ἀθηναίοις', <spacy.lexeme.Lexeme at 0x39f331800>), 149),\n",
       " (('Ἀχαιῶν', <spacy.lexeme.Lexeme at 0x3f2d4b080>), 146),\n",
       " (('πολὺ', <spacy.lexeme.Lexeme at 0x392aac240>), 142),\n",
       " (('Ἀρτέμιδος', <spacy.lexeme.Lexeme at 0x392a7cec0>), 139),\n",
       " (('ἔργον', <spacy.lexeme.Lexeme at 0x392a7c680>), 138),\n",
       " (('ἀρχαῖον', <spacy.lexeme.Lexeme at 0x392a92700>), 138),\n",
       " (('ἐπίκλησιν', <spacy.lexeme.Lexeme at 0x392a8f840>), 135),\n",
       " (('ἀπʼ', <spacy.lexeme.Lexeme at 0x392a9b200>), 134),\n",
       " (('γῆν', <spacy.lexeme.Lexeme at 0x392a9b800>), 134),\n",
       " (('Λακεδαιμόνιοι', <spacy.lexeme.Lexeme at 0x3e3827100>), 134),\n",
       " (('παίδων', <spacy.lexeme.Lexeme at 0x392a7d340>), 132),\n",
       " (('Ἡρακλέους', <spacy.lexeme.Lexeme at 0x392a9d1c0>), 131),\n",
       " (('Λακεδαιμονίοις', <spacy.lexeme.Lexeme at 0x392a8e4c0>), 130),\n",
       " (('ἐποίησεν', <spacy.lexeme.Lexeme at 0x392a82c00>), 129),\n",
       " (('μνῆμα', <spacy.lexeme.Lexeme at 0x392a7e440>), 128),\n",
       " (('πάντα', <spacy.lexeme.Lexeme at 0x392a8e6c0>), 128),\n",
       " (('χωρίον', <spacy.lexeme.Lexeme at 0x392a7ed40>), 127),\n",
       " (('ἕνεκα', <spacy.lexeme.Lexeme at 0x392aa0600>), 127),\n",
       " (('πλησίον', <spacy.lexeme.Lexeme at 0x392a83200>), 126),\n",
       " (('γῆς', <spacy.lexeme.Lexeme at 0x3d5dd06c0>), 124),\n",
       " (('θεοῦ', <spacy.lexeme.Lexeme at 0x392a7cb00>), 124),\n",
       " (('πόλεως', <spacy.lexeme.Lexeme at 0x39f332a80>), 122),\n",
       " (('παρʼ', <spacy.lexeme.Lexeme at 0x392a8ecc0>), 122),\n",
       " (('ὅσον', <spacy.lexeme.Lexeme at 0x392a92c00>), 121),\n",
       " (('ναὸς', <spacy.lexeme.Lexeme at 0x39f33d500>), 120),\n",
       " (('Ἀρκάδων', <spacy.lexeme.Lexeme at 0x3e39668c0>), 117),\n",
       " (('λόγῳ', <spacy.lexeme.Lexeme at 0x392a854c0>), 116),\n",
       " (('διʼ', <spacy.lexeme.Lexeme at 0x392a93b00>), 116),\n",
       " (('παῖδας', <spacy.lexeme.Lexeme at 0x392a7c180>), 115),\n",
       " (('ἄνδρα', <spacy.lexeme.Lexeme at 0x392aacd40>), 115),\n",
       " (('Ὀλυμπίᾳ', <spacy.lexeme.Lexeme at 0x3e38e02c0>), 115),\n",
       " (('πρὶν', <spacy.lexeme.Lexeme at 0x39f3328c0>), 114),\n",
       " (('λόγος', <spacy.lexeme.Lexeme at 0x392a847c0>), 114),\n",
       " (('καλούμενον', <spacy.lexeme.Lexeme at 0x392a84cc0>), 114),\n",
       " (('ναός', <spacy.lexeme.Lexeme at 0x392a7d140>), 112),\n",
       " (('χρόνον', <spacy.lexeme.Lexeme at 0x392a83100>), 112),\n",
       " (('ἀνθρώπων', <spacy.lexeme.Lexeme at 0x392a88e80>), 112),\n",
       " (('ὄρος', <spacy.lexeme.Lexeme at 0x392a99f00>), 112),\n",
       " (('ὅσοι', <spacy.lexeme.Lexeme at 0x392ab7a40>), 112),\n",
       " (('πρῶτον', <spacy.lexeme.Lexeme at 0x392a87280>), 111),\n",
       " (('ὁπόσα', <spacy.lexeme.Lexeme at 0x392a8d4c0>), 111),\n",
       " (('ἀνὴρ', <spacy.lexeme.Lexeme at 0x392ab47c0>), 109),\n",
       " (('σταδίους', <spacy.lexeme.Lexeme at 0x392a7d880>), 108),\n",
       " (('πόλει', <spacy.lexeme.Lexeme at 0x392adfd00>), 108),\n",
       " (('θάλασσαν', <spacy.lexeme.Lexeme at 0x392a89f80>), 107),\n",
       " (('αὐτίκα', <spacy.lexeme.Lexeme at 0x392aa6d40>), 107),\n",
       " (('πόλις', <spacy.lexeme.Lexeme at 0x3e37d5bc0>), 107),\n",
       " (('νῦν', <spacy.lexeme.Lexeme at 0x392a7e1c0>), 106),\n",
       " (('δεξιᾷ', <spacy.lexeme.Lexeme at 0x392a89580>), 106),\n",
       " (('θεῷ', <spacy.lexeme.Lexeme at 0x392a8fcc0>), 106),\n",
       " (('γένος', <spacy.lexeme.Lexeme at 0x392ac1900>), 106),\n",
       " (('πλέον', <spacy.lexeme.Lexeme at 0x392ac54c0>), 106),\n",
       " (('μάχῃ', <spacy.lexeme.Lexeme at 0x39f333ec0>), 103),\n",
       " (('Μεσσηνίων', <spacy.lexeme.Lexeme at 0x392b0c4c0>), 103),\n",
       " (('Ἠλείων', <spacy.lexeme.Lexeme at 0x3fc8b9580>), 103)]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexemes = [(t.text, t.lex) for t in pausanias_df['nlp_docs'].explode() if not t.is_stop and t.is_alpha]\n",
    "\n",
    "lexeme_counts = Counter(lexemes)\n",
    "\n",
    "lexeme_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wait a second -- this list looks identical to our list of word types.\n",
    "\n",
    "Sure enough, when we check the SpaCy documentation for [Lexeme](https://spacy.io/api/lexeme):\n",
    "\n",
    "> A Lexeme has no string context – it’s a word type, as opposed to a word token. It therefore has no part-of-speech tag, dependency parse, or lemma (if lemmatization depends on the part-of-speech tag)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Review\n",
    "\n",
    "> Discuss: Define **token**, **type**, **stop word**, **lemma**, and **lexeme** in your own words.\n",
    "\n",
    "> Answer: A token is a word that appears in the text; A type word form that appears in the text: ex: 'the' twice in a sentence would be two tokens, one type; stop words are small words like 'and' or 'the' that don't add substance to the text; lemmas are groups of the same form of one stem of a word ex: time, times; lexemmes are lemma with a particular meaning ex: time has different meanings\"\n",
    "\n",
    "> Discuss: How can we use these different notions of \"word\" in our analysis of corpora? Why is it important to be precise about what kind of word(s) we're using?\n",
    "\n",
    "> Answer: Tokens give us a base understanding of the amount of words in a text. Types show us any the words that appear in the text. A lemma allow us to reduce the word count even further to look at words with the same stem. Lexemmes allow us to look closely at the meaning distinctions between words to understand them clearly. It's important to be precise, especially in large corpora, because it allows the researcher to parse through the text for interesting trends with more efficiency and accuracy.\n",
    "\n",
    "## Homework\n",
    "\n",
    "1. Read @Brezina2018 [ch. 2, pp. 41--65].\n",
    "2. Choose 3 books of Pausanias and calculate the most common tokens, types, and lemmata for each. In a paragraph or so, describe your findings relative to the work we have done in class today.\n",
    "3. Using your findings from 2., write a short (1-page) evaluation of one of the books of Pausanias that you have analyzed. Does your qualitative -- which is not to say \"subjective\" -- experience of reading the text cohere with your quantitative evaluation?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyCapytain.resources.texts.local.capitains.cts import CapitainsCtsText\n",
    "import pandas as pd\n",
    " \n",
    "with open(\"../tei/tlg0525.tlg001.perseus-eng2.xml\") as f:\n",
    "    text = CapitainsCtsText(urn=\"urn:cts:greekLit:tlg0525.tlg001.perseus-eng2\", resource=f)\n",
    " \n",
    "from lxml import etree\n",
    "from MyCapytain.common.constants import Mimetypes\n",
    " \n",
    "urns = []\n",
    "raw_xmls = []\n",
    "unannotated_strings = []\n",
    " \n",
    "for ref in text.getReffs(level=len(text.citation)):\n",
    "    urn = f\"{text.urn}:{ref}\"\n",
    "    node = text.getTextualNode(ref)\n",
    "    raw_xml = node.export(Mimetypes.XML.TEI)\n",
    "    tree = node.export(Mimetypes.PYTHON.ETREE)\n",
    "    s = etree.tostring(tree, encoding=\"unicode\", method=\"text\")\n",
    " \n",
    "    urns.append(urn)\n",
    "    raw_xmls.append(raw_xml)\n",
    "    unannotated_strings.append(s)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {\n",
    "    \"urn\": pd.Series(urns, dtype=\"string\"),\n",
    "    \"raw_xml\": raw_xmls,\n",
    "    \"unannotated_strings\": pd.Series(unannotated_strings, dtype=\"string\")\n",
    "}\n",
    "pausanias_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urn</th>\n",
       "      <th>raw_xml</th>\n",
       "      <th>unannotated_strings</th>\n",
       "      <th>whitespaced_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>895</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The frontier between Messenia and that part of...</td>\n",
       "      <td>[The, frontier, between, Messenia, and, that, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>896</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>Messene, being proud of her origin, for her fa...</td>\n",
       "      <td>[Messene,, being, proud, of, her, origin,, for...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>897</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>Before the battle which the Thebans fought wit...</td>\n",
       "      <td>[Before, the, battle, which, the, Thebans, fou...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>898</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>He is still more clear when speaking about the...</td>\n",
       "      <td>[He, is, still, more, clear, when, speaking, a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>899</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The first rulers then in this country were Pol...</td>\n",
       "      <td>[The, first, rulers, then, in, this, country, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1213</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>These cattle must have been of Thessalian stoc...</td>\n",
       "      <td>[These, cattle, must, have, been, of, Thessali...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1214</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>Eryx too, who was reigning then in Sicily, pla...</td>\n",
       "      <td>[Eryx, too,, who, was, reigning, then, in, Sic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1215</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>But the cattle of Neleus were pastured for the...</td>\n",
       "      <td>[But, the, cattle, of, Neleus, were, pastured,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1216</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The island of Sphacteria lies in front of the ...</td>\n",
       "      <td>[The, island, of, Sphacteria, lies, in, front,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1217</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>When Cyparissiae is reached from Pylos, there ...</td>\n",
       "      <td>[When, Cyparissiae, is, reached, from, Pylos,,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>323 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    urn  \\\n",
       "895   urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...   \n",
       "896   urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...   \n",
       "897   urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...   \n",
       "898   urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...   \n",
       "899   urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...   \n",
       "...                                                 ...   \n",
       "1213  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...   \n",
       "1214  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...   \n",
       "1215  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...   \n",
       "1216  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...   \n",
       "1217  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:4...   \n",
       "\n",
       "                                                raw_xml  \\\n",
       "895   <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "896   <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "897   <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "898   <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "899   <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "...                                                 ...   \n",
       "1213  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1214  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1215  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1216  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1217  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "\n",
       "                                    unannotated_strings  \\\n",
       "895   The frontier between Messenia and that part of...   \n",
       "896   Messene, being proud of her origin, for her fa...   \n",
       "897   Before the battle which the Thebans fought wit...   \n",
       "898   He is still more clear when speaking about the...   \n",
       "899   The first rulers then in this country were Pol...   \n",
       "...                                                 ...   \n",
       "1213  These cattle must have been of Thessalian stoc...   \n",
       "1214  Eryx too, who was reigning then in Sicily, pla...   \n",
       "1215  But the cattle of Neleus were pastured for the...   \n",
       "1216  The island of Sphacteria lies in front of the ...   \n",
       "1217  When Cyparissiae is reached from Pylos, there ...   \n",
       "\n",
       "                                     whitespaced_tokens  \n",
       "895   [The, frontier, between, Messenia, and, that, ...  \n",
       "896   [Messene,, being, proud, of, her, origin,, for...  \n",
       "897   [Before, the, battle, which, the, Thebans, fou...  \n",
       "898   [He, is, still, more, clear, when, speaking, a...  \n",
       "899   [The, first, rulers, then, in, this, country, ...  \n",
       "...                                                 ...  \n",
       "1213  [These, cattle, must, have, been, of, Thessali...  \n",
       "1214  [Eryx, too,, who, was, reigning, then, in, Sic...  \n",
       "1215  [But, the, cattle, of, Neleus, were, pastured,...  \n",
       "1216  [The, island, of, Sphacteria, lies, in, front,...  \n",
       "1217  [When, Cyparissiae, is, reached, from, Pylos,,...  \n",
       "\n",
       "[323 rows x 4 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    \"urn\": pd.Series(urns, dtype=\"string\"),\n",
    "    \"raw_xml\": raw_xmls,\n",
    "    \"unannotated_strings\": pd.Series(unannotated_strings, dtype=\"string\")\n",
    "}\n",
    "pausanias_df = pd.DataFrame(d)\n",
    " \n",
    "def get_book_of_pausanias(df: pd.DataFrame, book_n: int):\n",
    "    return df[df['urn'].str.startswith(f\"urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:{book_n}\")]\n",
    " \n",
    "\n",
    "pausanias_df = get_book_of_pausanias(pausanias_df, 4)\n",
    " #here, i added 'pausanias_df =' because it had to be defined as book 4\n",
    " #i hope i did it right\n",
    "\n",
    "pausanias_df['whitespaced_tokens'] = pausanias_df['unannotated_strings'].str.split()\n",
    "\n",
    "pausanias_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26395"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(ts) for ts in pausanias_df['whitespaced_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26395"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doing it in Pandas\n",
    "pausanias_df['whitespaced_tokens'].explode().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5310"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#types in book 4\n",
    "len(pausanias_df['whitespaced_tokens'].explode().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2435),\n",
       " ('of', 1193),\n",
       " ('and', 927),\n",
       " ('to', 866),\n",
       " ('in', 477),\n",
       " ('a', 372),\n",
       " ('was', 344),\n",
       " ('that', 338),\n",
       " ('they', 331),\n",
       " ('their', 292),\n",
       " ('were', 266),\n",
       " ('by', 260),\n",
       " ('he', 216),\n",
       " ('his', 212),\n",
       " ('from', 206),\n",
       " ('with', 198),\n",
       " ('for', 193),\n",
       " ('is', 185),\n",
       " ('as', 184),\n",
       " ('at', 181),\n",
       " ('The', 174),\n",
       " ('had', 171),\n",
       " ('on', 155),\n",
       " ('but', 155),\n",
       " ('them', 146),\n",
       " ('who', 142),\n",
       " ('Messenians', 142),\n",
       " ('it', 138),\n",
       " ('not', 128),\n",
       " ('son', 116),\n",
       " ('all', 106),\n",
       " ('when', 105),\n",
       " ('this', 98),\n",
       " ('which', 92),\n",
       " ('Lacedaemonians', 90),\n",
       " ('be', 81),\n",
       " ('have', 71),\n",
       " ('him', 68),\n",
       " ('no', 67),\n",
       " ('men', 65),\n",
       " ('been', 63),\n",
       " ('But', 63),\n",
       " ('I', 60),\n",
       " ('They', 59),\n",
       " ('an', 59),\n",
       " ('Aristomenes', 58),\n",
       " ('after', 57),\n",
       " ('first', 54),\n",
       " ('When', 54),\n",
       " ('made', 53),\n",
       " ('also', 50),\n",
       " ('He', 49),\n",
       " ('her', 48),\n",
       " ('being', 47),\n",
       " ('called', 46),\n",
       " ('said', 45),\n",
       " ('would', 45),\n",
       " ('came', 44),\n",
       " ('Messenian', 44),\n",
       " ('time', 43),\n",
       " ('For', 43),\n",
       " ('into', 42),\n",
       " ('are', 42),\n",
       " ('other', 41),\n",
       " ('war', 41),\n",
       " ('city', 39),\n",
       " ('or', 39),\n",
       " ('than', 38),\n",
       " ('most', 38),\n",
       " ('battle', 37),\n",
       " ('more', 37),\n",
       " ('both', 36),\n",
       " ('Messenians,', 36),\n",
       " ('part', 34),\n",
       " ('daughter', 34),\n",
       " ('people', 34),\n",
       " ('against', 34),\n",
       " ('Lacedaemonians,', 34),\n",
       " ('did', 34),\n",
       " ('one', 33),\n",
       " ('some', 33),\n",
       " ('them,', 32),\n",
       " ('man', 32),\n",
       " ('death', 31),\n",
       " ('then', 31),\n",
       " ('name', 31),\n",
       " ('Messene', 30),\n",
       " ('without', 30),\n",
       " ('took', 29),\n",
       " ('there', 29),\n",
       " ('having', 29),\n",
       " ('up', 29),\n",
       " ('before', 29),\n",
       " ('out', 29),\n",
       " ('say', 28),\n",
       " ('It', 28),\n",
       " ('so', 28),\n",
       " ('through', 27),\n",
       " ('themselves', 27),\n",
       " ('received', 26)]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pausanias_df = get_book_of_pausanias(pausanias_df, 4)\n",
    "#shows us the top 100 types in the data frame\n",
    "from collections import Counter\n",
    "#counter is a python library\n",
    "\n",
    "type_counts = Counter(pausanias_df['whitespaced_tokens'].explode())\n",
    "#counts the amount of types in dataframe\n",
    "\n",
    "type_counts.most_common(100)\n",
    "#finds 100 most common types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/miniconda3/lib/python3.11/site-packages (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (2.9.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/miniconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/miniconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: wrapt in /opt/miniconda3/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/miniconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: grecy in /opt/miniconda3/lib/python3.11/site-packages (1.0)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.5 in /opt/miniconda3/lib/python3.11/site-packages (from grecy) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.9.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/miniconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.5->grecy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5->grecy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5->grecy) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5->grecy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.5->grecy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.5->grecy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.5->grecy) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.5->grecy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.11/site-packages (from jinja2->spacy<4.0.0,>=3.5->grecy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/miniconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.5->grecy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (2.15.1)\n",
      "Requirement already satisfied: wrapt in /opt/miniconda3/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.5->grecy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/miniconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Uncomment the line for your system's architecture\n",
    "%pip install spacy\n",
    "# %pip install 'spacy[apple]'\n",
    "%pip install grecy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m29.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/miniconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/miniconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/miniconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.15.1)\n",
      "Requirement already satisfied: wrapt in /opt/miniconda3/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/miniconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "%run -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nlp.tokenizer\n",
    "\n",
    "pausanias_df['tokens'] = pausanias_df['unannotated_strings'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Messenians', 192),\n",
       " ('Lacedaemonians', 143),\n",
       " ('son', 120),\n",
       " ('Aristomenes', 82),\n",
       " ('men', 81),\n",
       " ('war', 66),\n",
       " ('Messene', 56),\n",
       " ('called', 55),\n",
       " ('time', 53),\n",
       " ('said', 53),\n",
       " ('Messenian', 50),\n",
       " ('battle', 47),\n",
       " ('came', 46),\n",
       " ('city', 44),\n",
       " ('Ithome', 43),\n",
       " ('daughter', 42),\n",
       " ('Messenia', 41),\n",
       " ('people', 40),\n",
       " ('Aristodemus', 37),\n",
       " ('man', 37),\n",
       " ('country', 36),\n",
       " ('death', 36),\n",
       " ('Arcadians', 34),\n",
       " ('king', 33),\n",
       " ('land', 30),\n",
       " ('took', 29),\n",
       " ('account', 29),\n",
       " ('having', 29),\n",
       " ('Sparta', 28),\n",
       " ('received', 27),\n",
       " ('brought', 26),\n",
       " ('god', 26),\n",
       " ('town', 25),\n",
       " ('come', 24),\n",
       " ('troops', 24),\n",
       " ('Heracles', 23),\n",
       " ('gave', 23),\n",
       " ('place', 23),\n",
       " ('Zeus', 23),\n",
       " ('year', 23),\n",
       " ('Eira', 23),\n",
       " ('sons', 22),\n",
       " ('killed', 22),\n",
       " ('night', 22),\n",
       " ('following', 21),\n",
       " ('day', 21),\n",
       " ('Homer', 21),\n",
       " ('house', 21),\n",
       " ('Paus', 21),\n",
       " ('cattle', 21),\n",
       " ('way', 21),\n",
       " ('Greeks', 20),\n",
       " ('statue', 20),\n",
       " ('saw', 20),\n",
       " ('water', 20),\n",
       " ('sent', 20),\n",
       " ('Lacedaemonian', 20),\n",
       " ('Euphaes', 20),\n",
       " ('gods', 20),\n",
       " ('Peloponnese', 20),\n",
       " ('force', 19),\n",
       " ('Theopompus', 19),\n",
       " ('temple', 19),\n",
       " ('enemy', 19),\n",
       " ('sea', 19),\n",
       " ('Hom', 18),\n",
       " ('went', 18),\n",
       " ('kings', 18),\n",
       " ('sides', 18),\n",
       " ('courage', 18),\n",
       " ('captured', 18),\n",
       " ('like', 18),\n",
       " ('Il', 17),\n",
       " ('carried', 17),\n",
       " ('years', 17),\n",
       " ('later', 17),\n",
       " ('children', 17),\n",
       " ('Apollo', 17),\n",
       " ('Cresphontes', 17),\n",
       " ('Argives', 17),\n",
       " ('second', 17),\n",
       " ('Andania', 16),\n",
       " ('Athenians', 16),\n",
       " ('know', 16),\n",
       " ('given', 16),\n",
       " ('point', 16),\n",
       " ('return', 16),\n",
       " ('capture', 16),\n",
       " ('ground', 16),\n",
       " ('oracle', 16),\n",
       " ('rest', 16),\n",
       " ('Laconia', 15),\n",
       " ('present', 15),\n",
       " ('Athens', 15),\n",
       " ('Polychares', 15),\n",
       " ('fate', 15),\n",
       " ('wife', 14),\n",
       " ('Great', 14),\n",
       " ('far', 14),\n",
       " ('ready', 14)]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 100 types in book 4\n",
    "types = [t.text for t in pausanias_df['tokens'].explode() if not t.is_stop and t.is_alpha]\n",
    "#is_alpha is alphabetical characters\n",
    "\n",
    "type_counts = Counter(types)\n",
    "\n",
    "type_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_texts = [t for t in pausanias_df['unannotated_strings']]\n",
    "annotated_texts = nlp.pipe(raw_texts, batch_size=100)\n",
    "\n",
    "pausanias_df['nlp_docs'] = list(annotated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Messenians', 192),\n",
       " ('Lacedaemonians', 143),\n",
       " ('son', 142),\n",
       " ('man', 119),\n",
       " ('come', 83),\n",
       " ('Aristomenes', 75),\n",
       " ('say', 67),\n",
       " ('war', 67),\n",
       " ('call', 60),\n",
       " ('time', 56),\n",
       " ('Messene', 53),\n",
       " ('city', 53),\n",
       " ('king', 52),\n",
       " ('battle', 47),\n",
       " ('god', 46),\n",
       " ('daughter', 45),\n",
       " ('give', 45),\n",
       " ('take', 44),\n",
       " ('people', 44),\n",
       " ('Ithome', 43),\n",
       " ('Messenia', 41),\n",
       " ('messenian', 40),\n",
       " ('bring', 40),\n",
       " ('year', 40),\n",
       " ('town', 37),\n",
       " ('Aristodemus', 37),\n",
       " ('country', 36),\n",
       " ('receive', 36),\n",
       " ('death', 36),\n",
       " ('know', 36),\n",
       " ('capture', 35),\n",
       " ('Arcadians', 34),\n",
       " ('land', 33),\n",
       " ('great', 32),\n",
       " ('account', 31),\n",
       " ('see', 31),\n",
       " ('day', 30),\n",
       " ('troop', 30),\n",
       " ('fight', 29),\n",
       " ('statue', 29),\n",
       " ('place', 29),\n",
       " ('send', 29),\n",
       " ('kill', 28),\n",
       " ('Sparta', 28),\n",
       " ('force', 27),\n",
       " ('return', 27),\n",
       " ('house', 25),\n",
       " ('carry', 24),\n",
       " ('drive', 24),\n",
       " ('temple', 24),\n",
       " ('wall', 24),\n",
       " ('go', 23),\n",
       " ('having', 23),\n",
       " ('water', 23),\n",
       " ('Zeus', 23),\n",
       " ('attack', 23),\n",
       " ('join', 23),\n",
       " ('Eira', 23),\n",
       " ('spring', 22),\n",
       " ('child', 22),\n",
       " ('Heracles', 22),\n",
       " ('way', 22),\n",
       " ('night', 22),\n",
       " ('enemy', 22),\n",
       " ('think', 21),\n",
       " ('Homer', 21),\n",
       " ('Paus', 21),\n",
       " ('woman', 21),\n",
       " ('cattle', 21),\n",
       " ('hold', 21),\n",
       " ('lie', 21),\n",
       " ('long', 21),\n",
       " ('oracle', 21),\n",
       " ('Greeks', 20),\n",
       " ('Euphaes', 20),\n",
       " ('Peloponnese', 20),\n",
       " ('sea', 20),\n",
       " ('later', 19),\n",
       " ('wound', 19),\n",
       " ('point', 19),\n",
       " ('rest', 19),\n",
       " ('Theopompus', 19),\n",
       " ('like', 19),\n",
       " ('seer', 19),\n",
       " ('form', 18),\n",
       " ('wife', 18),\n",
       " ('Hom', 18),\n",
       " ('follow', 18),\n",
       " ('side', 18),\n",
       " ('courage', 18),\n",
       " ('fall', 18),\n",
       " ('lacedaemonian', 18),\n",
       " ('line', 17),\n",
       " ('Il', 17),\n",
       " ('Apollo', 17),\n",
       " ('sanctuary', 17),\n",
       " ('Cresphontes', 17),\n",
       " ('hear', 17),\n",
       " ('Argives', 17),\n",
       " ('second', 17)]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmata = [t.lemma_ for t in pausanias_df['nlp_docs'].explode() if not t.is_stop and t.is_alpha]\n",
    "\n",
    "lemmata_counts = Counter(lemmata)\n",
    "\n",
    "lemmata_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Messenians', <spacy.lexeme.Lexeme at 0x1301806c0>), 192),\n",
       " (('Lacedaemonians', <spacy.lexeme.Lexeme at 0x130182740>), 143),\n",
       " (('son', <spacy.lexeme.Lexeme at 0x13017ed00>), 120),\n",
       " (('Aristomenes', <spacy.lexeme.Lexeme at 0x1300b8880>), 82),\n",
       " (('men', <spacy.lexeme.Lexeme at 0x1301801c0>), 81),\n",
       " (('war', <spacy.lexeme.Lexeme at 0x130198500>), 66),\n",
       " (('Messene', <spacy.lexeme.Lexeme at 0x13017e900>), 56),\n",
       " (('called', <spacy.lexeme.Lexeme at 0x13017c480>), 55),\n",
       " (('time', <spacy.lexeme.Lexeme at 0x13017c540>), 53),\n",
       " (('said', <spacy.lexeme.Lexeme at 0x130186f00>), 53),\n",
       " (('Messenian', <spacy.lexeme.Lexeme at 0x130180040>), 50),\n",
       " (('battle', <spacy.lexeme.Lexeme at 0x130182e00>), 47),\n",
       " (('came', <spacy.lexeme.Lexeme at 0x130183900>), 46),\n",
       " (('city', <spacy.lexeme.Lexeme at 0x130182200>), 44),\n",
       " (('Ithome', <spacy.lexeme.Lexeme at 0x130181e40>), 43),\n",
       " (('daughter', <spacy.lexeme.Lexeme at 0x13017ea80>), 42),\n",
       " (('Messenia', <spacy.lexeme.Lexeme at 0x13017d400>), 41),\n",
       " (('people', <spacy.lexeme.Lexeme at 0x130199000>), 40),\n",
       " (('Aristodemus', <spacy.lexeme.Lexeme at 0x13019b200>), 37),\n",
       " (('man', <spacy.lexeme.Lexeme at 0x13032c840>), 37),\n",
       " (('country', <spacy.lexeme.Lexeme at 0x13017c640>), 36),\n",
       " (('death', <spacy.lexeme.Lexeme at 0x13017d240>), 36),\n",
       " (('Arcadians', <spacy.lexeme.Lexeme at 0x1301a6b00>), 34),\n",
       " (('king', <spacy.lexeme.Lexeme at 0x13018e1c0>), 33),\n",
       " (('land', <spacy.lexeme.Lexeme at 0x130183640>), 30),\n",
       " (('took', <spacy.lexeme.Lexeme at 0x13017e700>), 29),\n",
       " (('account', <spacy.lexeme.Lexeme at 0x130187d80>), 29),\n",
       " (('having', <spacy.lexeme.Lexeme at 0x1301a2fc0>), 29),\n",
       " (('Sparta', <spacy.lexeme.Lexeme at 0x1300ca980>), 28),\n",
       " (('received', <spacy.lexeme.Lexeme at 0x13017ca00>), 27),\n",
       " (('brought', <spacy.lexeme.Lexeme at 0x130187f80>), 26),\n",
       " (('god', <spacy.lexeme.Lexeme at 0x1302d22c0>), 26),\n",
       " (('town', <spacy.lexeme.Lexeme at 0x130180c80>), 25),\n",
       " (('come', <spacy.lexeme.Lexeme at 0x13018c380>), 24),\n",
       " (('troops', <spacy.lexeme.Lexeme at 0x13030fd00>), 24),\n",
       " (('Heracles', <spacy.lexeme.Lexeme at 0x13018ba00>), 23),\n",
       " (('gave', <spacy.lexeme.Lexeme at 0x130190ec0>), 23),\n",
       " (('place', <spacy.lexeme.Lexeme at 0x1301993c0>), 23),\n",
       " (('Zeus', <spacy.lexeme.Lexeme at 0x1302bc980>), 23),\n",
       " (('year', <spacy.lexeme.Lexeme at 0x1300c1840>), 23),\n",
       " (('Eira', <spacy.lexeme.Lexeme at 0x130378580>), 23),\n",
       " (('sons', <spacy.lexeme.Lexeme at 0x13017db40>), 22),\n",
       " (('killed', <spacy.lexeme.Lexeme at 0x130195c80>), 22),\n",
       " (('night', <spacy.lexeme.Lexeme at 0x1300c7400>), 22),\n",
       " (('following', <spacy.lexeme.Lexeme at 0x13017cec0>), 21),\n",
       " (('day', <spacy.lexeme.Lexeme at 0x13017f700>), 21),\n",
       " (('Homer', <spacy.lexeme.Lexeme at 0x130181880>), 21),\n",
       " (('house', <spacy.lexeme.Lexeme at 0x130182800>), 21),\n",
       " (('Paus', <spacy.lexeme.Lexeme at 0x1301857c0>), 21),\n",
       " (('cattle', <spacy.lexeme.Lexeme at 0x130195640>), 21),\n",
       " (('way', <spacy.lexeme.Lexeme at 0x1301a2440>), 21),\n",
       " (('Greeks', <spacy.lexeme.Lexeme at 0x13017f640>), 20),\n",
       " (('statue', <spacy.lexeme.Lexeme at 0x1301860c0>), 20),\n",
       " (('saw', <spacy.lexeme.Lexeme at 0x130196d80>), 20),\n",
       " (('water', <spacy.lexeme.Lexeme at 0x1301a0b80>), 20),\n",
       " (('sent', <spacy.lexeme.Lexeme at 0x1302d3b40>), 20),\n",
       " (('Lacedaemonian', <spacy.lexeme.Lexeme at 0x1300d2e00>), 20),\n",
       " (('Euphaes', <spacy.lexeme.Lexeme at 0x1300c5c00>), 20),\n",
       " (('gods', <spacy.lexeme.Lexeme at 0x1300c1240>), 20),\n",
       " (('Peloponnese', <spacy.lexeme.Lexeme at 0x1303af200>), 20),\n",
       " (('force', <spacy.lexeme.Lexeme at 0x13017fd40>), 19),\n",
       " (('Theopompus', <spacy.lexeme.Lexeme at 0x1302e9b40>), 19),\n",
       " (('temple', <spacy.lexeme.Lexeme at 0x1300cf580>), 19),\n",
       " (('enemy', <spacy.lexeme.Lexeme at 0x13030ba00>), 19),\n",
       " (('sea', <spacy.lexeme.Lexeme at 0x12dc50a40>), 19),\n",
       " (('Hom', <spacy.lexeme.Lexeme at 0x130181680>), 18),\n",
       " (('went', <spacy.lexeme.Lexeme at 0x130197780>), 18),\n",
       " (('kings', <spacy.lexeme.Lexeme at 0x1301a4a40>), 18),\n",
       " (('sides', <spacy.lexeme.Lexeme at 0x1302e8d80>), 18),\n",
       " (('courage', <spacy.lexeme.Lexeme at 0x1300c8e80>), 18),\n",
       " (('captured', <spacy.lexeme.Lexeme at 0x1300c0dc0>), 18),\n",
       " (('like', <spacy.lexeme.Lexeme at 0x1300bc700>), 18),\n",
       " (('Il', <spacy.lexeme.Lexeme at 0x130181600>), 17),\n",
       " (('carried', <spacy.lexeme.Lexeme at 0x130180340>), 17),\n",
       " (('years', <spacy.lexeme.Lexeme at 0x130185500>), 17),\n",
       " (('later', <spacy.lexeme.Lexeme at 0x130185300>), 17),\n",
       " (('children', <spacy.lexeme.Lexeme at 0x1301891c0>), 17),\n",
       " (('Apollo', <spacy.lexeme.Lexeme at 0x13018d300>), 17),\n",
       " (('Cresphontes', <spacy.lexeme.Lexeme at 0x13019aac0>), 17),\n",
       " (('Argives', <spacy.lexeme.Lexeme at 0x1300cce80>), 17),\n",
       " (('second', <spacy.lexeme.Lexeme at 0x1300c1780>), 17),\n",
       " (('Andania', <spacy.lexeme.Lexeme at 0x130182fc0>), 16),\n",
       " (('Athenians', <spacy.lexeme.Lexeme at 0x130186c80>), 16),\n",
       " (('know', <spacy.lexeme.Lexeme at 0x13018a680>), 16),\n",
       " (('given', <spacy.lexeme.Lexeme at 0x13018d380>), 16),\n",
       " (('point', <spacy.lexeme.Lexeme at 0x1301988c0>), 16),\n",
       " (('return', <spacy.lexeme.Lexeme at 0x1301989c0>), 16),\n",
       " (('capture', <spacy.lexeme.Lexeme at 0x1300d2ec0>), 16),\n",
       " (('ground', <spacy.lexeme.Lexeme at 0x1303011c0>), 16),\n",
       " (('oracle', <spacy.lexeme.Lexeme at 0x130301b40>), 16),\n",
       " (('rest', <spacy.lexeme.Lexeme at 0x1302df980>), 16),\n",
       " (('Laconia', <spacy.lexeme.Lexeme at 0x13017dcc0>), 15),\n",
       " (('present', <spacy.lexeme.Lexeme at 0x13017d640>), 15),\n",
       " (('Athens', <spacy.lexeme.Lexeme at 0x130192100>), 15),\n",
       " (('Polychares', <spacy.lexeme.Lexeme at 0x13032c900>), 15),\n",
       " (('fate', <spacy.lexeme.Lexeme at 0x130318780>), 15),\n",
       " (('wife', <spacy.lexeme.Lexeme at 0x13017e880>), 14),\n",
       " (('Great', <spacy.lexeme.Lexeme at 0x130187a40>), 14),\n",
       " (('far', <spacy.lexeme.Lexeme at 0x1300c99c0>), 14),\n",
       " (('ready', <spacy.lexeme.Lexeme at 0x1300c50c0>), 14)]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexemes = [(t.text, t.lex) for t in pausanias_df['nlp_docs'].explode() if not t.is_stop and t.is_alpha]\n",
    "\n",
    "lexeme_counts = Counter(lexemes)\n",
    "\n",
    "lexeme_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Book 4: In book 4, there are 26395 tokens and 5310 types. The most common types in book 4 include words like \"the\", \"of\", \"and\" and \"to\", which is not surprising. However, after excluding stop words, we see that the most common types are \"Messenias\", \"Lacedaemonians\", \"son\", \"Aristomenes\" and \"men.\" The lemmata for the most common types are very similar: \"Messenians\", \"Lacedaemonians\", \"son\", \"man\", and \"come.\" \"Come\" is the only new token, as man and men are the same lemma. The 5 most common Lexemes in book 4 are the same as the 5 most common types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyCapytain.resources.texts.local.capitains.cts import CapitainsCtsText\n",
    "import pandas as pd\n",
    " \n",
    "with open(\"../tei/tlg0525.tlg001.perseus-eng2.xml\") as f:\n",
    "    text = CapitainsCtsText(urn=\"urn:cts:greekLit:tlg0525.tlg001.perseus-eng2\", resource=f)\n",
    " \n",
    "from lxml import etree\n",
    "from MyCapytain.common.constants import Mimetypes\n",
    " \n",
    "urns = []\n",
    "raw_xmls = []\n",
    "unannotated_strings = []\n",
    " \n",
    "for ref in text.getReffs(level=len(text.citation)):\n",
    "    urn = f\"{text.urn}:{ref}\"\n",
    "    node = text.getTextualNode(ref)\n",
    "    raw_xml = node.export(Mimetypes.XML.TEI)\n",
    "    tree = node.export(Mimetypes.PYTHON.ETREE)\n",
    "    s = etree.tostring(tree, encoding=\"unicode\", method=\"text\")\n",
    " \n",
    "    urns.append(urn)\n",
    "    raw_xmls.append(raw_xml)\n",
    "    unannotated_strings.append(s)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {\n",
    "    \"urn\": pd.Series(urns, dtype=\"string\"),\n",
    "    \"raw_xml\": raw_xmls,\n",
    "    \"unannotated_strings\": pd.Series(unannotated_strings, dtype=\"string\")\n",
    "}\n",
    "pausanias_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urn</th>\n",
       "      <th>raw_xml</th>\n",
       "      <th>unannotated_strings</th>\n",
       "      <th>whitespaced_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1218</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The Greeks who say that the Peloponnesus has f...</td>\n",
       "      <td>[The, Greeks, who, say, that, the, Peloponnesu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1219</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The rest of Peloponnesus belongs to immigrants...</td>\n",
       "      <td>[The, rest, of, Peloponnesus, belongs, to, imm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1220</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The Eleans we know crossed over from Calydon a...</td>\n",
       "      <td>[The, Eleans, we, know, crossed, over, from, C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1221</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The Moon, they say, fell in love with this End...</td>\n",
       "      <td>[The, Moon,, they, say,, fell, in, love, with,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1222</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>Of his brothers they say that Aetolus remained...</td>\n",
       "      <td>[Of, his, brothers, they, say, that, Aetolus, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1475</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The Hermes carrying the ram under his arm, wit...</td>\n",
       "      <td>[The, Hermes, carrying, the, ram, under, his, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1476</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>Of the bronze oxen one was dedicated by the Co...</td>\n",
       "      <td>[Of, the, bronze, oxen, one, was, dedicated, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>Sitting under this ox a little boy was playing...</td>\n",
       "      <td>[Sitting, under, this, ox, a, little, boy, was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1478</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>Under the plane trees in the Altis, just about...</td>\n",
       "      <td>[Under, the, plane, trees, in, the, Altis,, ju...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1479</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The offering of the Mendeans in Thrace came ve...</td>\n",
       "      <td>[The, offering, of, the, Mendeans, in, Thrace,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>262 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    urn  \\\n",
       "1218  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...   \n",
       "1219  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...   \n",
       "1220  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...   \n",
       "1221  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...   \n",
       "1222  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...   \n",
       "...                                                 ...   \n",
       "1475  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...   \n",
       "1476  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...   \n",
       "1477  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...   \n",
       "1478  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...   \n",
       "1479  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:5...   \n",
       "\n",
       "                                                raw_xml  \\\n",
       "1218  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1219  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1220  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1221  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1222  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "...                                                 ...   \n",
       "1475  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1476  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1477  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1478  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1479  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "\n",
       "                                    unannotated_strings  \\\n",
       "1218  The Greeks who say that the Peloponnesus has f...   \n",
       "1219  The rest of Peloponnesus belongs to immigrants...   \n",
       "1220  The Eleans we know crossed over from Calydon a...   \n",
       "1221  The Moon, they say, fell in love with this End...   \n",
       "1222  Of his brothers they say that Aetolus remained...   \n",
       "...                                                 ...   \n",
       "1475  The Hermes carrying the ram under his arm, wit...   \n",
       "1476  Of the bronze oxen one was dedicated by the Co...   \n",
       "1477  Sitting under this ox a little boy was playing...   \n",
       "1478  Under the plane trees in the Altis, just about...   \n",
       "1479  The offering of the Mendeans in Thrace came ve...   \n",
       "\n",
       "                                     whitespaced_tokens  \n",
       "1218  [The, Greeks, who, say, that, the, Peloponnesu...  \n",
       "1219  [The, rest, of, Peloponnesus, belongs, to, imm...  \n",
       "1220  [The, Eleans, we, know, crossed, over, from, C...  \n",
       "1221  [The, Moon,, they, say,, fell, in, love, with,...  \n",
       "1222  [Of, his, brothers, they, say, that, Aetolus, ...  \n",
       "...                                                 ...  \n",
       "1475  [The, Hermes, carrying, the, ram, under, his, ...  \n",
       "1476  [Of, the, bronze, oxen, one, was, dedicated, b...  \n",
       "1477  [Sitting, under, this, ox, a, little, boy, was...  \n",
       "1478  [Under, the, plane, trees, in, the, Altis,, ju...  \n",
       "1479  [The, offering, of, the, Mendeans, in, Thrace,...  \n",
       "\n",
       "[262 rows x 4 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    \"urn\": pd.Series(urns, dtype=\"string\"),\n",
    "    \"raw_xml\": raw_xmls,\n",
    "    \"unannotated_strings\": pd.Series(unannotated_strings, dtype=\"string\")\n",
    "}\n",
    "pausanias_df = pd.DataFrame(d)\n",
    " \n",
    "def get_book_of_pausanias(df: pd.DataFrame, book_n: int):\n",
    "    return df[df['urn'].str.startswith(f\"urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:{book_n}\")]\n",
    " \n",
    "\n",
    "pausanias_df = get_book_of_pausanias(pausanias_df, 5)\n",
    " #here, i added 'pausanias_df =' because it had to be defined as book 4\n",
    " #i hope i did it right\n",
    "\n",
    "pausanias_df['whitespaced_tokens'] = pausanias_df['unannotated_strings'].str.split()\n",
    "\n",
    "pausanias_df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22840"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doing it in Pandas\n",
    "pausanias_df['whitespaced_tokens'].explode().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5084"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#types in book 5\n",
    "len(pausanias_df['whitespaced_tokens'].explode().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2224),\n",
       " ('of', 1245),\n",
       " ('and', 694),\n",
       " ('to', 531),\n",
       " ('a', 454),\n",
       " ('is', 451),\n",
       " ('in', 370),\n",
       " ('that', 247),\n",
       " ('by', 243),\n",
       " ('was', 236),\n",
       " ('from', 204),\n",
       " ('on', 201),\n",
       " ('are', 194),\n",
       " ('The', 190),\n",
       " ('they', 181),\n",
       " ('with', 174),\n",
       " ('at', 167),\n",
       " ('for', 159),\n",
       " ('it', 141),\n",
       " ('his', 136),\n",
       " ('as', 120),\n",
       " ('he', 120),\n",
       " ('an', 120),\n",
       " ('who', 106),\n",
       " ('not', 105),\n",
       " ('were', 104),\n",
       " ('this', 102),\n",
       " ('I', 98),\n",
       " ('but', 96),\n",
       " ('have', 96),\n",
       " ('which', 88),\n",
       " ('one', 86),\n",
       " ('their', 85),\n",
       " ('son', 78),\n",
       " ('also', 74),\n",
       " ('made', 69),\n",
       " ('called', 68),\n",
       " ('be', 68),\n",
       " ('Eleans', 65),\n",
       " ('Zeus', 65),\n",
       " ('been', 65),\n",
       " ('altar', 63),\n",
       " ('dedicated', 61),\n",
       " ('has', 60),\n",
       " ('other', 60),\n",
       " ('them', 60),\n",
       " ('had', 59),\n",
       " ('after', 53),\n",
       " ('there', 48),\n",
       " ('him', 47),\n",
       " ('image', 47),\n",
       " ('say', 46),\n",
       " ('It', 45),\n",
       " ('her', 45),\n",
       " ('There', 44),\n",
       " ('first', 43),\n",
       " ('when', 41),\n",
       " ('two', 41),\n",
       " ('Heracles', 40),\n",
       " ('too', 40),\n",
       " ('all', 38),\n",
       " ('On', 37),\n",
       " ('about', 37),\n",
       " ('This', 35),\n",
       " ('upon', 35),\n",
       " ('Olympia', 34),\n",
       " ('no', 33),\n",
       " ('its', 33),\n",
       " ('said', 33),\n",
       " ('into', 31),\n",
       " ('being', 31),\n",
       " ('against', 31),\n",
       " ('up', 31),\n",
       " ('land', 30),\n",
       " ('set', 30),\n",
       " ('Olympic', 30),\n",
       " ('offerings', 30),\n",
       " ('my', 29),\n",
       " ('or', 29),\n",
       " ('those', 29),\n",
       " ('out', 28),\n",
       " ('temple', 28),\n",
       " ('part', 28),\n",
       " ('name', 28),\n",
       " ('Elis', 28),\n",
       " ('right', 28),\n",
       " ('inscription', 28),\n",
       " ('you', 28),\n",
       " ('these', 27),\n",
       " ('won', 27),\n",
       " ('only', 26),\n",
       " ('In', 26),\n",
       " ('so', 26),\n",
       " ('what', 26),\n",
       " ('city', 25),\n",
       " ('river', 24),\n",
       " ('came', 24),\n",
       " ('They', 24),\n",
       " ('side', 24),\n",
       " ('time', 23)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pausanias_df = get_book_of_pausanias(pausanias_df, 5)\n",
    "#shows us the top 100 types in the data frame\n",
    "from collections import Counter\n",
    "#counter is a python library\n",
    "\n",
    "type_counts = Counter(pausanias_df['whitespaced_tokens'].explode())\n",
    "#counts the amount of types in dataframe\n",
    "\n",
    "type_counts.most_common(100)\n",
    "#finds 100 most common types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/miniconda3/lib/python3.11/site-packages (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (2.9.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/miniconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/miniconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: wrapt in /opt/miniconda3/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/miniconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: grecy in /opt/miniconda3/lib/python3.11/site-packages (1.0)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.5 in /opt/miniconda3/lib/python3.11/site-packages (from grecy) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.9.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/miniconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.5->grecy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5->grecy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5->grecy) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5->grecy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.5->grecy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.5->grecy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.5->grecy) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.5->grecy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.11/site-packages (from jinja2->spacy<4.0.0,>=3.5->grecy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/miniconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.5->grecy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (2.15.1)\n",
      "Requirement already satisfied: wrapt in /opt/miniconda3/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.5->grecy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/miniconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Uncomment the line for your system's architecture\n",
    "%pip install spacy\n",
    "# %pip install 'spacy[apple]'\n",
    "%pip install grecy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m29.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/miniconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/miniconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/miniconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.15.1)\n",
      "Requirement already satisfied: wrapt in /opt/miniconda3/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/miniconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "%run -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nlp.tokenizer\n",
    "\n",
    "pausanias_df['tokens'] = pausanias_df['unannotated_strings'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Zeus', 105),\n",
       " ('Eleans', 90),\n",
       " ('son', 82),\n",
       " ('called', 72),\n",
       " ('altar', 70),\n",
       " ('dedicated', 65),\n",
       " ('Heracles', 64),\n",
       " ('Olympia', 61),\n",
       " ('image', 55),\n",
       " ('Elis', 54),\n",
       " ('games', 44),\n",
       " ('said', 36),\n",
       " ('inscription', 36),\n",
       " ('land', 35),\n",
       " ('race', 35),\n",
       " ('temple', 35),\n",
       " ('offerings', 33),\n",
       " ('Pelops', 31),\n",
       " ('right', 31),\n",
       " ('Olympic', 31),\n",
       " ('Festival', 31),\n",
       " ('set', 30),\n",
       " ('time', 29),\n",
       " ('won', 29),\n",
       " ('city', 29),\n",
       " ('river', 28),\n",
       " ('images', 28),\n",
       " ('god', 27),\n",
       " ('came', 25),\n",
       " ('Altis', 25),\n",
       " ('bronze', 25),\n",
       " ('Greeks', 24),\n",
       " ('left', 24),\n",
       " ('man', 23),\n",
       " ('war', 23),\n",
       " ('Alpheius', 23),\n",
       " ('stands', 23),\n",
       " ('account', 22),\n",
       " ('men', 22),\n",
       " ('feet', 22),\n",
       " ('chariot', 21),\n",
       " ('offering', 21),\n",
       " ('people', 20),\n",
       " ('sacrifice', 20),\n",
       " ('day', 20),\n",
       " ('sanctuary', 20),\n",
       " ('ancient', 20),\n",
       " ('horses', 20),\n",
       " ('sons', 19),\n",
       " ('throne', 19),\n",
       " ('sea', 19),\n",
       " ('Artemis', 19),\n",
       " ('olive', 19),\n",
       " ('number', 18),\n",
       " ('Lacedaemonians', 18),\n",
       " ('hand', 17),\n",
       " ('present', 17),\n",
       " ('near', 17),\n",
       " ('held', 17),\n",
       " ('boys', 17),\n",
       " ('story', 17),\n",
       " ('holding', 17),\n",
       " ('water', 17),\n",
       " ('great', 17),\n",
       " ('second', 16),\n",
       " ('daughter', 16),\n",
       " ('father', 16),\n",
       " ('Oenomaus', 16),\n",
       " ('Pisa', 16),\n",
       " ('Hermes', 16),\n",
       " ('women', 16),\n",
       " ('Oxylus', 16),\n",
       " ('built', 16),\n",
       " ('woman', 16),\n",
       " ('Apollo', 16),\n",
       " ('Athenians', 16),\n",
       " ('figures', 16),\n",
       " ('gods', 16),\n",
       " ('statues', 16),\n",
       " ('found', 15),\n",
       " ('oracle', 15),\n",
       " ('Athena', 15),\n",
       " ('far', 15),\n",
       " ('horse', 15),\n",
       " ('head', 15),\n",
       " ('Hera', 15),\n",
       " ('altars', 15),\n",
       " ('old', 14),\n",
       " ('Endymion', 14),\n",
       " ('honor', 14),\n",
       " ('Iphitus', 14),\n",
       " ('foot', 14),\n",
       " ('says', 14),\n",
       " ('ivory', 14),\n",
       " ('chest', 14),\n",
       " ('Arcadians', 13),\n",
       " ('following', 13),\n",
       " ('gave', 13),\n",
       " ('Elean', 13),\n",
       " ('Greek', 13)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 100 types in book 4\n",
    "types = [t.text for t in pausanias_df['tokens'].explode() if not t.is_stop and t.is_alpha]\n",
    "#is_alpha is alphabetical characters\n",
    "\n",
    "type_counts = Counter(types)\n",
    "\n",
    "type_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_texts = [t for t in pausanias_df['unannotated_strings']]\n",
    "annotated_texts = nlp.pipe(raw_texts, batch_size=100)\n",
    "\n",
    "pausanias_df['nlp_docs'] = list(annotated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Zeus', 105),\n",
       " ('son', 101),\n",
       " ('Eleans', 90),\n",
       " ('altar', 85),\n",
       " ('image', 83),\n",
       " ('call', 77),\n",
       " ('dedicate', 66),\n",
       " ('Olympia', 61),\n",
       " ('Heracles', 55),\n",
       " ('Elis', 54),\n",
       " ('offering', 54),\n",
       " ('come', 52),\n",
       " ('say', 51),\n",
       " ('hold', 46),\n",
       " ('man', 46),\n",
       " ('inscription', 46),\n",
       " ('race', 45),\n",
       " ('game', 45),\n",
       " ('stand', 44),\n",
       " ('god', 43),\n",
       " ('city', 42),\n",
       " ('temple', 36),\n",
       " ('foot', 36),\n",
       " ('land', 35),\n",
       " ('sacrifice', 35),\n",
       " ('horse', 35),\n",
       " ('time', 34),\n",
       " ('win', 34),\n",
       " ('right', 34),\n",
       " ('give', 33),\n",
       " ('set', 32),\n",
       " ('river', 32),\n",
       " ('woman', 32),\n",
       " ('Pelops', 31),\n",
       " ('Festival', 31),\n",
       " ('great', 28),\n",
       " ('chariot', 28),\n",
       " ('account', 26),\n",
       " ('statue', 26),\n",
       " ('figure', 26),\n",
       " ('daughter', 25),\n",
       " ('war', 25),\n",
       " ('Altis', 25),\n",
       " ('bronze', 25),\n",
       " ('Greeks', 24),\n",
       " ('victory', 24),\n",
       " ('take', 23),\n",
       " ('day', 23),\n",
       " ('Alpheius', 23),\n",
       " ('run', 22),\n",
       " ('near', 22),\n",
       " ('boy', 22),\n",
       " ('sanctuary', 22),\n",
       " ('carry', 22),\n",
       " ('work', 22),\n",
       " ('hand', 21),\n",
       " ('follow', 21),\n",
       " ('people', 21),\n",
       " ('grow', 21),\n",
       " ('throne', 20),\n",
       " ('enter', 20),\n",
       " ('ancient', 20),\n",
       " ('sea', 20),\n",
       " ('left', 20),\n",
       " ('honor', 19),\n",
       " ('number', 19),\n",
       " ('fine', 19),\n",
       " ('Artemis', 19),\n",
       " ('olive', 19),\n",
       " ('father', 18),\n",
       " ('place', 18),\n",
       " ('story', 18),\n",
       " ('Lacedaemonians', 18),\n",
       " ('water', 18),\n",
       " ('present', 17),\n",
       " ('find', 17),\n",
       " ('fight', 17),\n",
       " ('Olympic', 17),\n",
       " ('far', 17),\n",
       " ('include', 17),\n",
       " ('second', 16),\n",
       " ('old', 16),\n",
       " ('know', 16),\n",
       " ('go', 16),\n",
       " ('Oenomaus', 16),\n",
       " ('Pisa', 16),\n",
       " ('Hermes', 16),\n",
       " ('crown', 16),\n",
       " ('surname', 16),\n",
       " ('Oxylus', 16),\n",
       " ('bring', 16),\n",
       " ('build', 16),\n",
       " ('Apollo', 16),\n",
       " ('Athenians', 16),\n",
       " ('head', 16),\n",
       " ('pillar', 16),\n",
       " ('turn', 15),\n",
       " ('oracle', 15),\n",
       " ('Athena', 15),\n",
       " ('think', 15)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmata = [t.lemma_ for t in pausanias_df['nlp_docs'].explode() if not t.is_stop and t.is_alpha]\n",
    "\n",
    "lemmata_counts = Counter(lemmata)\n",
    "\n",
    "lemmata_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('Zeus', <spacy.lexeme.Lexeme at 0x11dfaaa80>), 105),\n",
       " (('Eleans', <spacy.lexeme.Lexeme at 0x11dfa87c0>), 90),\n",
       " (('son', <spacy.lexeme.Lexeme at 0x11dfaaa00>), 82),\n",
       " (('called', <spacy.lexeme.Lexeme at 0x11dfa9100>), 72),\n",
       " (('altar', <spacy.lexeme.Lexeme at 0x11e84c080>), 70),\n",
       " (('dedicated', <spacy.lexeme.Lexeme at 0x11e828640>), 65),\n",
       " (('Heracles', <spacy.lexeme.Lexeme at 0x11e820940>), 64),\n",
       " (('Olympia', <spacy.lexeme.Lexeme at 0x11e618340>), 61),\n",
       " (('image', <spacy.lexeme.Lexeme at 0x11e828880>), 55),\n",
       " (('Elis', <spacy.lexeme.Lexeme at 0x11e820d00>), 54),\n",
       " (('games', <spacy.lexeme.Lexeme at 0x11e81e2c0>), 44),\n",
       " (('said', <spacy.lexeme.Lexeme at 0x11e81c880>), 36),\n",
       " (('inscription', <spacy.lexeme.Lexeme at 0x11e82c580>), 36),\n",
       " (('land', <spacy.lexeme.Lexeme at 0x11dfa8d00>), 35),\n",
       " (('race', <spacy.lexeme.Lexeme at 0x11e618280>), 35),\n",
       " (('temple', <spacy.lexeme.Lexeme at 0x11e81cac0>), 35),\n",
       " (('offerings', <spacy.lexeme.Lexeme at 0x11e8c4800>), 33),\n",
       " (('Pelops', <spacy.lexeme.Lexeme at 0x11e61bac0>), 31),\n",
       " (('right', <spacy.lexeme.Lexeme at 0x11e827940>), 31),\n",
       " (('Olympic', <spacy.lexeme.Lexeme at 0x11e829780>), 31),\n",
       " (('Festival', <spacy.lexeme.Lexeme at 0x11e882000>), 31),\n",
       " (('set', <spacy.lexeme.Lexeme at 0x11e618040>), 30),\n",
       " (('time', <spacy.lexeme.Lexeme at 0x11dfa9600>), 29),\n",
       " (('won', <spacy.lexeme.Lexeme at 0x11e618580>), 29),\n",
       " (('city', <spacy.lexeme.Lexeme at 0x11e8241c0>), 29),\n",
       " (('river', <spacy.lexeme.Lexeme at 0x11e6193c0>), 28),\n",
       " (('images', <spacy.lexeme.Lexeme at 0x11e89a340>), 28),\n",
       " (('god', <spacy.lexeme.Lexeme at 0x11e81cdc0>), 27),\n",
       " (('came', <spacy.lexeme.Lexeme at 0x11e81d3c0>), 25),\n",
       " (('Altis', <spacy.lexeme.Lexeme at 0x11e897000>), 25),\n",
       " (('bronze', <spacy.lexeme.Lexeme at 0x11e8a6bc0>), 25),\n",
       " (('Greeks', <spacy.lexeme.Lexeme at 0x11d1751c0>), 24),\n",
       " (('left', <spacy.lexeme.Lexeme at 0x11e84f340>), 24),\n",
       " (('man', <spacy.lexeme.Lexeme at 0x11e821fc0>), 23),\n",
       " (('war', <spacy.lexeme.Lexeme at 0x11e8247c0>), 23),\n",
       " (('Alpheius', <spacy.lexeme.Lexeme at 0x11e864a00>), 23),\n",
       " (('stands', <spacy.lexeme.Lexeme at 0x11e89b480>), 23),\n",
       " (('account', <spacy.lexeme.Lexeme at 0x11e829cc0>), 22),\n",
       " (('men', <spacy.lexeme.Lexeme at 0x11e82de40>), 22),\n",
       " (('feet', <spacy.lexeme.Lexeme at 0x11e898840>), 22),\n",
       " (('chariot', <spacy.lexeme.Lexeme at 0x11e81e140>), 21),\n",
       " (('offering', <spacy.lexeme.Lexeme at 0x11e828c40>), 21),\n",
       " (('people', <spacy.lexeme.Lexeme at 0x11e619840>), 20),\n",
       " (('sacrifice', <spacy.lexeme.Lexeme at 0x11e81cd00>), 20),\n",
       " (('day', <spacy.lexeme.Lexeme at 0x11e827ac0>), 20),\n",
       " (('sanctuary', <spacy.lexeme.Lexeme at 0x11e830ac0>), 20),\n",
       " (('ancient', <spacy.lexeme.Lexeme at 0x11e83e280>), 20),\n",
       " (('horses', <spacy.lexeme.Lexeme at 0x11e884a00>), 20),\n",
       " (('sons', <spacy.lexeme.Lexeme at 0x11e618100>), 19),\n",
       " (('throne', <spacy.lexeme.Lexeme at 0x11e618400>), 19),\n",
       " (('sea', <spacy.lexeme.Lexeme at 0x11e84da00>), 19),\n",
       " (('Artemis', <spacy.lexeme.Lexeme at 0x11e8622c0>), 19),\n",
       " (('olive', <spacy.lexeme.Lexeme at 0x11e874480>), 19),\n",
       " (('number', <spacy.lexeme.Lexeme at 0x11e83f2c0>), 18),\n",
       " (('Lacedaemonians', <spacy.lexeme.Lexeme at 0x11e8438c0>), 18),\n",
       " (('hand', <spacy.lexeme.Lexeme at 0x11dfa9480>), 17),\n",
       " (('present', <spacy.lexeme.Lexeme at 0x11dfa9580>), 17),\n",
       " (('near', <spacy.lexeme.Lexeme at 0x11e6199c0>), 17),\n",
       " (('held', <spacy.lexeme.Lexeme at 0x11e81e380>), 17),\n",
       " (('boys', <spacy.lexeme.Lexeme at 0x11e82a980>), 17),\n",
       " (('story', <spacy.lexeme.Lexeme at 0x11e82ba00>), 17),\n",
       " (('holding', <spacy.lexeme.Lexeme at 0x11e8534c0>), 17),\n",
       " (('water', <spacy.lexeme.Lexeme at 0x11e855480>), 17),\n",
       " (('great', <spacy.lexeme.Lexeme at 0x11e8a4d00>), 17),\n",
       " (('second', <spacy.lexeme.Lexeme at 0x11dfa8840>), 16),\n",
       " (('daughter', <spacy.lexeme.Lexeme at 0x11dfaab80>), 16),\n",
       " (('father', <spacy.lexeme.Lexeme at 0x11dfaac80>), 16),\n",
       " (('Oenomaus', <spacy.lexeme.Lexeme at 0x11e61b100>), 16),\n",
       " (('Pisa', <spacy.lexeme.Lexeme at 0x11e61ba00>), 16),\n",
       " (('Hermes', <spacy.lexeme.Lexeme at 0x11e81cb80>), 16),\n",
       " (('women', <spacy.lexeme.Lexeme at 0x11e82fe80>), 16),\n",
       " (('Oxylus', <spacy.lexeme.Lexeme at 0x11e8381c0>), 16),\n",
       " (('built', <spacy.lexeme.Lexeme at 0x11e853b80>), 16),\n",
       " (('woman', <spacy.lexeme.Lexeme at 0x11e865900>), 16),\n",
       " (('Apollo', <spacy.lexeme.Lexeme at 0x11e878740>), 16),\n",
       " (('Athenians', <spacy.lexeme.Lexeme at 0x11e89ccc0>), 16),\n",
       " (('figures', <spacy.lexeme.Lexeme at 0x11e8a2800>), 16),\n",
       " (('gods', <spacy.lexeme.Lexeme at 0x11e8c3740>), 16),\n",
       " (('statues', <spacy.lexeme.Lexeme at 0x11e8c6e40>), 16),\n",
       " (('found', <spacy.lexeme.Lexeme at 0x11dfaa880>), 15),\n",
       " (('oracle', <spacy.lexeme.Lexeme at 0x11e82e680>), 15),\n",
       " (('Athena', <spacy.lexeme.Lexeme at 0x11e830580>), 15),\n",
       " (('far', <spacy.lexeme.Lexeme at 0x11e853640>), 15),\n",
       " (('horse', <spacy.lexeme.Lexeme at 0x11e87ec00>), 15),\n",
       " (('head', <spacy.lexeme.Lexeme at 0x11e89f680>), 15),\n",
       " (('Hera', <spacy.lexeme.Lexeme at 0x11e8b6e40>), 15),\n",
       " (('altars', <spacy.lexeme.Lexeme at 0x11e8e6740>), 15),\n",
       " (('old', <spacy.lexeme.Lexeme at 0x11dfa9180>), 14),\n",
       " (('Endymion', <spacy.lexeme.Lexeme at 0x11dfaad00>), 14),\n",
       " (('honor', <spacy.lexeme.Lexeme at 0x11e61a2c0>), 14),\n",
       " (('Iphitus', <spacy.lexeme.Lexeme at 0x11e8432c0>), 14),\n",
       " (('foot', <spacy.lexeme.Lexeme at 0x11e855a80>), 14),\n",
       " (('says', <spacy.lexeme.Lexeme at 0x11e8764c0>), 14),\n",
       " (('ivory', <spacy.lexeme.Lexeme at 0x11e8a8100>), 14),\n",
       " (('chest', <spacy.lexeme.Lexeme at 0x11e918ec0>), 14),\n",
       " (('Arcadians', <spacy.lexeme.Lexeme at 0x11dfa8740>), 13),\n",
       " (('following', <spacy.lexeme.Lexeme at 0x11e61aec0>), 13),\n",
       " (('gave', <spacy.lexeme.Lexeme at 0x11e81e800>), 13),\n",
       " (('Elean', <spacy.lexeme.Lexeme at 0x11e829f00>), 13),\n",
       " (('Greek', <spacy.lexeme.Lexeme at 0x11e82c1c0>), 13)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexemes = [(t.text, t.lex) for t in pausanias_df['nlp_docs'].explode() if not t.is_stop and t.is_alpha]\n",
    "\n",
    "lexeme_counts = Counter(lexemes)\n",
    "\n",
    "lexeme_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Book 5: In book 5 there are 22840 tokens and 5084 types. The most common types are \"the\", \"of\", \"and\", \"to\", and \"a,\" which makes sense as they are stop words. When filtering out stop words, the most common types are \"Zeus\", \"Eleans\", \"son\", \"called\", and \"altar.\" The top 5 lemmata are \"Zeus\", \"son\", \"Eleans\", \"altar\", and \"image.\" The top 5 lexemmes are the same as the top 5 types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from MyCapytain.resources.texts.local.capitains.cts import CapitainsCtsText\n",
    "import pandas as pd\n",
    " \n",
    "with open(\"../tei/tlg0525.tlg001.perseus-eng2.xml\") as f:\n",
    "    text = CapitainsCtsText(urn=\"urn:cts:greekLit:tlg0525.tlg001.perseus-eng2\", resource=f)\n",
    " \n",
    "from lxml import etree\n",
    "from MyCapytain.common.constants import Mimetypes\n",
    " \n",
    "urns = []\n",
    "raw_xmls = []\n",
    "unannotated_strings = []\n",
    " \n",
    "for ref in text.getReffs(level=len(text.citation)):\n",
    "    urn = f\"{text.urn}:{ref}\"\n",
    "    node = text.getTextualNode(ref)\n",
    "    raw_xml = node.export(Mimetypes.XML.TEI)\n",
    "    tree = node.export(Mimetypes.PYTHON.ETREE)\n",
    "    s = etree.tostring(tree, encoding=\"unicode\", method=\"text\")\n",
    " \n",
    "    urns.append(urn)\n",
    "    raw_xmls.append(raw_xml)\n",
    "    unannotated_strings.append(s)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "d = {\n",
    "    \"urn\": pd.Series(urns, dtype=\"string\"),\n",
    "    \"raw_xml\": raw_xmls,\n",
    "    \"unannotated_strings\": pd.Series(unannotated_strings, dtype=\"string\")\n",
    "}\n",
    "pausanias_df = pd.DataFrame(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>urn</th>\n",
       "      <th>raw_xml</th>\n",
       "      <th>unannotated_strings</th>\n",
       "      <th>whitespaced_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1480</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>After my description of the votive offerings I...</td>\n",
       "      <td>[After, my, description, of, the, votive, offe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1481</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>These I am forced to omit by the nature of my ...</td>\n",
       "      <td>[These, I, am, forced, to, omit, by, the, natu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1482</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>On the right of the temple of Hera is the stat...</td>\n",
       "      <td>[On, the, right, of, the, temple, of, Hera, is...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1483</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The inscription on Cleogenes the son of Silenu...</td>\n",
       "      <td>[The, inscription, on, Cleogenes, the, son, of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1484</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>After this the Eleans passed a law that in fut...</td>\n",
       "      <td>[After, this, the, Eleans, passed, a, law, tha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1742</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>The land of Elis is fruitful, being especially...</td>\n",
       "      <td>[The, land, of, Elis, is, fruitful,, being, es...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1743</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>Its size is twice that of the largest beetle, ...</td>\n",
       "      <td>[Its, size, is, twice, that, of, the, largest,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1744</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>They keep them for four years, feeding them on...</td>\n",
       "      <td>[They, keep, them, for, four, years,, feeding,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1745</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>But I have heard that it is not the Red Sea, b...</td>\n",
       "      <td>[But, I, have, heard, that, it, is, not, the, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1746</th>\n",
       "      <td>urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...</td>\n",
       "      <td>&lt;TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...</td>\n",
       "      <td>Such are the accounts that are given.  As you ...</td>\n",
       "      <td>[Such, are, the, accounts, that, are, given., ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>267 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    urn  \\\n",
       "1480  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...   \n",
       "1481  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...   \n",
       "1482  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...   \n",
       "1483  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...   \n",
       "1484  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...   \n",
       "...                                                 ...   \n",
       "1742  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...   \n",
       "1743  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...   \n",
       "1744  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...   \n",
       "1745  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...   \n",
       "1746  urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:6...   \n",
       "\n",
       "                                                raw_xml  \\\n",
       "1480  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1481  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1482  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1483  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1484  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "...                                                 ...   \n",
       "1742  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1743  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1744  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1745  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "1746  <TEI xmlns=\"http://www.tei-c.org/ns/1.0\" xmlns...   \n",
       "\n",
       "                                    unannotated_strings  \\\n",
       "1480  After my description of the votive offerings I...   \n",
       "1481  These I am forced to omit by the nature of my ...   \n",
       "1482  On the right of the temple of Hera is the stat...   \n",
       "1483  The inscription on Cleogenes the son of Silenu...   \n",
       "1484  After this the Eleans passed a law that in fut...   \n",
       "...                                                 ...   \n",
       "1742  The land of Elis is fruitful, being especially...   \n",
       "1743  Its size is twice that of the largest beetle, ...   \n",
       "1744  They keep them for four years, feeding them on...   \n",
       "1745  But I have heard that it is not the Red Sea, b...   \n",
       "1746  Such are the accounts that are given.  As you ...   \n",
       "\n",
       "                                     whitespaced_tokens  \n",
       "1480  [After, my, description, of, the, votive, offe...  \n",
       "1481  [These, I, am, forced, to, omit, by, the, natu...  \n",
       "1482  [On, the, right, of, the, temple, of, Hera, is...  \n",
       "1483  [The, inscription, on, Cleogenes, the, son, of...  \n",
       "1484  [After, this, the, Eleans, passed, a, law, tha...  \n",
       "...                                                 ...  \n",
       "1742  [The, land, of, Elis, is, fruitful,, being, es...  \n",
       "1743  [Its, size, is, twice, that, of, the, largest,...  \n",
       "1744  [They, keep, them, for, four, years,, feeding,...  \n",
       "1745  [But, I, have, heard, that, it, is, not, the, ...  \n",
       "1746  [Such, are, the, accounts, that, are, given., ...  \n",
       "\n",
       "[267 rows x 4 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = {\n",
    "    \"urn\": pd.Series(urns, dtype=\"string\"),\n",
    "    \"raw_xml\": raw_xmls,\n",
    "    \"unannotated_strings\": pd.Series(unannotated_strings, dtype=\"string\")\n",
    "}\n",
    "pausanias_df = pd.DataFrame(d)\n",
    "\n",
    "#(d) means on the parameters that we defined in the first 5 lines of code\n",
    " \n",
    "def get_book_of_pausanias(df: pd.DataFrame, book_n: int):\n",
    "    return df[df['urn'].str.startswith(f\"urn:cts:greekLit:tlg0525.tlg001.perseus-eng2:{book_n}\")]\n",
    "\n",
    "pausanias_df = get_book_of_pausanias(pausanias_df, 6)\n",
    " #here, i added 'pausanias_df =' because it had to be defined as book 4\n",
    " #i hope i did it right\n",
    "\n",
    "pausanias_df['whitespaced_tokens'] = pausanias_df['unannotated_strings'].str.split()\n",
    "\n",
    "pausanias_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21034"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(len(ts) for ts in pausanias_df['whitespaced_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21034"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#doing it in Pandas\n",
    "pausanias_df['whitespaced_tokens'].explode().count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4515"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#types in book 6\n",
    "len(pausanias_df['whitespaced_tokens'].explode().unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 2060),\n",
       " ('of', 1285),\n",
       " ('and', 629),\n",
       " ('a', 471),\n",
       " ('to', 427),\n",
       " ('in', 422),\n",
       " ('was', 309),\n",
       " ('is', 297),\n",
       " ('at', 269),\n",
       " ('by', 267),\n",
       " ('his', 214),\n",
       " ('that', 212),\n",
       " ('The', 187),\n",
       " ('he', 176),\n",
       " ('who', 170),\n",
       " ('for', 170),\n",
       " ('statue', 164),\n",
       " ('son', 156),\n",
       " ('from', 146),\n",
       " ('on', 137),\n",
       " ('won', 126),\n",
       " ('it', 126),\n",
       " ('are', 123),\n",
       " ('with', 120),\n",
       " ('they', 106),\n",
       " ('as', 103),\n",
       " ('made', 103),\n",
       " ('but', 85),\n",
       " ('not', 82),\n",
       " ('were', 82),\n",
       " ('this', 81),\n",
       " ('also', 78),\n",
       " ('have', 75),\n",
       " ('an', 75),\n",
       " ('their', 66),\n",
       " ('one', 64),\n",
       " ('be', 63),\n",
       " ('dedicated', 63),\n",
       " ('I', 61),\n",
       " ('him', 59),\n",
       " ('had', 58),\n",
       " ('Olympia', 53),\n",
       " ('when', 51),\n",
       " ('victory', 49),\n",
       " ('two', 47),\n",
       " ('which', 45),\n",
       " ('after', 43),\n",
       " ('them', 43),\n",
       " ('Eleans', 40),\n",
       " ('victories', 40),\n",
       " ('been', 38),\n",
       " ('inscription', 37),\n",
       " ('name', 37),\n",
       " ('There', 37),\n",
       " ('being', 36),\n",
       " ('statues', 35),\n",
       " ('all', 35),\n",
       " ('other', 35),\n",
       " ('called', 35),\n",
       " ('man', 35),\n",
       " ('because', 34),\n",
       " ('He', 33),\n",
       " (\"boys'\", 33),\n",
       " ('no', 31),\n",
       " ('among', 31),\n",
       " ('Olympic', 30),\n",
       " ('up', 30),\n",
       " ('side', 30),\n",
       " ('those', 29),\n",
       " ('set', 29),\n",
       " ('time', 29),\n",
       " ('Elis', 29),\n",
       " ('It', 29),\n",
       " ('has', 28),\n",
       " ('stands', 28),\n",
       " ('For', 27),\n",
       " ('say', 27),\n",
       " ('But', 27),\n",
       " ('In', 27),\n",
       " ('same', 27),\n",
       " ('my', 26),\n",
       " ('another', 26),\n",
       " ('This', 26),\n",
       " ('said', 26),\n",
       " ('sanctuary', 26),\n",
       " ('On', 25),\n",
       " ('first', 25),\n",
       " ('race', 25),\n",
       " ('there', 24),\n",
       " ('against', 24),\n",
       " ('men', 24),\n",
       " ('work', 24),\n",
       " ('chariot', 23),\n",
       " ('while', 23),\n",
       " ('about', 23),\n",
       " ('too', 23),\n",
       " ('or', 22),\n",
       " ('proclaimed', 22),\n",
       " ('Olympia,', 22),\n",
       " ('Elis,', 22)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pausanias_df = get_book_of_pausanias(pausanias_df, 6)\n",
    "#shows us the top 100 types in the data frame\n",
    "from collections import Counter\n",
    "#counter is a python library\n",
    "\n",
    "type_counts = Counter(pausanias_df['whitespaced_tokens'].explode())\n",
    "#counts the amount of types in dataframe\n",
    "\n",
    "type_counts.most_common(100)\n",
    "#finds 100 most common types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: spacy in /opt/miniconda3/lib/python3.11/site-packages (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (2.9.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/miniconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.11/site-packages (from jinja2->spacy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/miniconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (2.15.1)\n",
      "Requirement already satisfied: wrapt in /opt/miniconda3/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/miniconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: grecy in /opt/miniconda3/lib/python3.11/site-packages (1.0)\n",
      "Requirement already satisfied: spacy<4.0.0,>=3.5 in /opt/miniconda3/lib/python3.11/site-packages (from grecy) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (2.9.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<4.0.0,>=3.5->grecy) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/miniconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.5->grecy) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5->grecy) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5->grecy) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.5->grecy) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.5->grecy) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.5->grecy) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.5->grecy) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.5->grecy) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.5->grecy) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.11/site-packages (from jinja2->spacy<4.0.0,>=3.5->grecy) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/miniconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.5->grecy) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (2.15.1)\n",
      "Requirement already satisfied: wrapt in /opt/miniconda3/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<4.0.0,>=3.5->grecy) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/miniconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<4.0.0,>=3.5->grecy) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "## Uncomment the line for your system's architecture\n",
    "%pip install spacy\n",
    "# %pip install 'spacy[apple]'\n",
    "%pip install grecy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting en-core-web-sm==3.7.1\n",
      "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /opt/miniconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.6)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.3)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.4.1)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.12.5)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.5)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.9.1)\n",
      "Requirement already satisfied: jinja2 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.4)\n",
      "Requirement already satisfied: setuptools in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (72.1.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.1)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in /opt/miniconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.4)\n",
      "Requirement already satisfied: language-data>=1.2 in /opt/miniconda3/lib/python3.11/site-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.3 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.23.3)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/miniconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.8.30)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/miniconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.5)\n",
      "Requirement already satisfied: click>=8.0.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
      "Requirement already satisfied: shellingham>=1.3.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.5.4)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/miniconda3/lib/python3.11/site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (13.8.1)\n",
      "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.19.0)\n",
      "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /opt/miniconda3/lib/python3.11/site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (7.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/miniconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.3)\n",
      "Requirement already satisfied: marisa-trie>=0.7.7 in /opt/miniconda3/lib/python3.11/site-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.2.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /opt/miniconda3/lib/python3.11/site-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.15.1)\n",
      "Requirement already satisfied: wrapt in /opt/miniconda3/lib/python3.11/site-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.16.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/miniconda3/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.2)\n",
      "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
      "You can now load the package via spacy.load('en_core_web_sm')\n",
      "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
      "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
      "order to load all the package's dependencies. You can do this by selecting the\n",
      "'Restart kernel' or 'Restart runtime' option.\n"
     ]
    }
   ],
   "source": [
    "%run -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\", disable=[\"ner\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = nlp.tokenizer\n",
    "\n",
    "pausanias_df['tokens'] = pausanias_df['unannotated_strings'].apply(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('statue', 172),\n",
       " ('son', 161),\n",
       " ('won', 128),\n",
       " ('Olympia', 89),\n",
       " ('race', 69),\n",
       " ('Eleans', 67),\n",
       " ('boys', 65),\n",
       " ('dedicated', 64),\n",
       " ('Elis', 63),\n",
       " ('victory', 56),\n",
       " ('men', 53),\n",
       " ('boxing', 53),\n",
       " ('victories', 52),\n",
       " ('match', 52),\n",
       " ('man', 45),\n",
       " ('inscription', 42),\n",
       " ('chariot', 42),\n",
       " ('called', 40),\n",
       " ('wrestling', 39),\n",
       " ('statues', 36),\n",
       " ('games', 35),\n",
       " ('time', 33),\n",
       " ('place', 32),\n",
       " ('said', 32),\n",
       " ('Olympic', 30),\n",
       " ('set', 29),\n",
       " ('pancratium', 29),\n",
       " ('stands', 29),\n",
       " ('horses', 28),\n",
       " ('sanctuary', 28),\n",
       " ('people', 27),\n",
       " ('work', 25),\n",
       " ('Elean', 24),\n",
       " ('horse', 24),\n",
       " ('pentathlum', 24),\n",
       " ('crown', 23),\n",
       " ('father', 23),\n",
       " ('foot', 23),\n",
       " ('proclaimed', 22),\n",
       " ('victor', 22),\n",
       " ('image', 22),\n",
       " ('land', 22),\n",
       " ('river', 22),\n",
       " ('Sicyon', 21),\n",
       " ('came', 21),\n",
       " ('temple', 20),\n",
       " ('native', 20),\n",
       " ('Pytho', 20),\n",
       " ('Nemea', 20),\n",
       " ('old', 20),\n",
       " ('city', 20),\n",
       " ('boy', 19),\n",
       " ('bronze', 19),\n",
       " ('received', 18),\n",
       " ('Festival', 18),\n",
       " ('Heracles', 18),\n",
       " ('day', 18),\n",
       " ('brought', 17),\n",
       " ('Arcadians', 17),\n",
       " ('Euthymus', 17),\n",
       " ('story', 17),\n",
       " ('god', 16),\n",
       " ('Isthmus', 16),\n",
       " ('Athenian', 16),\n",
       " ('great', 16),\n",
       " ('Oenomaus', 16),\n",
       " ('treasury', 16),\n",
       " ('says', 15),\n",
       " ('umpires', 15),\n",
       " ('course', 15),\n",
       " ('gymnasium', 15),\n",
       " ('Theagenes', 15),\n",
       " ('sons', 15),\n",
       " ('Hiero', 15),\n",
       " ('know', 14),\n",
       " ('Greeks', 14),\n",
       " ('boxer', 14),\n",
       " ('market', 14),\n",
       " ('athletes', 13),\n",
       " ('second', 13),\n",
       " ('artist', 13),\n",
       " ('following', 13),\n",
       " ('war', 13),\n",
       " ('king', 13),\n",
       " ('tyrant', 13),\n",
       " ('year', 13),\n",
       " ('Zeus', 13),\n",
       " ('Philip', 13),\n",
       " ('Pulydamas', 13),\n",
       " ('Pelops', 13),\n",
       " ('Pisa', 13),\n",
       " ('offerings', 12),\n",
       " ('account', 12),\n",
       " ('pupil', 12),\n",
       " ('Argos', 12),\n",
       " ('reason', 12),\n",
       " ('Paus', 12),\n",
       " ('Nemean', 12),\n",
       " ('near', 12),\n",
       " ('Artemis', 12)]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#top 100 types in book 6\n",
    "types = [t.text for t in pausanias_df['tokens'].explode() if not t.is_stop and t.is_alpha]\n",
    "#is_alpha is alphabetical characters\n",
    "\n",
    "type_counts = Counter(types)\n",
    "\n",
    "type_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_texts = [t for t in pausanias_df['unannotated_strings']]\n",
    "annotated_texts = nlp.pipe(raw_texts, batch_size=100)\n",
    "\n",
    "pausanias_df['nlp_docs'] = list(annotated_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('statue', 209),\n",
       " ('son', 176),\n",
       " ('win', 145),\n",
       " ('victory', 109),\n",
       " ('man', 100),\n",
       " ('Olympia', 89),\n",
       " ('boy', 84),\n",
       " ('race', 76),\n",
       " ('Eleans', 67),\n",
       " ('dedicate', 65),\n",
       " ('Elis', 63),\n",
       " ('match', 54),\n",
       " ('horse', 52),\n",
       " ('stand', 50),\n",
       " ('say', 48),\n",
       " ('chariot', 46),\n",
       " ('inscription', 45),\n",
       " ('time', 42),\n",
       " ('boxing', 41),\n",
       " ('call', 41),\n",
       " ('place', 37),\n",
       " ('come', 36),\n",
       " ('game', 35),\n",
       " ('crown', 34),\n",
       " ('set', 33),\n",
       " ('hold', 33),\n",
       " ('wrestling', 33),\n",
       " ('work', 31),\n",
       " ('foot', 30),\n",
       " ('victor', 29),\n",
       " ('pancratium', 29),\n",
       " ('image', 29),\n",
       " ('city', 29),\n",
       " ('sanctuary', 29),\n",
       " ('people', 28),\n",
       " ('native', 26),\n",
       " ('know', 24),\n",
       " ('pentathlum', 24),\n",
       " ('proclaim', 23),\n",
       " ('father', 23),\n",
       " ('land', 23),\n",
       " ('receive', 22),\n",
       " ('god', 22),\n",
       " ('river', 22),\n",
       " ('treasury', 22),\n",
       " ('olympic', 21),\n",
       " ('Sicyon', 21),\n",
       " ('bring', 21),\n",
       " ('old', 21),\n",
       " ('great', 21),\n",
       " ('athlete', 20),\n",
       " ('temple', 20),\n",
       " ('Pytho', 20),\n",
       " ('Nemea', 20),\n",
       " ('enter', 20),\n",
       " ('year', 20),\n",
       " ('take', 19),\n",
       " ('bronze', 19),\n",
       " ('day', 19),\n",
       " ('umpire', 18),\n",
       " ('near', 18),\n",
       " ('Festival', 18),\n",
       " ('name', 18),\n",
       " ('Heracles', 18),\n",
       " ('story', 18),\n",
       " ('offering', 17),\n",
       " ('Arcadians', 17),\n",
       " ('Euthymus', 17),\n",
       " ('Isthmus', 16),\n",
       " ('boxer', 16),\n",
       " ('run', 16),\n",
       " ('go', 16),\n",
       " ('Oenomaus', 16),\n",
       " ('declare', 15),\n",
       " ('give', 15),\n",
       " ('king', 15),\n",
       " ('surname', 15),\n",
       " ('kill', 15),\n",
       " ('course', 15),\n",
       " ('long', 15),\n",
       " ('gymnasium', 15),\n",
       " ('Hiero', 15),\n",
       " ('altar', 15),\n",
       " ('wrestler', 14),\n",
       " ('reason', 14),\n",
       " ('represent', 14),\n",
       " ('hand', 14),\n",
       " ('Greeks', 14),\n",
       " ('elean', 14),\n",
       " ('tyrant', 14),\n",
       " ('box', 14),\n",
       " ('build', 14),\n",
       " ('market', 14),\n",
       " ('account', 13),\n",
       " ('record', 13),\n",
       " ('contest', 13),\n",
       " ('second', 13),\n",
       " ('artist', 13),\n",
       " ('war', 13),\n",
       " ('see', 13)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmata = [t.lemma_ for t in pausanias_df['nlp_docs'].explode() if not t.is_stop and t.is_alpha]\n",
    "\n",
    "lemmata_counts = Counter(lemmata)\n",
    "\n",
    "lemmata_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(('statue', <spacy.lexeme.Lexeme at 0x11d4afd40>), 172),\n",
       " (('son', <spacy.lexeme.Lexeme at 0x11d4dc900>), 161),\n",
       " (('won', <spacy.lexeme.Lexeme at 0x11d4d6c80>), 128),\n",
       " (('Olympia', <spacy.lexeme.Lexeme at 0x11dfae0c0>), 89),\n",
       " (('race', <spacy.lexeme.Lexeme at 0x11d4bbf80>), 69),\n",
       " (('Eleans', <spacy.lexeme.Lexeme at 0x11d4a1640>), 67),\n",
       " (('boys', <spacy.lexeme.Lexeme at 0x11d4de800>), 65),\n",
       " (('dedicated', <spacy.lexeme.Lexeme at 0x11d433fc0>), 64),\n",
       " (('Elis', <spacy.lexeme.Lexeme at 0x11e4d1d80>), 63),\n",
       " (('victory', <spacy.lexeme.Lexeme at 0x11d4ddf80>), 56),\n",
       " (('men', <spacy.lexeme.Lexeme at 0x11d4d9200>), 53),\n",
       " (('boxing', <spacy.lexeme.Lexeme at 0x11d4deb80>), 53),\n",
       " (('victories', <spacy.lexeme.Lexeme at 0x11d4d7840>), 52),\n",
       " (('match', <spacy.lexeme.Lexeme at 0x11d4dedc0>), 52),\n",
       " (('man', <spacy.lexeme.Lexeme at 0x11e7a2cc0>), 45),\n",
       " (('inscription', <spacy.lexeme.Lexeme at 0x11d4dff40>), 42),\n",
       " (('chariot', <spacy.lexeme.Lexeme at 0x11d4a1e00>), 42),\n",
       " (('called', <spacy.lexeme.Lexeme at 0x11e71bd40>), 40),\n",
       " (('wrestling', <spacy.lexeme.Lexeme at 0x11e7a59c0>), 39),\n",
       " (('statues', <spacy.lexeme.Lexeme at 0x11d4d8240>), 36),\n",
       " (('games', <spacy.lexeme.Lexeme at 0x11d4afd80>), 35),\n",
       " (('time', <spacy.lexeme.Lexeme at 0x11d4a3c80>), 33),\n",
       " (('place', <spacy.lexeme.Lexeme at 0x11e4d0140>), 32),\n",
       " (('said', <spacy.lexeme.Lexeme at 0x11e79d2c0>), 32),\n",
       " (('Olympic', <spacy.lexeme.Lexeme at 0x11d4da200>), 30),\n",
       " (('set', <spacy.lexeme.Lexeme at 0x11d4b0300>), 29),\n",
       " (('pancratium', <spacy.lexeme.Lexeme at 0x11dfa2080>), 29),\n",
       " (('stands', <spacy.lexeme.Lexeme at 0x11e645c40>), 29),\n",
       " (('horses', <spacy.lexeme.Lexeme at 0x11dfae940>), 28),\n",
       " (('sanctuary', <spacy.lexeme.Lexeme at 0x11effe7c0>), 28),\n",
       " (('people', <spacy.lexeme.Lexeme at 0x11e4d3640>), 27),\n",
       " (('work', <spacy.lexeme.Lexeme at 0x11d4d6a00>), 25),\n",
       " (('Elean', <spacy.lexeme.Lexeme at 0x11d4dc700>), 24),\n",
       " (('horse', <spacy.lexeme.Lexeme at 0x11d4a0140>), 24),\n",
       " (('pentathlum', <spacy.lexeme.Lexeme at 0x11dfac480>), 24),\n",
       " (('crown', <spacy.lexeme.Lexeme at 0x11e6eee40>), 23),\n",
       " (('father', <spacy.lexeme.Lexeme at 0x11e4d2cc0>), 23),\n",
       " (('foot', <spacy.lexeme.Lexeme at 0x11e4cb5c0>), 23),\n",
       " (('proclaimed', <spacy.lexeme.Lexeme at 0x11dfad1c0>), 22),\n",
       " (('victor', <spacy.lexeme.Lexeme at 0x11dfad100>), 22),\n",
       " (('image', <spacy.lexeme.Lexeme at 0x11e798800>), 22),\n",
       " (('land', <spacy.lexeme.Lexeme at 0x11feaa580>), 22),\n",
       " (('river', <spacy.lexeme.Lexeme at 0x11d580840>), 22),\n",
       " (('Sicyon', <spacy.lexeme.Lexeme at 0x11d4df700>), 21),\n",
       " (('came', <spacy.lexeme.Lexeme at 0x11e79c440>), 21),\n",
       " (('temple', <spacy.lexeme.Lexeme at 0x11d4de180>), 20),\n",
       " (('native', <spacy.lexeme.Lexeme at 0x11d1fffc0>), 20),\n",
       " (('Pytho', <spacy.lexeme.Lexeme at 0x11d4bbe00>), 20),\n",
       " (('Nemea', <spacy.lexeme.Lexeme at 0x11d4bba00>), 20),\n",
       " (('old', <spacy.lexeme.Lexeme at 0x11e79d580>), 20),\n",
       " (('city', <spacy.lexeme.Lexeme at 0x11fea8940>), 20),\n",
       " (('boy', <spacy.lexeme.Lexeme at 0x11e4cbf80>), 19),\n",
       " (('bronze', <spacy.lexeme.Lexeme at 0x11e543f40>), 19),\n",
       " (('received', <spacy.lexeme.Lexeme at 0x11dfac680>), 18),\n",
       " (('Festival', <spacy.lexeme.Lexeme at 0x11fea7380>), 18),\n",
       " (('Heracles', <spacy.lexeme.Lexeme at 0x11d57e880>), 18),\n",
       " (('day', <spacy.lexeme.Lexeme at 0x11d673c80>), 18),\n",
       " (('brought', <spacy.lexeme.Lexeme at 0x11d46bbc0>), 17),\n",
       " (('Arcadians', <spacy.lexeme.Lexeme at 0x11d450dc0>), 17),\n",
       " (('Euthymus', <spacy.lexeme.Lexeme at 0x11d571b00>), 17),\n",
       " (('story', <spacy.lexeme.Lexeme at 0x11d56bd80>), 17),\n",
       " (('god', <spacy.lexeme.Lexeme at 0x119438140>), 16),\n",
       " (('Isthmus', <spacy.lexeme.Lexeme at 0x11d4bbd80>), 16),\n",
       " (('Athenian', <spacy.lexeme.Lexeme at 0x11d177880>), 16),\n",
       " (('great', <spacy.lexeme.Lexeme at 0x11fe9cc40>), 16),\n",
       " (('Oenomaus', <spacy.lexeme.Lexeme at 0x11d6d4ac0>), 16),\n",
       " (('treasury', <spacy.lexeme.Lexeme at 0x11d6d5cc0>), 16),\n",
       " (('says', <spacy.lexeme.Lexeme at 0x11d4bac00>), 15),\n",
       " (('umpires', <spacy.lexeme.Lexeme at 0x11e4d1e00>), 15),\n",
       " (('course', <spacy.lexeme.Lexeme at 0x11e7abd00>), 15),\n",
       " (('gymnasium', <spacy.lexeme.Lexeme at 0x11d5721c0>), 15),\n",
       " (('Theagenes', <spacy.lexeme.Lexeme at 0x11d56f240>), 15),\n",
       " (('sons', <spacy.lexeme.Lexeme at 0x11d665b00>), 15),\n",
       " (('Hiero', <spacy.lexeme.Lexeme at 0x11d67bc40>), 15),\n",
       " (('know', <spacy.lexeme.Lexeme at 0x11d4b0200>), 14),\n",
       " (('Greeks', <spacy.lexeme.Lexeme at 0x11dfa3600>), 14),\n",
       " (('boxer', <spacy.lexeme.Lexeme at 0x11e79b680>), 14),\n",
       " (('market', <spacy.lexeme.Lexeme at 0x11d635d00>), 14),\n",
       " (('athletes', <spacy.lexeme.Lexeme at 0x11d4d9340>), 13),\n",
       " (('second', <spacy.lexeme.Lexeme at 0x11d4a3f40>), 13),\n",
       " (('artist', <spacy.lexeme.Lexeme at 0x11dfac340>), 13),\n",
       " (('following', <spacy.lexeme.Lexeme at 0x11dfa3a40>), 13),\n",
       " (('war', <spacy.lexeme.Lexeme at 0x11e4d0e00>), 13),\n",
       " (('king', <spacy.lexeme.Lexeme at 0x11d451400>), 13),\n",
       " (('tyrant', <spacy.lexeme.Lexeme at 0x11e79a240>), 13),\n",
       " (('year', <spacy.lexeme.Lexeme at 0x11e79e200>), 13),\n",
       " (('Zeus', <spacy.lexeme.Lexeme at 0x11e52ecc0>), 13),\n",
       " (('Philip', <spacy.lexeme.Lexeme at 0x11feb2500>), 13),\n",
       " (('Pulydamas', <spacy.lexeme.Lexeme at 0x11feb3bc0>), 13),\n",
       " (('Pelops', <spacy.lexeme.Lexeme at 0x11d6db400>), 13),\n",
       " (('Pisa', <spacy.lexeme.Lexeme at 0x11d707080>), 13),\n",
       " (('offerings', <spacy.lexeme.Lexeme at 0x11d4d8a40>), 12),\n",
       " (('account', <spacy.lexeme.Lexeme at 0x11d4d70c0>), 12),\n",
       " (('pupil', <spacy.lexeme.Lexeme at 0x11d4df580>), 12),\n",
       " (('Argos', <spacy.lexeme.Lexeme at 0x11d4dfd00>), 12),\n",
       " (('reason', <spacy.lexeme.Lexeme at 0x11d4a3840>), 12),\n",
       " (('Paus', <spacy.lexeme.Lexeme at 0x11dfadc40>), 12),\n",
       " (('Nemean', <spacy.lexeme.Lexeme at 0x11e7a0880>), 12),\n",
       " (('near', <spacy.lexeme.Lexeme at 0x11e7abfc0>), 12),\n",
       " (('Artemis', <spacy.lexeme.Lexeme at 0x11effee80>), 12)]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexemes = [(t.text, t.lex) for t in pausanias_df['nlp_docs'].explode() if not t.is_stop and t.is_alpha]\n",
    "\n",
    "lexeme_counts = Counter(lexemes)\n",
    "\n",
    "lexeme_counts.most_common(100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Book 4: In book 4, there are 26395 tokens and 5310 types. The most common types in book 4 include words like \"the\", \"of\", \"and\" and \"to\", which is not surprising. However, after excluding stop words, we see that the most common types are \"Messenias\", \"Lacedaemonians\", \"son\", \"Aristomenes\" and \"men.\" The lemmata for the most common types are very similar: \"Messenians\", \"Lacedaemonians\", \"son\", \"man\", and \"come.\" \"Come\" is the only new token, as man and men are the same lemma. The 5 most common Lexemes in book 4 are the same as the 5 most common types.\n",
    "\n",
    "> Book 5: In book 5 there are 22840 tokens and 5084 types. The most common types are \"the\", \"of\", \"and\", \"to\", and \"a,\" which makes sense as they are stop words. When filtering out stop words, the most common types are \"Zeus\", \"Eleans\", \"son\", \"called\", and \"altar.\" The top 5 lemmata are \"Zeus\", \"son\", \"Eleans\", \"altar\", and \"image.\" The top 5 lexemmes are the same as the top 5 types.\n",
    "\n",
    ">Book 6: In book 6, there are 21034 tokens and 4515 types. The most common types are \"the\", \"of\", \"and\", \"a\", and \"to,\" which makes sense as they are stop words. After filtering out stop words the most common types are \"statue\", \"son\", \"won\", \"olympia\", and \"race.\" The most common lemmata are \"statue\", \"son\", \"win\", \"victory\", and \"man.\" It is interesting that versions of victory rise to the top of the lemmata. The top 5 lexemmes are the same as the top 5 types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> HW Paragraph: Upon analyzing books 4, 5, and 6 of the text, I am able to analyze those books with more clarity. Book 4 had the highest amount of tokens and types, at 26395 tokens and 5310. This information tells me that book 4 is longer than books 5 and 6 respectively. In all of the books, stop words are the most common types, which makes sense. In book 4, I can deduce that it is about Messenia given the most common types. In book 5, I assume it focuses on the temple of Zeus and ancient Elis. In book 6, I assume it is based on the site of Olympia. By analyzing the most common types, lemmata, and lexemmes. The difference between type and lexemes was not apparent int his exercise, which makes sense as it is subjective. However, by analyzing the books seperately, I was able to deduce what each one focused on and was about. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">HW #3\n",
    "For my homework for this week, one of the books I analyzed was Book four of Pausanias’ “Description of Greece.” I analyzed the English translation of this text. In book 4, there are 26395 tokens and 5310 types. The most common types in Book four include words like \"the\", \"of\", \"and\" and \"to\", which is not surprising as they are stop words that appear very frequently in the English language. However, after excluding stop words, I found that the most common types are \"Messenias\", \"Lacedaemonians\", \"son\", \"Aristomenes\" and \"men.\" These types indicate to me that book 4 is about Messenia and Sparta. I also can infer that Book four focuses highly on Aristomenes, the king of Messenia. The most common lemmata are very similar to the most common types: \"Messenians\", \"Lacedaemonians\", \"son\", \"man\", and \"come.\" \"Come\" is the only new token, as man and men are the same lemma. This new token does not provide me with much information as it has little substance. The five most common Lexemes in Book four are the same as the five most common types, which makes sense as in SpaCy, lexemes have no part-of-speech tag, dependency parse, or lemma. This quantitative analysis of the text aligns with what I know of Book four. Book four focuses on the history of Messenia, especially its wars. This information aligns with the fact that “war” is the sixth most common type in Book four. The words “battle,” “death,” and \"land\" are also “land” among the most common types. Overall, the quantitative analysis of this book aligns with the information that I know about the text and what it encapsulates. "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
