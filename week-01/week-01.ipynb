{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meeting 1\n",
    "\n",
    "## Review Resources\n",
    "\n",
    "- [Anaconda Crash Course](https://learning.anaconda.cloud/path/intro-to-python)\n",
    "- [Learn Python the Hard Way](https://learncodethehardway.com/client/#/product/learn-python-the-hard-way-5e-2023/)\n",
    "\n",
    "## Installing JupyterLab\n",
    "\n",
    "You don't need to install anything locally, as we'll be working from [Colab](https://colab.research.google.com/#) notebooks -- like Google Docs, but for code.\n",
    "\n",
    "## What is quantitative textual analysis?\n",
    "\n",
    "> Unlike other sources of information such as mythology, philosophy or art, **science** relies on the systematic collection of empirical data and testing of theories and hypotheses. [@Brezina2018 2; emphasis original]\n",
    "\n",
    "More tactfully (citing Popper 2005 [1935]):\n",
    "\n",
    "> A scientific statement or theory [is] something that can in principle be falsified.... In other words, we can call a statement or theory scientific only if it can be tested empirically. [@Brezina2018: 2]\n",
    "\n",
    "-   How do we qualify these statements?\n",
    "-   Are there problems with viewing texts in this way?\n",
    "-   Conversely, are there virtues in understanding textual data in this light?\n",
    "\n",
    "## What is corpus linguistics?\n",
    "\n",
    "> **Corpus linguistics** is a scientific method of language analysis. It requires the analyst to provide empirical evidence in the form of data drawn from language corpora in support of any statement made about language. [@Brezina2018: 2]\n",
    "\n",
    "## Getting started\n",
    "\n",
    "In this directory, you will find three text files containing the openings to Xenophon's *Apology*, Caesar's *De Bello Gallico*, and Jane Austen's *Pride and Prejudice*.\n",
    "\n",
    "Let's start with *Pride and Prejudice*. Run the code block below to load the contents of the file into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It is a truth universally acknowledged, that a single man in possession of a good fortune must be in want of a wife.\\n', '\\n', 'However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered as the rightful property of some one or other of their daughters.\\n']\n"
     ]
    }
   ],
   "source": [
    "with open(\"austen-pride-and-prejudice.txt\") as f:\n",
    "    austen = f.readlines()\n",
    "\n",
    "# notice that `austen` is still available outside of the\n",
    "# `with` block.\n",
    "print(austen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "1. Describe what each `token` in the above short code snippet is doing. (You might first need to decide what a `token` is.)\n",
    "2. What data type is the variable `austen`?\n",
    "3. How can we remove empty lines from `austen`?\n",
    "4. How would you update the code to print the excerpt from Caesar instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## write the code for reading the lines of Caesar below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These exercises are just the first steps towards using corpus linguistics in your interpretive practice. The main textbook that we'll be using, @Brezina2018, doesn't do a great job of providing hands-on exercises and instead wants to focus on the statics side of things. We're going to try to cover both the hands-on programming side and the statistical side in this course.\n",
    "\n",
    "To that end, let's turn our attention to some terms and techniques that we'll need to cover.\n",
    "\n",
    "- Corpus/sample: Collections of data. Most of the time, a \"corpus\" is meant to be large, like all Greek literature before 300 AD. But relatively small corpora -- like, say, all of 5th-century Athenian tragedy -- can prove useful as well.\n",
    "- Dataset: Collection of findings within the data of a corpus.\n",
    "- Variable: \n",
    "  - Linguistic variables: These are, generally, the things we want to measure.\n",
    "  - Explanatory (\"independent\") variables: Descriptors for where we find linguistic variables (see [@Brezina2018 6--7]).\n",
    "\n",
    "\n",
    "### Different kinds of variables\n",
    "\n",
    "Variables come in three varieties: nominal, ordinal, and scale [@Brezina2018 7]:\n",
    "\n",
    "- **Nominal** variables \"represent different categories into which the cases in a dataset can be grouped; there is no order or hierarchy between the categories.\"\n",
    "  - Ex. speaker's gender\n",
    "- **Ordinal** variables, like nominal variables, can be used for grouping data, but they \"can be ordered according to some inherent hierarchy.\"\n",
    "  - Ex. speaker's foreign language proficiency\n",
    "- **Scale** variables \"[show] the quantity of a particular feature; ... [they] can be added, subtracted, multiplied, and divided, because they represent measurable quantities, not just rank orders.\"\n",
    "  - Ex. relative frequency of first-person pronouns in a speaker's speech.\n",
    "\n",
    "\n",
    "## Measures of central tendency\n",
    "\n",
    "- Frequency distributions and averages help us determine outliers in our data.\n",
    "- What are the measures of central tendency with which you're familiar?\n",
    "- How are they calculated?\n",
    "- What is a normal distribution?\n",
    "\n",
    "\n",
    "## Dispersion measures\n",
    "\n",
    "Define the following:\n",
    "\n",
    "- Range_1\n",
    "- Interquartile range\n",
    "- Standard deviation\n",
    "\n",
    "## Statistical tests\n",
    "\n",
    "- How do we determine if a result is statistically signficant?\n",
    "\n",
    "## Biases\n",
    "\n",
    "According to @Brezina2018 [17--18], with what biases should we be concerned?\n",
    "\n",
    "What biases might be present in our tiny test corpus (`austen`) right now?\n",
    "\n",
    "## Homework\n",
    "\n",
    "1. @Brezina2018 1.7 Exercises (pp. 32--36); you can skip Exercise 1.\n",
    "2. Practice loading the included Greek and Latin texts into RStudio. What issues do you encounter?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
