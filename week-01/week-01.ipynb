{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Meeting 1\n",
    "\n",
    "## Review Resources\n",
    "\n",
    "- [Anaconda Crash Course](https://learning.anaconda.cloud/path/intro-to-python)\n",
    "- [Learn Python the Hard Way](https://learncodethehardway.com/client/#/product/learn-python-the-hard-way-5e-2023/)\n",
    "\n",
    "## Installing JupyterLab\n",
    "\n",
    "You don't need to install anything locally, as we'll be working from [Colab](https://colab.research.google.com/#) notebooks -- like Google Docs, but for code.\n",
    "\n",
    "## What is quantitative textual analysis?\n",
    "\n",
    "> Unlike other sources of information such as mythology, philosophy or art, **science** relies on the systematic collection of empirical data and testing of theories and hypotheses. [@Brezina2018 2; emphasis original]\n",
    "\n",
    "More tactfully (citing Popper 2005 [1935]):\n",
    "\n",
    "> A scientific statement or theory [is] something that can in principle be falsified.... In other words, we can call a statement or theory scientific only if it can be tested empirically. [@Brezina2018: 2]\n",
    "\n",
    "-   How do we qualify these statements?\n",
    "-   Are there problems with viewing texts in this way?\n",
    "-   Conversely, are there virtues in understanding textual data in this light?\n",
    "\n",
    "## What is corpus linguistics?\n",
    "\n",
    "> **Corpus linguistics** is a scientific method of language analysis. It requires the analyst to provide empirical evidence in the form of data drawn from language corpora in support of any statement made about language. [@Brezina2018: 2]\n",
    "\n",
    "## Getting started\n",
    "\n",
    "In this directory, you will find three text files containing the openings to Xenophon's *Apology*, Caesar's *De Bello Gallico*, and Jane Austen's *Pride and Prejudice*.\n",
    "\n",
    "Let's start with *Pride and Prejudice*. Run the code block below to load the contents of the file into memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['It is a truth universally acknowledged, that a single man in possession of a good fortune must be in want of a wife.', 'However little known the feelings or views of such a man may be on his first entering a neighbourhood, this truth is so well fixed in the minds of the surrounding families, that he is considered as the rightful property of some one or other of their daughters.']\n"
     ]
    }
   ],
   "source": [
    "with open(\"austen-pride-and-prejudice.txt\") as f:\n",
    "    austen = f.readlines()\n",
    "\n",
    "# notice that `austen` is still available outside of the\n",
    "# `with` block.\n",
    "print([l.strip()for l in austen if l.strip() != \"\"]) # taking out blank lines in austen (\\n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise \n",
    "\n",
    "1. Describe what each `token` in the above short code snippet is doing. (You might first need to decide what a `token` is.)\n",
    "2. What data type is the variable `austen`?\n",
    "3. How can we remove empty lines from `austen`?\n",
    "4. How would you update the code to print the excerpt from Caesar instead?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Gallia est omnis divisa in partes tres, quarum unam incolunt Belgae, aliam Aquitani, tertiam qui ipsorum lingua Celtae, nostra Galli appellantur. Hi omnes lingua, institutis, legibus inter se differunt. Gallos ab Aquitanis Garumna flumen, a Belgis Matrona et Sequana dividit. ']\n"
     ]
    }
   ],
   "source": [
    "## write the code for reading the lines of Caesar below:\n",
    "with open('phi0448.phi001.perseus-lat1/1.1.1-1.1.2.txt') as f:\n",
    "   caesar = f.readlines()\n",
    "print(caesar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These exercises are just the first steps towards using corpus linguistics in your interpretive practice. The main textbook that we'll be using, @Brezina2018, doesn't do a great job of providing hands-on exercises and instead wants to focus on the statics side of things. We're going to try to cover both the hands-on programming side and the statistical side in this course.\n",
    "\n",
    "To that end, let's turn our attention to some terms and techniques that we'll need to cover.\n",
    "\n",
    "- Corpus/sample: Collections of data. Most of the time, a \"corpus\" is meant to be large, like all Greek literature before 300 AD. But relatively small corpora -- like, say, all of 5th-century Athenian tragedy -- can prove useful as well.\n",
    "- Dataset: Collection of findings within the data of a corpus.\n",
    "- Variable: \n",
    "  - Linguistic variables: These are, generally, the things we want to measure.\n",
    "  - Explanatory (\"independent\") variables: Descriptors for where we find linguistic variables (see [@Brezina2018 6--7]).\n",
    "\n",
    "\n",
    "### Different kinds of variables\n",
    "\n",
    "Variables come in three varieties: nominal, ordinal, and scale [@Brezina2018 7]:\n",
    "\n",
    "- **Nominal** variables \"represent different categories into which the cases in a dataset can be grouped; there is no order or hierarchy between the categories.\"\n",
    "  - Ex. speaker's gender\n",
    "- **Ordinal** variables, like nominal variables, can be used for grouping data, but they \"can be ordered according to some inherent hierarchy.\"\n",
    "  - Ex. speaker's foreign language proficiency\n",
    "- **Scale** variables \"[show] the quantity of a particular feature; ... [they] can be added, subtracted, multiplied, and divided, because they represent measurable quantities, not just rank orders.\"\n",
    "  - Ex. relative frequency of first-person pronouns in a speaker's speech.\n",
    "\n",
    "\n",
    "## Measures of central tendency\n",
    "\n",
    "- Frequency distributions and averages help us determine outliers in our data.\n",
    "- What are the measures of central tendency with which you're familiar?\n",
    "- How are they calculated?\n",
    "- What is a normal distribution?\n",
    "\n",
    "\n",
    "## Dispersion measures\n",
    "\n",
    "Define the following:\n",
    "\n",
    "- Range_1\n",
    "- Interquartile range\n",
    "- Standard deviation\n",
    "\n",
    "## Statistical tests\n",
    "\n",
    "- How do we determine if a result is statistically signficant?\n",
    "\n",
    "## Biases\n",
    "\n",
    "According to @Brezina2018 [17--18], with what biases should we be concerned?\n",
    "\n",
    "What biases might be present in our tiny test corpus (`austen`) right now?\n",
    "\n",
    "## Homework\n",
    "\n",
    "1. @Brezina2018 1.7 Exercises (pp. 32--36); you can skip Exercise 1.\n",
    "2. Practice loading the included Greek and Latin texts into a Python notebook. What issues do you encounter?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr = [1, 2, 3, 4, 5]\n",
    "\n",
    "sum(arr) / len(arr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
