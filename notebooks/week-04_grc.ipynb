{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semantics and Discourse\n",
    "\n",
    "(Brezina 2018: ch. 3, pp. 66â€“75)\n",
    "\n",
    "## Collocations\n",
    "\n",
    "Definitions (@Brezina2018, 67): \n",
    "\n",
    "- **Collocation**: a group of two or more words \"that habitually co-occur in texts and corpora.\"\n",
    "- **Collocation measures**: \"statistical meausres that calculate the strength of association between words based on different aspects of the co-occurrence relationship.\"\n",
    "- **Node**: \"word that we want to search for and analyse.\"\n",
    "- **Collocates**: \"words that co-occur with the node in a specifically defined **span** around the node, which we call the **collocation window**.\"\n",
    "- **Observed frequency of collocation**: Number of times that a **collocate** appears with a **node**.\n",
    "\n",
    "## The simple approach\n",
    "\n",
    "> Discuss: Why might one avoid a basic ranked list of collocates?\n",
    "\n",
    "\n",
    "## A more sophisticated approach\n",
    "\n",
    "- **Expected frequency of collocation**\n",
    "\n",
    "```python\n",
    "expected_collocate_freq = (node_freq * collocate_freq * window_size) / n_tokens_in_corpus\n",
    "```\n",
    "\n",
    "> Discuss: Explain Brezina's example of \"my\" and \"love\" in Robert Burns' \"A Red, Red Rose.\"\n",
    "\n",
    "> Discuss: What problems does one encounter if one uses this approach blindly?\n",
    "\n",
    "\n",
    "## Association Measures\n",
    "\n",
    "Let's prepare to explore these collocation measures by loading up a dataframe of Pausanias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I've created a utils.py file for frequently reused functionality -- you can import from it like so\n",
    "from utils import load_pausanias\n",
    "\n",
    "pausanias_df = load_pausanias()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[c for c in pausanias_df['nlp_docs'][0][1].children]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Frequency of co-occurrence\n",
    "\n",
    "### Mutual Uninformation (MU)\n",
    "\n",
    "Simple the ratio of the **observed** frequency (O11) and **expected** frequency (E11).\n",
    "\n",
    "If the ratio is greater than 1, the words co-appear more frequently than expected.\n",
    "\n",
    "### Mutual Information (MI)\n",
    "\n",
    "`log<sub>2</sub>(O11/E11)`\n",
    "\n",
    "#### MI2\n",
    "\n",
    "\n",
    "#### MI3\n",
    "\n",
    "\n",
    "### Log-likelihood (LL)\n",
    "\n",
    "\n",
    "### Z-score<sub>1</sub>\n",
    "\n",
    "\n",
    "### T-score\n",
    "\n",
    "\n",
    "### Dice\n",
    "\n",
    "\n",
    "### Log Dice\n",
    "\n",
    "\n",
    "### Log ratio\n",
    "\n",
    "\n",
    "### Minimum Sensitivity (MS)\n",
    "\n",
    "\n",
    "### Delta P\n",
    "\n",
    "\n",
    "### Cohen's *d*\n",
    "\n",
    "\n",
    "## Directionality and Dispersion"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
